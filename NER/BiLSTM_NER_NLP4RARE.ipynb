{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"BiLSTM_NER_NLP4RARE.ipynb","provenance":[{"file_id":"1LCJt3fu3pW0hFe7L19Uu4MMRrW9Z9p5N","timestamp":1612543820837}],"collapsed_sections":["_yrUIDHv4TDD"]},"environment":{"name":"pytorch-gpu.1-4.m55","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m55"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AcQ7f6ku4TCy"},"source":["# BiLSTM approach for detecting rare diseases\n","\n","This notebook contains the code to develop a BiLSTM model to detect rare diseases from texts.\n","\n","It can use random initialization or pre-trained word embeddings to initializate the vectors for the tokens in the texts.\n","\n","It can also include a CRF layer. \n","\n","First, we declare some variables to save paths that will be used in this notebook.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E-awiIaFW2Nc","executionInfo":{"status":"ok","timestamp":1625740289812,"user_tz":-120,"elapsed":15894,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"a350243d-f915-412f-9e2c-a61a8f9c4148"},"source":["if 'google.colab' in str(get_ipython()):\n","    print('Running on CoLab')\n","    from google.colab import drive\n","    #drive.flush_and_unmount()\n","    drive.mount('/content/drive')\n","    root = '/content/drive/My Drive/Colab Notebooks'\n","else:\n","    print('Not running on CoLab')\n","    root = './'\n","\n","print(\"Current directory: {}\".format(root))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running on CoLab\n","Mounted at /content/drive\n","Current directory: /content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awEV9-qRs7xc","executionInfo":{"status":"ok","timestamp":1625740297155,"user_tz":-120,"elapsed":7347,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"41f0fa33-734e-46df-d283-8c1524f7167b"},"source":["import tensorflow as tf\n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())\n","print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n","print('Tensorflow version used: {}'.format(tf.__version__))\n","\n","# If not working try\n","#!pip install tensorflow==2.1.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 15665462775423011571\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14509932544\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 11341853609289169519\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","]\n","Default GPU Device: /device:GPU:0\n","Tensorflow version used: 2.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aiUMvFIX4TCy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625740297156,"user_tz":-120,"elapsed":8,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"41e55ee1-3f7d-437c-899f-449f622fc91e"},"source":["LANG = 'en'  #This system will also process texts written in Spanish, LANG='es'\n","allTypes = True\n","sTypes = ''\n","if allTypes:\n","    sTypes = '_all'\n","\n","random_initialization = 0 #1 use random initialization, 0 uses pre-trained word embeddings\n","\n","#path_data=root+'data/{}/'.format(LANG) #folder where you can find the datasets\n","path_data = root + '/ner/data/gold_nlp4rare_corpus/' #folder where you can find the datasets\n","path_models = root + '/ner/models/{}/'.format(LANG) #folder to save the models\n","checkpoints = root + '/ner/checkpoints/'\n","path_scores = root + '/ner/scores/{}/'.format(LANG) #folder to save the scores\n","path_outputs = root + '/ner/outputs/{}/'.format(LANG) #folder to save the scores\n","\n","print('Datasets:',path_data)\n","print('Path to save this model:',path_models)\n","print('Path for checkpoints:',checkpoints)\n","print('Path to save the scores:',path_scores)\n","print('Path to save the outputs:',path_outputs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Datasets: /content/drive/My Drive/Colab Notebooks/ner/data/gold_nlp4rare_corpus/\n","Path to save this model: /content/drive/My Drive/Colab Notebooks/ner/models/en/\n","Path for checkpoints: /content/drive/My Drive/Colab Notebooks/ner/checkpoints/\n","Path to save the scores: /content/drive/My Drive/Colab Notebooks/ner/scores/en/\n","Path to save the outputs: /content/drive/My Drive/Colab Notebooks/ner/outputs/en/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aToyNWlZZjRn"},"source":["## Random initialization or word embeddings???\n","\n","Our texts can be represented with random initialization or with pre-trained word embeddings models\n","\n","If our system uses word embeddings to initialize the vectors for our network, we need to load a pre-trained word embedding model. \n","\n","The following cell contains the code need to do this:"]},{"cell_type":"code","metadata":{"id":"qTz3peEPYWHF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625740392650,"user_tz":-120,"elapsed":95499,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"2607b05e-8361-489f-812f-8d95f5db5400"},"source":["import time\n","import numpy as np\n","\n","if random_initialization==0:\n","    models = {'Google News':'GoogleNews-vectors-negative300.bin.gz', 'GloVe':'glove.840B.300d.zip', 'Wiki-PubMed-PMC':'wikipedia-pubmed-and-PMC-w2v.bin'}\n","    model_used = models['Wiki-PubMed-PMC'] # Change for desired model\n","    path_w2v = root+'/word_embedding/'+model_used # Change for correct path to the model folder\n","    print(\"Charging word embedding model {}...\".format(model_used))\n","\n","    if model_used == 'GoogleNews-vectors-negative300.bin.gz' or model_used == 'wikipedia-pubmed-and-PMC-w2v.bin':\n","        from gensim.models import KeyedVectors\n","        start_time = time.time()\n","        modelw2v = KeyedVectors.load_word2vec_format(path_w2v, binary=True)\n","\n","    elif model_used == 'glove.840B.300d.zip':\n","        import zipfile # It allows to manage the file compressed\n","        start_time = time.time()\n","        modelw2v = {}\n","        with zipfile.ZipFile(path_w2v) as zf:\n","            with zf.open('glove.840B.300d.txt') as f:\n","                for line in f:\n","                    values = line.decode('utf-8').split(' ')\n","                    word = values[0]\n","                    coefs = np.asarray([float(val) for val in values[1:]])\n","                    modelw2v[word] = coefs\n","            zf.close()\n","  \n","    # Some metrics\n","    execution_time = time.time() - start_time\n","    print(\"Elapsed Time:\\n\\t{:.2f} seconds\\n\\t{:.2f} min\".format(execution_time, execution_time/60))\n","    print(\"Model loaded\")\n","\n","else:\n","    print('Random initialization')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Charging word embedding model wikipedia-pubmed-and-PMC-w2v.bin...\n","Elapsed Time:\n","\t94.19 seconds\n","\t1.57 min\n","Model loaded\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Xx32GXkM4TC1"},"source":["## 1) Loading the data and creating the vocabulary\n","\n","The input of a neural network model cannot be texts. So, we need to tranform texts into number. In this approach, we are going to represent each words as integer, its index in the vocabulary. This vocabulary is the list of unique words (tokens) from the texts.  To obtains this vocabulary, we consider the texts from training and development datasets. In particular, we need to define the following dictionaries:\n","\n","\n","- **word_index**: is a dictionary to convert a word into an index value.\n","- **tag_index** is a dictionary to convert a label into an index value. \n","\n","Therefore, first, we need to load the training and development datasets to panda dataframes. \n","\n","Moreover, we need to join both datasets into one."]},{"cell_type":"code","metadata":{"id":"ewW7dzRD4TC2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625740396379,"user_tz":-120,"elapsed":3233,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"2855aeb4-2dc6-4d13-84a8-22ffb28c7d57"},"source":["import pandas as pd\n","\n","df_train = pd.read_csv(path_data+'train{}.csv'.format(sTypes),index_col=0)\n","print('size of the training dataset: {}'.format(len(df_train)))\n","df_dev = pd.read_csv(path_data+'dev{}.csv'.format(sTypes),index_col=0)\n","print('size of the development dataset: {}'.format(len(df_dev)))\n","df_test = pd.read_csv(path_data+'test{}.csv'.format(sTypes),index_col=0)\n","print('size of the test dataset: {}'.format(len(df_test)))\n","print('datasets loaded!\\n')\n","\n","#number of labels (IOB tags)\n","tags = df_train['Tag'].unique()\n","num_tags = df_train['Tag'].nunique()\n","print('Labels: {}'.format(tags))\n","print('Nr of labels: {}'.format(num_tags))\n","\n","# Overall statistics for the number of words in each text\n","count_df_train = df_train.groupby('Sentence #').count()\n","statistics_train = count_df_train['Word'].describe()\n","print('\\nSome statistics of the sentences in the training dataset:')\n","print(statistics_train)\n","\n","count_df_dev = df_dev.groupby('Sentence #').count()\n","statistics_dev = count_df_dev['Word'].describe()\n","print('\\nSome statistics of the sentences in the development dataset:')\n","print(statistics_dev)\n","\n","#The lenth of the longest sentence. Lenght is the number of words.\n","MAX_LEN_TRAIN = int(statistics_train['max'])\n","MAX_LEN_DEV = int(statistics_dev['max'])\n","MAX_LEN = max(MAX_LEN_TRAIN, MAX_LEN_DEV)\n","print('\\n')\n","print('The maximum length of sentences in TRAIN is: ', MAX_LEN_TRAIN)\n","print('The maximum length of sentences in DEV is: ', MAX_LEN_DEV)\n","print('The maximum length of sentences in TOTAL is:', MAX_LEN)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["size of the training dataset: 135656\n","size of the development dataset: 18492\n","size of the test dataset: 37837\n","datasets loaded!\n","\n","Labels: ['O' 'B-RAREDISEASE' 'I-RAREDISEASE' 'B-DISEASE' 'I-DISEASE' 'B-SIGN'\n"," 'I-SIGN' 'B-SYMPTOM' 'I-SYMPTOM']\n","Nr of labels: 9\n","\n","Some statistics of the sentences in the training dataset:\n","count    6451.000000\n","mean       21.028678\n","std        10.653876\n","min         1.000000\n","25%        13.000000\n","50%        19.000000\n","75%        26.000000\n","max        90.000000\n","Name: Word, dtype: float64\n","\n","Some statistics of the sentences in the development dataset:\n","count    903.000000\n","mean      20.478405\n","std       10.105284\n","min        1.000000\n","25%       13.000000\n","50%       18.000000\n","75%       25.000000\n","max       71.000000\n","Name: Word, dtype: float64\n","\n","\n","The maximum length of sentences in TRAIN is:  90\n","The maximum length of sentences in DEV is:  71\n","The maximum length of sentences in TOTAL is: 90\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"leGFOSVppFli"},"source":["## Create the vocabulary\n","\n","We need to build the vocabulary from the training (and validation texts). This vocabulary contains the list of unique words in these texts. The vocabulary is a dictionary with the words (as keys) and its corresponding frequencies. The words in the dictionary are sorted by its frecuencies. \n","\n","To obtain this vocabulary, we can use the class Tokenizer provided by Keras. Please, note that this tokenizer keeps the index 0 for pad tokens"]},{"cell_type":"code","metadata":{"id":"ocQT8Bd3pHkc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625740397222,"user_tz":-120,"elapsed":846,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"f2613566-8a08-4843-b541-56867e0e10ca"},"source":["from keras.preprocessing.text import Tokenizer\n","MAX_FEATURES = 20000 # this is the number of words we care about, we only consider the 20000 words most common \n","\n","full_train_df = pd.concat([df_train, df_dev], ignore_index=True).copy()\n","words = full_train_df['Word'].values\n","\n","tokenizer = Tokenizer(num_words=MAX_FEATURES, filters='\\t\\n')\n","\n","#this methods creates the dictionary (which contains the unique words from words)\n","tokenizer.fit_on_texts(words)\n","#this is the vocabulary. \n","word_index = tokenizer.word_index  \n","#the tokenizer keeps the index 0 for pad tokens\n","print('Size of the vocabulary:', len(word_index))\n","\n","#We also have to create a dictionary for the labels (IOB labels):\n","# label is key and value is index.\n","tag_index = {t : i + 1 for i, t in enumerate(tags)}\n","#we have to add a new label for pad tokens\n","tag_index[\"PAD\"] = 0\n","\n","print('Dictionary for labels:', tag_index)\n","print('Number of tags added the tag for pad tokens:', len(tag_index))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Size of the vocabulary: 8916\n","Dictionary for labels: {'O': 1, 'B-RAREDISEASE': 2, 'I-RAREDISEASE': 3, 'B-DISEASE': 4, 'I-DISEASE': 5, 'B-SIGN': 6, 'I-SIGN': 7, 'B-SYMPTOM': 8, 'I-SYMPTOM': 9, 'PAD': 0}\n","Number of tags added the tag for pad tokens: 10\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eCW2gF_B3KiP"},"source":["\n","### Create the word embedding matrix"]},{"cell_type":"code","metadata":{"id":"HY_qi1yf3NfX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625740397222,"user_tz":-120,"elapsed":4,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"e69a008b-0d81-4163-b2ad-72c206585d0b"},"source":["def getEmbeddingMatrix(word_index, MAX_FEATURES, model, dimensionality):\n","    \"\"\"This functions creates a matrix where each file is a word embedding vector.\n","      Inputs:\n","          word_index = refers to the tokenized word index from our dataset\n","          MAX_FEATURES = refers to the maximum vocabulary size desired\n","          model = refers to the word embedding dictionary model used\n","          dimensionality = refers to the size of the one-dimensional vectors in the word embedding model used\n","    \"\"\"\n","    \n","    # first create a matrix of zeros, this is our embedding matrix\n","    num_words = min(MAX_FEATURES, len(word_index)) + 1 # +1 because of the padding token\n","    print(\"Nr of words [(maximum vocabulary size | word_index) +1 padded]: {}\".format(num_words))\n","    embedding_matrix = np.zeros((num_words, dimensionality), dtype=np.float32)\n","\n","    # for each word in our word_index lets get the equivalent model vector\n","    for word, i in word_index.items():\n","        if i > MAX_FEATURES:\n","            continue\n","        if word in model:\n","            embedding_matrix[i] = model[word]\n","        # If word doesn't exist in model, let the vector of zeros\n","\n","    #print (count,\" \",num_words)\n","    print(\"Shape of the embedding matrix: {}\".format(embedding_matrix.shape))\n","    print(\"Nr of words inside the model: {}\".format(int((np.count_nonzero(embedding_matrix, axis=None))/dimensionality)))\n","    return embedding_matrix, num_words\n","\n","\n","if random_initialization==1:\n","    dim_embedding = 300 #by default, 300 dimension for the vectors representing the tokens\n","    print(\"No Embedding matrix needed\")\n","else:\n","    dim_embedding = 300 #by default, 300 dimension for the vectors representing the tokens\n","    if model_used == 'wikipedia-pubmed-and-PMC-w2v.bin':\n","        dim_embedding = 200\n","    embedding_matrix, num_words = getEmbeddingMatrix(word_index, MAX_FEATURES, modelw2v, dim_embedding)\n","    print(\"Embedding matrix for {} model was successfully created\".format(model_used))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Nr of words [(maximum vocabulary size | word_index) +1 padded]: 8917\n","Shape of the embedding matrix: (8917, 200)\n","Nr of words inside the model: 8383\n","Embedding matrix for wikipedia-pubmed-and-PMC-w2v.bin model was successfully created\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ia7D4tKP4TC4"},"source":["## 2) Vectorization (transforming the texts to numbers)"]},{"cell_type":"code","metadata":{"id":"1BD1kRqB4TC4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625740398326,"user_tz":-120,"elapsed":1106,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"6171dc75-e2a7-4363-ff27-9f9a05a03413"},"source":["from tensorflow.keras.preprocessing import sequence, text\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","\n","class SentenceGetter(object):\n","    \"\"\"This is a class to get sentence. Each sentence will be a list of tuples with its tag and pos.\"\"\"\n","    def __init__(self, df):\n","        self.n_sent = 1\n","        self.df = df\n","        self.empty = False\n","        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n","                                                       s['POS'].values.tolist(),\n","                                                       s['Tag'].values.tolist())]\n","        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n","        self.sentences = [s for s in self.grouped]\n","        \n","    def get_text(self):\n","        try:\n","            #s = self.grouped['Sentence: {}'.format(self.n_sent)]\n","            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n","            self.n_sent +=1\n","            return s\n","        except:\n","            return None\n","\n","def vectorization(df,word_index,tag_index,MAX_LEN):\n","    \"\"\"This functions gets the dataframe with the dataset and transform it to vectors. \n","    First, its sentences are retrieved. Then, for each sentence, the function creates a list\n","    with its corresponding indexes. If the word does not exist, it gives 0 for this token.\n","    In addition to X (which are the sentences transformed to vectors), the functions also\n","    returns the corresponding labels for each token in one-hot coding\"\"\"\n","    \n","    df = df[['Sentence #','Word','POS','Tag']]\n","    \n","    # Getting full sentences\n","    getter = SentenceGetter(df)\n","    sentences = getter.sentences\n","\n","    # Converting each sentence into list of index from list of tokens\n","    X = [[word_index.get(w[0], 0) for w in s] for s in sentences]\n","    X = pad_sequences(maxlen = MAX_LEN, sequences = X, padding = \"post\")\n","\n","    # Convert label to index\n","    y = [[tag_index[w[2]] for w in s] for s in sentences]\n","\n","    # padding\n","    y = pad_sequences(maxlen=MAX_LEN, sequences=y, padding=\"post\", value=tag_index[\"PAD\"])\n","    \n","    # One hot encoded labels\n","    num_tags = df['Tag'].nunique()\n","    y = [to_categorical(i, num_classes=num_tags+1) for i in y]\n","    \n","    return (X, y)\n","    \n","\n","X_train, y_train = vectorization(df_train, word_index, tag_index, MAX_LEN)\n","X_dev, y_dev = vectorization(df_dev, word_index, tag_index, MAX_LEN)\n","X_test, y_test = vectorization(df_test, word_index, tag_index, MAX_LEN)\n","\n","print(\"Size of training input data : \", X_train.shape)\n","print(\"Size of training output data : \", np.array(y_train).shape)\n","\n","print(\"Size of validation input data : \", X_dev.shape)\n","print(\"Size of validation output data : \", np.array(y_dev).shape)\n","\n","print(\"Size of testing input data : \", X_test.shape)\n","print(\"Size of testing output data : \", np.array(y_test).shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Size of training input data :  (6451, 90)\n","Size of training output data :  (6451, 90, 10)\n","Size of validation input data :  (903, 90)\n","Size of validation output data :  (903, 90, 10)\n","Size of testing input data :  (1772, 90)\n","Size of testing output data :  (1772, 90, 10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9g7XWoKv4TC6"},"source":["## 3) Defining the architecture\n","\n","We now define our architecture, that is, its layers. Before we have to define some important parameters:"]},{"cell_type":"code","metadata":{"id":"RHCgBjWh4TC_","colab":{"base_uri":"https://localhost:8080/","height":755},"executionInfo":{"status":"ok","timestamp":1625740399445,"user_tz":-120,"elapsed":1123,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"514e7416-50ec-465e-b35c-35ff5984e9cd"},"source":["BATCH_SIZE = 64 #64\n","EPOCHS = 20 #40,20\n","#MAX_LEN = 75\n","EMBEDDING = dim_embedding\n","UNITS=100 #50\n","\n","if random_initialization==1:\n","    initialization = 'random'\n","else:\n","    initialization = path_w2v[path_w2v.rfind('/')+1:path_w2v.find('-')]\n","    print(initialization)\n","\n","from datetime import datetime\n","\n","today=datetime.today().strftime('%Y-%m-%d')\n","\n","NAMEMODEL='BILSTM-{}-epochs:{}-batchsize:{}-dimembeding:{}-units:{}-date:{}-sTypes:{}'.format(initialization, EPOCHS, BATCH_SIZE, EMBEDDING, UNITS, today, sTypes)\n","print(NAMEMODEL)\n","\n","# Model architecture\n","from tensorflow import keras\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import LSTM, Dense, TimeDistributed, Embedding, Bidirectional, Input\n","from keras.models import Model\n","\n","# Model definition\n","input = Input(shape=(MAX_LEN,))\n","\n","# embedding layer\n","if random_initialization==1:\n","    model = Embedding(input_dim = len(word_index)+1, output_dim = EMBEDDING, input_length = MAX_LEN, mask_zero = False)(input)\n","else:\n","    model= Embedding(input_dim = len(word_index)+1, weights=[embedding_matrix], output_dim = EMBEDDING, input_length = MAX_LEN, mask_zero = False)(input)\n","\n","# Bilstm layer\n","model = Bidirectional(LSTM(units = UNITS, return_sequences=True, recurrent_dropout=0.1))(model)\n","\n","# Variational BiLSTM\n","out = TimeDistributed(Dense(num_tags+1, activation=\"relu\"))(model)\n","\n","# output\n","model = Model(input, out)\n","\n","# Model compile\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","\n","model.summary()\n","tf.keras.utils.plot_model(model)\n","#tf.keras.utils.plot_model(model, to_file = root+'imgs/'+NAMEMODEL+'.png')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["wikipedia\n","BILSTM-wikipedia-epochs:20-batchsize:64-dimembeding:200-units:100-date:2021-07-08-sTypes:_all\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 90)]              0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, 90, 200)           1783400   \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 90, 200)           240800    \n","_________________________________________________________________\n","time_distributed (TimeDistri (None, 90, 10)            2010      \n","=================================================================\n","Total params: 2,026,210\n","Trainable params: 2,026,210\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"OM8Uw_T14TDB"},"source":["## 4) Training the model \n","\n","\n","Now we train our model. We use EarlyStopping to avoid overfitting. This callback will stop the training when there is no improvement in the validation loss for three consecutive epochs.\n","\n","A model is only saved when it provides better performance than previous ones. \n","\n"]},{"cell_type":"code","metadata":{"id":"DupdVbXe4TDC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625741211620,"user_tz":-120,"elapsed":812178,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"0fdba16c-20c9-4b81-cb58-cc41fe2c0592"},"source":["from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","checkModel = checkpoints + NAMEMODEL + '.h5'\n","\n","callbacks = [EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True),\n","                ModelCheckpoint(filepath=checkModel,verbose=1, monitor='val_loss', \n","                             save_best_only=True)]\n","\n","import time\n","\n","start = time.time()\n","from numpy.random import seed\n","seed(42)\n","tf.random.set_seed(42)\n","history = model.fit(X_train, np.array(y_train), validation_data=(X_dev, np.array(y_dev)), batch_size=BATCH_SIZE, epochs=EPOCHS,  callbacks=callbacks)\n","stop = time.time()\n","\n","trainingTime = round(stop - start,2)\n","print(f\"Training time: {trainingTime} seconds\")\n","print(f\"Training time: {trainingTime/60} min\")\n","history.history.keys()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","101/101 [==============================] - 84s 565ms/step - loss: 1.2429 - accuracy: 0.8590 - val_loss: 0.1754 - val_accuracy: 0.9571\n","\n","Epoch 00001: val_loss improved from inf to 0.17535, saving model to /content/drive/My Drive/Colab Notebooks/ner/checkpoints/BILSTM-wikipedia-epochs:20-batchsize:64-dimembeding:200-units:100-date:2021-07-08-sTypes:_all.h5\n","Epoch 2/20\n","101/101 [==============================] - 55s 546ms/step - loss: 0.1603 - accuracy: 0.9579 - val_loss: 0.1262 - val_accuracy: 0.9572\n","\n","Epoch 00002: val_loss improved from 0.17535 to 0.12625, saving model to /content/drive/My Drive/Colab Notebooks/ner/checkpoints/BILSTM-wikipedia-epochs:20-batchsize:64-dimembeding:200-units:100-date:2021-07-08-sTypes:_all.h5\n","Epoch 3/20\n","101/101 [==============================] - 55s 545ms/step - loss: 0.1146 - accuracy: 0.9594 - val_loss: 0.1096 - val_accuracy: 0.9573\n","\n","Epoch 00003: val_loss improved from 0.12625 to 0.10959, saving model to /content/drive/My Drive/Colab Notebooks/ner/checkpoints/BILSTM-wikipedia-epochs:20-batchsize:64-dimembeding:200-units:100-date:2021-07-08-sTypes:_all.h5\n","Epoch 4/20\n","101/101 [==============================] - 55s 545ms/step - loss: 0.0952 - accuracy: 0.9588 - val_loss: 0.1006 - val_accuracy: 0.9575\n","\n","Epoch 00004: val_loss improved from 0.10959 to 0.10065, saving model to /content/drive/My Drive/Colab Notebooks/ner/checkpoints/BILSTM-wikipedia-epochs:20-batchsize:64-dimembeding:200-units:100-date:2021-07-08-sTypes:_all.h5\n","Epoch 5/20\n","101/101 [==============================] - 55s 546ms/step - loss: 0.0837 - accuracy: 0.9597 - val_loss: 0.0966 - val_accuracy: 0.9591\n","\n","Epoch 00005: val_loss improved from 0.10065 to 0.09663, saving model to /content/drive/My Drive/Colab Notebooks/ner/checkpoints/BILSTM-wikipedia-epochs:20-batchsize:64-dimembeding:200-units:100-date:2021-07-08-sTypes:_all.h5\n","Epoch 6/20\n","101/101 [==============================] - 55s 545ms/step - loss: 0.0753 - accuracy: 0.9625 - val_loss: 0.0922 - val_accuracy: 0.9671\n","\n","Epoch 00006: val_loss improved from 0.09663 to 0.09217, saving model to /content/drive/My Drive/Colab Notebooks/ner/checkpoints/BILSTM-wikipedia-epochs:20-batchsize:64-dimembeding:200-units:100-date:2021-07-08-sTypes:_all.h5\n","Epoch 7/20\n","101/101 [==============================] - 55s 546ms/step - loss: 0.0632 - accuracy: 0.9759 - val_loss: 0.0878 - val_accuracy: 0.9723\n","\n","Epoch 00007: val_loss improved from 0.09217 to 0.08776, saving model to /content/drive/My Drive/Colab Notebooks/ner/checkpoints/BILSTM-wikipedia-epochs:20-batchsize:64-dimembeding:200-units:100-date:2021-07-08-sTypes:_all.h5\n","Epoch 8/20\n","101/101 [==============================] - 55s 548ms/step - loss: 0.0530 - accuracy: 0.9819 - val_loss: 0.0855 - val_accuracy: 0.9740\n","\n","Epoch 00008: val_loss improved from 0.08776 to 0.08553, saving model to /content/drive/My Drive/Colab Notebooks/ner/checkpoints/BILSTM-wikipedia-epochs:20-batchsize:64-dimembeding:200-units:100-date:2021-07-08-sTypes:_all.h5\n","Epoch 9/20\n","101/101 [==============================] - 55s 547ms/step - loss: 0.0450 - accuracy: 0.9846 - val_loss: 0.0877 - val_accuracy: 0.9744\n","\n","Epoch 00009: val_loss did not improve from 0.08553\n","Epoch 10/20\n","101/101 [==============================] - 55s 546ms/step - loss: 0.0392 - accuracy: 0.9867 - val_loss: 0.0849 - val_accuracy: 0.9749\n","\n","Epoch 00010: val_loss improved from 0.08553 to 0.08491, saving model to /content/drive/My Drive/Colab Notebooks/ner/checkpoints/BILSTM-wikipedia-epochs:20-batchsize:64-dimembeding:200-units:100-date:2021-07-08-sTypes:_all.h5\n","Epoch 11/20\n","101/101 [==============================] - 56s 555ms/step - loss: 0.0358 - accuracy: 0.9880 - val_loss: 0.0909 - val_accuracy: 0.9753\n","\n","Epoch 00011: val_loss did not improve from 0.08491\n","Epoch 12/20\n","101/101 [==============================] - 56s 551ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.0918 - val_accuracy: 0.9746\n","\n","Epoch 00012: val_loss did not improve from 0.08491\n","Epoch 13/20\n","101/101 [==============================] - 55s 544ms/step - loss: 0.0300 - accuracy: 0.9901 - val_loss: 0.0910 - val_accuracy: 0.9751\n","\n","Epoch 00013: val_loss did not improve from 0.08491\n","Epoch 14/20\n","101/101 [==============================] - 54s 538ms/step - loss: 0.0277 - accuracy: 0.9907 - val_loss: 0.0943 - val_accuracy: 0.9750\n","\n","Epoch 00014: val_loss did not improve from 0.08491\n","Training time: 812.2 seconds\n","Training time: 13.536666666666667 min\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"_yrUIDHv4TDD"},"source":["### Saving the model\n","We need to save the best model into a variable, bestmodel. Then, the loaded model could be used to evaluate the test dataset. \n","\n","We also save the model into the folder models with the name BiLSTM-random.h5."]},{"cell_type":"code","metadata":{"id":"XgrWYfqE4TDE"},"source":["from keras.models import load_model \n","\n","# checkModel=checkpoints+NAMEMODEL+'.h5'\n","\n","# loss = history.history['loss']\n","# val_loss = history.history['val_loss']\n","\n","def create_custom_objects():\n","    instanceHolder = {\"instance\": None}\n","    class ClassWrapper(CRF):\n","        def __init__(self, *args, **kwargs):\n","            instanceHolder[\"instance\"] = self\n","            super(ClassWrapper, self).__init__(*args, **kwargs)\n","    def loss(*args):\n","        method = getattr(instanceHolder[\"instance\"], \"loss_function\")\n","        return method(*args)\n","    def accuracy(*args):\n","        method = getattr(instanceHolder[\"instance\"], \"accuracy\")\n","        return method(*args)\n","    return {\"ClassWrapper\": ClassWrapper ,\"CRF\": ClassWrapper, \"loss\": loss, \"accuracy\":accuracy}\n","\n","def load_keras_model(path):\n","    model = load_model(path, custom_objects=create_custom_objects())\n","    return model\n","\n","# model = load_model(checkModel)\n","# print('model loaded into the variable bestmodel')\n","\n","#we now save the model\n","#model.save(path_models+NAMEMODEL+'.h5')\n","#print('model was saved into the file:',path_models+NAMEMODEL+'.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4GYN4ierLL7T"},"source":["If you already have a trained model, it is possible to skip the training phase. \n"]},{"cell_type":"code","metadata":{"id":"O5YIgdNjLHVm"},"source":["loadModel=True\n","\n","if loadModel:\n","    model = load_model(path_models+NAMEMODEL+'.h5')\n","    print('model loaded from the file:',path_models+NAMEMODEL+'.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_K2hxqpp4TDF"},"source":["## 5) Testing the model \n","\n","We can now apply the model over the test dataset to measure its results. The test dataset was already loaded and processed to prepare the input of the network. "]},{"cell_type":"code","metadata":{"id":"7LAZ1rcp4TDG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625741291699,"user_tz":-120,"elapsed":5411,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"2b199fe8-2878-44af-9c0a-c8bd10302298"},"source":["# Evaluation\n","y_pred = model.predict(X_test)\n","y_pred = np.argmax(y_pred, axis=-1)\n","y_gold = np.argmax(y_test, -1)\n","\n","# Convert the index to tag\n","idx2tag = {i: w for w, i in tag_index.items()}\n","y_pred = [[idx2tag[i] for i in row] for row in y_pred]\n","y_gold = [[idx2tag[i] for i in row] for row in y_gold]\n","\n","print('Predictions completed')\n","\n","### Saving the predictions\n","#We also save the predictions and the gold-standard outputs into files. These files will allow us to perform an error anlysis. \n","file_outputs = path_outputs + NAMEMODEL + '.npy'\n","np.save(file_outputs, y_pred)\n","np.save(path_outputs + 'y_gold_test.npy', y_gold)\n","print('Predictions saved' + file_outputs)\n","\n","### Cleaning the predictions from padding\n","no_padded_y_gold = []\n","no_padded_y_pred = []\n","\n","for g, p in zip(y_gold, y_pred):\n","    clean_g = [value for value in g if value != 'PAD']\n","    no_padded_y_gold.append(clean_g)\n","    threshold = len(clean_g)\n","    clean_p = p[:threshold]\n","    no_padded_y_pred.append(clean_p)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predictions completed\n","Predictions saved/content/drive/My Drive/Colab Notebooks/ner/outputs/en/BILSTM-wikipedia-epochs:20-batchsize:64-dimembeding:200-units:100-date:2021-07-08-sTypes:_all.npy\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ORevcU6R4TDH"},"source":["### Showing (and saving) the results\n","\n","We can see than our model achieves very high average scores. This is because the tag 'O' (which has many examples) helps to increase these average results. However, the scores for the other individual tags  are much lower. \n","\n"]},{"cell_type":"code","metadata":{"id":"IhuUfpIm4TDI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625741316684,"user_tz":-120,"elapsed":6308,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"0d28f08b-4c3f-4a6f-d40c-a8769aedb11a"},"source":["!pip install sklearn-crfsuite\n","from sklearn_crfsuite.metrics import flat_classification_report\n","\n","if allTypes:\n","    labels=['B-DISEASE','I-DISEASE','B-RAREDISEASE','I-RAREDISEASE','B-SYMPTOM','I-SYMPTOM','B-SIGN','I-SIGN','O']\n","else:\n","    labels=['B-RAREDISEASE','I-RAREDISEASE','B-SIGN-SYM','I-SIGN-SYM','O']\n","\n","# Results including 'O' tag\n","metric1 = flat_classification_report(no_padded_y_gold, no_padded_y_pred, labels=labels, digits=4) # individual tags evaluation\n","print('BiLSTM results (including the class O):')\n","print('Language:'+ LANG + '\\n')\n","print(metric1)\n","\n","file_scores = path_scores + NAMEMODEL + '.txt'\n","f = open(file_scores, \"w\")\n","\n","# Results without including 'O' tag\n","labels.remove('O')\n","report = flat_classification_report(no_padded_y_gold, no_padded_y_pred, labels=labels, digits=4) # individual tags evaluation\n","\n","# Prints\n","print('BiLSTM results (without including the class O):')\n","print('Language:'+ LANG + '\\n')\n","print(report)\n","\n","f.write('BiLSTM results (without including the class O)\\n')\n","f.write('Language:'+ LANG + '\\n')\n","\n","data=report.split('\\n')\n","for line in data:\n","    if len(line.strip())==0 or 'precision' in line:\n","        pass\n","    else:\n","        if ' avg' in line:\n","            line=line.replace(' avg','-avg')\n","        line=line.strip()\n","        line=' '.join(line.split())\n","\n","        line=line.replace(' ','\\t&\\t')+'\\\\\\\\'\n","        if line.startswith('weighted'):\n","            line='\\\\hline %'+line\n","        \n","        print(line)\n","        f.write(line)\n","\n","f.write('\\n\\n')\n","# f.write('Training times:{}(s)'.format(str(trainingTime)))\n","f.close()\n","print('Scores were saved to path: ' + file_scores)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting sklearn-crfsuite\n","  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n","Collecting python-crfsuite>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n","\u001b[K     |████████████████████████████████| 747kB 10.4MB/s \n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.8.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (1.15.0)\n","Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (4.41.1)\n","Installing collected packages: python-crfsuite, sklearn-crfsuite\n","Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n","BiLSTM results (including the class O):\n","Language:en\n","\n","               precision    recall  f1-score   support\n","\n","    B-DISEASE     0.7600    0.4718    0.5822       443\n","    I-DISEASE     0.7546    0.5150    0.6122       400\n","B-RAREDISEASE     0.7163    0.6636    0.6889      1073\n","I-RAREDISEASE     0.8489    0.6480    0.7350      1179\n","    B-SYMPTOM     0.6765    0.4600    0.5476        50\n","    I-SYMPTOM     1.0000    0.0750    0.1395        80\n","       B-SIGN     0.5318    0.5106    0.5210       803\n","       I-SIGN     0.5807    0.4614    0.5142      2215\n","            O     0.9310    0.9610    0.9458     31594\n","\n","    micro avg     0.8961    0.8911    0.8936     37837\n","    macro avg     0.7555    0.5296    0.5874     37837\n"," weighted avg     0.8893    0.8911    0.8876     37837\n","\n","BiLSTM results (without including the class O):\n","Language:en\n","\n","               precision    recall  f1-score   support\n","\n","    B-DISEASE     0.7600    0.4718    0.5822       443\n","    I-DISEASE     0.7546    0.5150    0.6122       400\n","B-RAREDISEASE     0.7163    0.6636    0.6889      1073\n","I-RAREDISEASE     0.8489    0.6480    0.7350      1179\n","    B-SYMPTOM     0.6765    0.4600    0.5476        50\n","    I-SYMPTOM     1.0000    0.0750    0.1395        80\n","       B-SIGN     0.5318    0.5106    0.5210       803\n","       I-SIGN     0.5807    0.4614    0.5142      2215\n","\n","    micro avg     0.6687    0.5369    0.5956      6243\n","    macro avg     0.7336    0.4757    0.5426      6243\n"," weighted avg     0.6784    0.5369    0.5934      6243\n","\n","B-DISEASE\t&\t0.7600\t&\t0.4718\t&\t0.5822\t&\t443\\\\\n","I-DISEASE\t&\t0.7546\t&\t0.5150\t&\t0.6122\t&\t400\\\\\n","B-RAREDISEASE\t&\t0.7163\t&\t0.6636\t&\t0.6889\t&\t1073\\\\\n","I-RAREDISEASE\t&\t0.8489\t&\t0.6480\t&\t0.7350\t&\t1179\\\\\n","B-SYMPTOM\t&\t0.6765\t&\t0.4600\t&\t0.5476\t&\t50\\\\\n","I-SYMPTOM\t&\t1.0000\t&\t0.0750\t&\t0.1395\t&\t80\\\\\n","B-SIGN\t&\t0.5318\t&\t0.5106\t&\t0.5210\t&\t803\\\\\n","I-SIGN\t&\t0.5807\t&\t0.4614\t&\t0.5142\t&\t2215\\\\\n","micro-avg\t&\t0.6687\t&\t0.5369\t&\t0.5956\t&\t6243\\\\\n","macro-avg\t&\t0.7336\t&\t0.4757\t&\t0.5426\t&\t6243\\\\\n","\\hline %weighted-avg\t&\t0.6784\t&\t0.5369\t&\t0.5934\t&\t6243\\\\\n","Scores were saved to path: /content/drive/My Drive/Colab Notebooks/ner/scores/en/BILSTM-wikipedia-epochs:20-batchsize:64-dimembeding:200-units:100-date:2021-07-08-sTypes:_all.txt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"V8iNsNtXJ4bV"},"source":["We now obtain the results at the level of entity. To do this, we use the seqeval library"]},{"cell_type":"code","metadata":{"id":"jnEtQwzGL16x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625741326492,"user_tz":-120,"elapsed":5475,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"a1ff42b7-13be-4214-8b6e-a6ee3ba5078c"},"source":["!pip install seqeval\n","from seqeval.metrics import classification_report\n","from seqeval.scheme import IOB2\n","#IOB2: It is same as IOB, except that the B- tag is used in the beginning of every chunk (i.e. all chunks start with the B- tag).\n","\n","f=open(file_scores, \"a\")\n","\n","report = classification_report(no_padded_y_gold, no_padded_y_pred, scheme=IOB2, digits=4)\n","f.write('BiLSTM results on entity (approximate):\\n')\n","print('BiLSTM results on entity (approximate):')\n","print('Language:'+ LANG+ '\\n')\n","print(report)\n","\n","data=report.split('\\n')\n","for line in data:\n","    if len(line.strip())==0 or 'precision' in line:\n","        pass\n","    else:\n","        if ' avg' in line:\n","            line=line.replace(' avg','-avg')\n","        line=line.strip()\n","        line=' '.join(line.split())\n","\n","        line=line.replace(' ','\\t&\\t')+'\\\\\\\\'\n","        if line.startswith('weighted'):\n","            line='\\hline%'+line\n","        print(line)\n","        f.write(line)\n","\n","f.close() \n","print('Scores were saved to path: ' + file_scores)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\r\u001b[K     |███████▌                        | 10kB 22.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 22.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 15.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16184 sha256=8a8cd65aedf2092ba59bcbb86a08a49fd92b0937036d4c6fbdb153f35e563ea4\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["BiLSTM results on entity (approximate):\n","Language:en\n","\n","              precision    recall  f1-score   support\n","\n","          AD     0.0000    0.0000    0.0000         0\n","     DISEASE     0.5794    0.4339    0.4962       454\n"," RAREDISEASE     0.5378    0.5388    0.5383      1095\n","        SIGN     0.3167    0.3570    0.3356       958\n","     SYMPTOM     0.5946    0.4074    0.4835        54\n","\n","   micro avg     0.4170    0.4494    0.4326      2561\n","   macro avg     0.4057    0.3474    0.3707      2561\n","weighted avg     0.4637    0.4494    0.4539      2561\n","\n","AD\t&\t0.0000\t&\t0.0000\t&\t0.0000\t&\t0\\\\\n","DISEASE\t&\t0.5794\t&\t0.4339\t&\t0.4962\t&\t454\\\\\n","RAREDISEASE\t&\t0.5378\t&\t0.5388\t&\t0.5383\t&\t1095\\\\\n","SIGN\t&\t0.3167\t&\t0.3570\t&\t0.3356\t&\t958\\\\\n","SYMPTOM\t&\t0.5946\t&\t0.4074\t&\t0.4835\t&\t54\\\\\n","micro-avg\t&\t0.4170\t&\t0.4494\t&\t0.4326\t&\t2561\\\\\n","macro-avg\t&\t0.4057\t&\t0.3474\t&\t0.3707\t&\t2561\\\\\n","\\hline%weighted-avg\t&\t0.4637\t&\t0.4494\t&\t0.4539\t&\t2561\\\\\n","Scores were saved to path: /content/drive/My Drive/Colab Notebooks/ner/scores/en/BILSTM-wikipedia-epochs:20-batchsize:64-dimembeding:200-units:100-date:2021-07-08-sTypes:_all.txt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XwVVI4lb8qNt"},"source":["Scenarios:\n","\n","    - I. Surface string and entity type match\n","    - II. System hypothesized an entity\n","    - III. System misses an entity\n","    - IV. System assigns the wrong entity type\n","    - V. System gets the boundaries of the surface string wrong\n","    - VI. System gets the boundaries and entity type wrong\n","\n","MUC metrics:\n","\n","    - Correct (COR) : both are the same\n","    - Incorrect (INC) : the output of a system and the golden annotation don’t match\n","    - Partial (PAR) : system and the golden annotation are somewhat “similar” but not the same\n","    - Missing (MIS) : a golden annotation is not captured by a system\n","    - Spurius (SPU) : system produces a response which doesn’t exist in the golden annotation\n","\n","Four different ways to measure precision/recall/f1-score:\n","\n","    - Strict: exact boundary surface string match and entity type\n","    - Exact: exact boundary match over the surface string, regardless of the type\n","    - Partial: partial boundary match over the surface string, regardless of the type\n","    - Type: some overlap between the system tagged entity and the gold annotation is required"]},{"cell_type":"code","metadata":{"id":"NTVZZLDx8oqk"},"source":["import logging\n","from collections import namedtuple\n","from copy import deepcopy\n","\n","logging.basicConfig(\n","    format=\"%(asctime)s %(name)s %(levelname)s: %(message)s\",\n","    datefmt=\"%Y-%m-%d %H:%M:%S\",\n","    level=\"DEBUG\",\n",")\n","\n","Entity = namedtuple(\"Entity\", \"e_type start_offset end_offset\")\n","\n","class Evaluator():\n","\n","    def __init__(self, true, pred, tags):\n","        \"\"\"\n","        \"\"\"\n","\n","        if len(true) != len(pred):\n","            raise ValueError(\"Number of predicted documents does not equal true\")\n","\n","        self.true = true\n","        self.pred = pred\n","        self.tags = tags\n","\n","        # Setup dict into which metrics will be stored.\n","\n","        self.metrics_results = {\n","            'correct': 0,\n","            'incorrect': 0,\n","            'partial': 0,\n","            'missed': 0,\n","            'spurious': 0,\n","            'possible': 0,\n","            'actual': 0,\n","            'precision': 0,\n","            'recall': 0,\n","        }\n","\n","        # Copy results dict to cover the four schemes.\n","\n","        self.results = {\n","            'strict': deepcopy(self.metrics_results),\n","            'ent_type': deepcopy(self.metrics_results),\n","            'partial':deepcopy(self.metrics_results),\n","            'exact':deepcopy(self.metrics_results),\n","            }\n","\n","        # Create an accumulator to store results\n","\n","        self.evaluation_agg_entities_type = {e: deepcopy(self.results) for e in tags}\n","\n","\n","    def evaluate(self):\n","\n","        logging.info(\n","            \"Imported %s predictions for %s true examples\",\n","            len(self.pred), len(self.true)\n","        )\n","\n","        for true_ents, pred_ents in zip(self.true, self.pred):\n","\n","            # Check that the length of the true and predicted examples are the\n","            # same. This must be checked here, because another error may not\n","            # be thrown if the lengths do not match.\n","\n","            if len(true_ents) != len(pred_ents):\n","                raise ValueError(\"Prediction length does not match true example length\")\n","\n","            # Compute results for one message\n","\n","            tmp_results, tmp_agg_results = compute_metrics(\n","                collect_named_entities(true_ents),\n","                collect_named_entities(pred_ents),\n","                self.tags\n","            )\n","\n","            # Cycle through each result and accumulate\n","\n","            # TODO: Combine these loops below:\n","\n","            for eval_schema in self.results:\n","\n","                for metric in self.results[eval_schema]:\n","\n","                    self.results[eval_schema][metric] += tmp_results[eval_schema][metric]\n","\n","            # Calculate global precision and recall\n","\n","            self.results = compute_precision_recall_wrapper(self.results)\n","\n","            # Aggregate results by entity type\n","\n","            for e_type in self.tags:\n","\n","                for eval_schema in tmp_agg_results[e_type]:\n","\n","                    for metric in tmp_agg_results[e_type][eval_schema]:\n","\n","                        self.evaluation_agg_entities_type[e_type][eval_schema][metric] += tmp_agg_results[e_type][eval_schema][metric]\n","\n","                # Calculate precision recall at the individual entity level\n","\n","                self.evaluation_agg_entities_type[e_type] = compute_precision_recall_wrapper(self.evaluation_agg_entities_type[e_type])\n","\n","        return self.results, self.evaluation_agg_entities_type\n","\n","\n","def collect_named_entities(tokens):\n","    \"\"\"\n","    Creates a list of Entity named-tuples, storing the entity type and the start and end\n","    offsets of the entity.\n","    :param tokens: a list of tags\n","    :return: a list of Entity named-tuples\n","    \"\"\"\n","\n","    named_entities = []\n","    start_offset = None\n","    end_offset = None\n","    ent_type = None\n","\n","    for offset, token_tag in enumerate(tokens):\n","\n","        if token_tag == 'O':\n","            if ent_type is not None and start_offset is not None:\n","                end_offset = offset - 1\n","                named_entities.append(Entity(ent_type, start_offset, end_offset))\n","                start_offset = None\n","                end_offset = None\n","                ent_type = None\n","\n","        elif ent_type is None:\n","            ent_type = token_tag[2:]\n","            start_offset = offset\n","\n","        elif ent_type != token_tag[2:] or (ent_type == token_tag[2:] and token_tag[:1] == 'B'):\n","\n","            end_offset = offset - 1\n","            named_entities.append(Entity(ent_type, start_offset, end_offset))\n","\n","            # start of a new entity\n","            ent_type = token_tag[2:]\n","            start_offset = offset\n","            end_offset = None\n","\n","    # catches an entity that goes up until the last token\n","\n","    if ent_type is not None and start_offset is not None and end_offset is None:\n","        named_entities.append(Entity(ent_type, start_offset, len(tokens)-1))\n","\n","    return named_entities\n","\n","\n","def compute_metrics(true_named_entities, pred_named_entities, tags):\n","\n","\n","    eval_metrics = {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'precision': 0, 'recall': 0}\n","\n","    # overall results\n","    \n","    evaluation = {\n","        'strict': deepcopy(eval_metrics),\n","        'ent_type': deepcopy(eval_metrics),\n","        'partial': deepcopy(eval_metrics),\n","        'exact': deepcopy(eval_metrics)\n","    }\n","\n","    # results by entity type\n","\n","    evaluation_agg_entities_type = {e: deepcopy(evaluation) for e in tags}\n","\n","    # keep track of entities that overlapped\n","\n","    true_which_overlapped_with_pred = []\n","\n","    # Subset into only the tags that we are interested in.\n","    # NOTE: we remove the tags we don't want from both the predicted and the\n","    # true entities. This covers the two cases where mismatches can occur:\n","    #\n","    # 1) Where the model predicts a tag that is not present in the true data\n","    # 2) Where there is a tag in the true data that the model is not capable of\n","    # predicting.\n","\n","    true_named_entities = [ent for ent in true_named_entities if ent.e_type in tags]\n","    pred_named_entities = [ent for ent in pred_named_entities if ent.e_type in tags]\n","\n","    # go through each predicted named-entity\n","\n","    for pred in pred_named_entities:\n","        found_overlap = False\n","\n","        # Check each of the potential scenarios in turn. See\n","        # http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/\n","        # for scenario explanation.\n","\n","        # Scenario I: Exact match between true and pred\n","\n","        if pred in true_named_entities:\n","            true_which_overlapped_with_pred.append(pred)\n","            evaluation['strict']['correct'] += 1\n","            evaluation['ent_type']['correct'] += 1\n","            evaluation['exact']['correct'] += 1\n","            evaluation['partial']['correct'] += 1\n","\n","            # for the agg. by e_type results\n","            evaluation_agg_entities_type[pred.e_type]['strict']['correct'] += 1\n","            evaluation_agg_entities_type[pred.e_type]['ent_type']['correct'] += 1\n","            evaluation_agg_entities_type[pred.e_type]['exact']['correct'] += 1\n","            evaluation_agg_entities_type[pred.e_type]['partial']['correct'] += 1\n","\n","        else:\n","\n","            # check for overlaps with any of the true entities\n","\n","            for true in true_named_entities:\n","\n","                pred_range = range(pred.start_offset, pred.end_offset)\n","                true_range = range(true.start_offset, true.end_offset)\n","\n","                # Scenario IV: Offsets match, but entity type is wrong\n","\n","                if true.start_offset == pred.start_offset and pred.end_offset == true.end_offset \\\n","                        and true.e_type != pred.e_type:\n","\n","                    # overall results\n","                    evaluation['strict']['incorrect'] += 1\n","                    evaluation['ent_type']['incorrect'] += 1\n","                    evaluation['partial']['correct'] += 1\n","                    evaluation['exact']['correct'] += 1\n","\n","                    # aggregated by entity type results\n","                    evaluation_agg_entities_type[true.e_type]['strict']['incorrect'] += 1\n","                    evaluation_agg_entities_type[true.e_type]['ent_type']['incorrect'] += 1\n","                    evaluation_agg_entities_type[true.e_type]['partial']['correct'] += 1\n","                    evaluation_agg_entities_type[true.e_type]['exact']['correct'] += 1\n","\n","                    true_which_overlapped_with_pred.append(true)\n","                    found_overlap = True\n","\n","                    break\n","\n","                # check for an overlap i.e. not exact boundary match, with true entities\n","\n","                elif find_overlap(true_range, pred_range):\n","\n","                    true_which_overlapped_with_pred.append(true)\n","\n","                    # Scenario V: There is an overlap (but offsets do not match\n","                    # exactly), and the entity type is the same.\n","                    # 2.1 overlaps with the same entity type\n","\n","                    if pred.e_type == true.e_type:\n","\n","                        # overall results\n","                        evaluation['strict']['incorrect'] += 1\n","                        evaluation['ent_type']['correct'] += 1\n","                        evaluation['partial']['partial'] += 1\n","                        evaluation['exact']['incorrect'] += 1\n","\n","                        # aggregated by entity type results\n","                        evaluation_agg_entities_type[true.e_type]['strict']['incorrect'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['ent_type']['correct'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['partial']['partial'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['exact']['incorrect'] += 1\n","\n","                        found_overlap = True\n","\n","                        break\n","\n","                    # Scenario VI: Entities overlap, but the entity type is\n","                    # different.\n","\n","                    else:\n","                        # overall results\n","                        evaluation['strict']['incorrect'] += 1\n","                        evaluation['ent_type']['incorrect'] += 1\n","                        evaluation['partial']['partial'] += 1\n","                        evaluation['exact']['incorrect'] += 1\n","\n","                        # aggregated by entity type results\n","                        # Results against the true entity\n","\n","                        evaluation_agg_entities_type[true.e_type]['strict']['incorrect'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['partial']['partial'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['ent_type']['incorrect'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['exact']['incorrect'] += 1\n","\n","                        # Results against the predicted entity\n","\n","                        # evaluation_agg_entities_type[pred.e_type]['strict']['spurious'] += 1\n","\n","                        found_overlap = True\n","\n","                        break\n","\n","            # Scenario II: Entities are spurious (i.e., over-generated).\n","\n","            if not found_overlap:\n","\n","                # Overall results\n","\n","                evaluation['strict']['spurious'] += 1\n","                evaluation['ent_type']['spurious'] += 1\n","                evaluation['partial']['spurious'] += 1\n","                evaluation['exact']['spurious'] += 1\n","\n","                # Aggregated by entity type results\n","\n","                # NOTE: when pred.e_type is not found in tags\n","                # or when it simply does not appear in the test set, then it is\n","                # spurious, but it is not clear where to assign it at the tag\n","                # level. In this case, it is applied to all target_tags\n","                # found in this example. This will mean that the sum of the\n","                # evaluation_agg_entities will not equal evaluation.\n","\n","                for true in tags:                    \n","\n","                    evaluation_agg_entities_type[true]['strict']['spurious'] += 1\n","                    evaluation_agg_entities_type[true]['ent_type']['spurious'] += 1\n","                    evaluation_agg_entities_type[true]['partial']['spurious'] += 1\n","                    evaluation_agg_entities_type[true]['exact']['spurious'] += 1\n","\n","    # Scenario III: Entity was missed entirely.\n","\n","    for true in true_named_entities:\n","        if true in true_which_overlapped_with_pred:\n","            continue\n","        else:\n","            # overall results\n","            evaluation['strict']['missed'] += 1\n","            evaluation['ent_type']['missed'] += 1\n","            evaluation['partial']['missed'] += 1\n","            evaluation['exact']['missed'] += 1\n","\n","            # for the agg. by e_type\n","            evaluation_agg_entities_type[true.e_type]['strict']['missed'] += 1\n","            evaluation_agg_entities_type[true.e_type]['ent_type']['missed'] += 1\n","            evaluation_agg_entities_type[true.e_type]['partial']['missed'] += 1\n","            evaluation_agg_entities_type[true.e_type]['exact']['missed'] += 1\n","\n","    # Compute 'possible', 'actual' according to SemEval-2013 Task 9.1 on the\n","    # overall results, and use these to calculate precision and recall.\n","\n","    for eval_type in evaluation:\n","        evaluation[eval_type] = compute_actual_possible(evaluation[eval_type])\n","\n","    # Compute 'possible', 'actual', and precision and recall on entity level\n","    # results. Start by cycling through the accumulated results.\n","\n","    for entity_type, entity_level in evaluation_agg_entities_type.items():\n","\n","        # Cycle through the evaluation types for each dict containing entity\n","        # level results.\n","\n","        for eval_type in entity_level:\n","\n","            evaluation_agg_entities_type[entity_type][eval_type] = compute_actual_possible(\n","                entity_level[eval_type]\n","            )\n","\n","    return evaluation, evaluation_agg_entities_type\n","\n","\n","def find_overlap(true_range, pred_range):\n","    \"\"\"Find the overlap between two ranges\n","    Find the overlap between two ranges. Return the overlapping values if\n","    present, else return an empty set().\n","    Examples:\n","    >>> find_overlap((1, 2), (2, 3))\n","    2\n","    >>> find_overlap((1, 2), (3, 4))\n","    set()\n","    \"\"\"\n","\n","    true_set = set(true_range)\n","    pred_set = set(pred_range)\n","\n","    overlaps = true_set.intersection(pred_set)\n","\n","    return overlaps\n","\n","\n","def compute_actual_possible(results):\n","    \"\"\"\n","    Takes a result dict that has been output by compute metrics.\n","    Returns the results dict with actual, possible populated.\n","    When the results dicts is from partial or ent_type metrics, then\n","    partial_or_type=True to ensure the right calculation is used for\n","    calculating precision and recall.\n","    \"\"\"\n","\n","    correct = results['correct']\n","    incorrect = results['incorrect']\n","    partial = results['partial']\n","    missed = results['missed']\n","    spurious = results['spurious']\n","\n","    # Possible: number annotations in the gold-standard which contribute to the\n","    # final score\n","\n","    possible = correct + incorrect + partial + missed\n","\n","    # Actual: number of annotations produced by the NER system\n","\n","    actual = correct + incorrect + partial + spurious\n","\n","    results[\"actual\"] = actual\n","    results[\"possible\"] = possible\n","\n","    return results\n","\n","\n","def compute_precision_recall(results, partial_or_type=False):\n","    \"\"\"\n","    Takes a result dict that has been output by compute metrics.\n","    Returns the results dict with precison and recall populated.\n","    When the results dicts is from partial or ent_type metrics, then\n","    partial_or_type=True to ensure the right calculation is used for\n","    calculating precision and recall.\n","    \"\"\"\n","\n","    actual = results[\"actual\"]\n","    possible = results[\"possible\"]\n","    partial = results['partial']\n","    correct = results['correct']\n","\n","    if partial_or_type:\n","        precision = (correct + 0.5 * partial) / actual if actual > 0 else 0\n","        recall = (correct + 0.5 * partial) / possible if possible > 0 else 0\n","\n","    else:\n","        precision = correct / actual if actual > 0 else 0\n","        recall = correct / possible if possible > 0 else 0\n","\n","    results[\"precision\"] = precision\n","    results[\"recall\"] = recall\n","\n","    return results\n","\n","\n","def compute_precision_recall_wrapper(results):\n","    \"\"\"\n","    Wraps the compute_precision_recall function and runs on a dict of results\n","    \"\"\"\n","\n","    results_a = {key: compute_precision_recall(value, True) for key, value in results.items() if\n","                 key in ['partial', 'ent_type']}\n","    results_b = {key: compute_precision_recall(value) for key, value in results.items() if\n","                 key in ['strict', 'exact']}\n","\n","    results = {**results_a, **results_b}\n","\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NQ1rhjz580rC","executionInfo":{"status":"ok","timestamp":1625741370257,"user_tz":-120,"elapsed":567,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"48badc9c-0464-4dbd-ed21-aaea8a036914"},"source":["random_df = df_test[['Sentence #','Word','POS','Tag']].copy()\n","# Getting full sentences\n","getter_random = SentenceGetter(random_df)\n","sentences_random = getter_random.sentences\n","\n","import random\n","\n","random.seed(42)\n","result_examples_idx = random.sample(range(len(no_padded_y_gold)), k=10)\n","result_examples_y_gold = list()\n","result_examples_y_pred = list()\n","original_sentences = list()\n","\n","for idx in result_examples_idx:\n","    result_examples_y_gold.append(no_padded_y_gold[idx])\n","    result_examples_y_pred.append(no_padded_y_pred[idx])\n","    original_sentences.append(sentences_random[idx])\n","\n","itr = 0\n","for g, p, s in zip(result_examples_y_gold, result_examples_y_pred, original_sentences):\n","    assert len(g) == len(p), 'Results does not seem to be the same'\n","    print('Sentence Nr: ', result_examples_idx[itr])\n","    original_s = pd.Series(s, name='WORD')\n","    df = pd.DataFrame(original_s)\n","    df['GOLD'] = g\n","    df['PRED'] = p\n","    print(df)\n","    itr += 1\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sentence Nr:  1309\n","                            WORD           GOLD           PRED\n","0                  (The, DET, O)              O              O\n","1            (symptoms, NOUN, O)              O              O\n","2                (and, CCONJ, O)              O              O\n","3                  (the, DET, O)              O              O\n","4             (physical, ADJ, O)              O              O\n","5            (findings, NOUN, O)              O              O\n","6          (associated, VERB, O)              O              O\n","7                 (with, ADP, O)              O              O\n","8   (ASLD, PROPN, B-RAREDISEASE)  B-RAREDISEASE  B-RAREDISEASE\n","9                (vary, VERB, O)              O              O\n","10             (greatly, ADV, O)              O              O\n","11                (from, ADP, O)              O              O\n","12               (case, NOUN, O)              O              O\n","13                  (to, ADP, O)              O              O\n","14               (case, NOUN, O)              O              O\n","15                 (., PUNCT, O)              O              O\n","\n","Sentence Nr:  228\n","                    WORD GOLD PRED\n","0       (There, PRON, O)    O    O\n","1          (are, AUX, O)    O    O\n","2           (no, DET, O)    O    O\n","3       (blood, NOUN, O)    O    O\n","4       (tests, NOUN, O)    O    O\n","5         (or, CCONJ, O)    O    O\n","6        (skin, NOUN, O)    O    O\n","7       (tests, NOUN, O)    O    O\n","8           (at, ADP, O)    O    O\n","9          (the, DET, O)    O    O\n","10     (present, ADJ, O)    O    O\n","11       (time, NOUN, O)    O    O\n","12        (that, DET, O)    O    O\n","13         (are, AUX, O)    O    O\n","14     (helpful, ADJ, O)    O    O\n","15          (in, ADP, O)    O    O\n","16         (the, DET, O)    O    O\n","17  (diagnosis, NOUN, O)    O    O\n","18         (., PUNCT, O)    O    O\n","\n","Sentence Nr:  51\n","                       WORD    GOLD PRED\n","0             (The, DET, O)       O    O\n","1       (disorder, NOUN, O)       O    O\n","2            (may, VERB, O)       O    O\n","3              (be, AUX, O)       O    O\n","4     (recognized, VERB, O)       O    O\n","5            (more, ADV, O)       O    O\n","6         (readily, ADV, O)       O    O\n","7              (in, ADP, O)       O    O\n","8        (females, NOUN, O)       O    O\n","9       (because, SCONJ, O)       O    O\n","10             (of, ADP, O)       O    O\n","11            (the, DET, O)       O    O\n","12   (development, NOUN, O)       O    O\n","13             (of, ADP, O)       O    O\n","14   (uterine, ADJ, B-SIGN)  B-SIGN    O\n","15  (fibroid, NOUN, I-SIGN)  I-SIGN    O\n","16          (and, CCONJ, O)       O    O\n","17     (associated, ADJ, O)       O    O\n","18      (symptoms, NOUN, O)       O    O\n","19            (., PUNCT, O)       O    O\n","\n","Sentence Nr:  1518\n","                               WORD           GOLD PRED\n","0                 (While, SCONJ, O)              O    O\n","1                     (the, DET, O)              O    O\n","2               (features, NOUN, O)              O    O\n","3                     (for, ADP, O)              O    O\n","4   (trisomy, PROPN, B-RAREDISEASE)  B-RAREDISEASE    O\n","5          (5p, NUM, I-RAREDISEASE)  I-RAREDISEASE    O\n","6                 (appear, VERB, O)              O    O\n","7              (consistent, ADJ, O)              O    O\n","8                     (,, PUNCT, O)              O    O\n","9                     (the, DET, O)              O    O\n","10             (diagnosis, NOUN, O)              O    O\n","11                   (can, VERB, O)              O    O\n","12                   (not, PART, O)              O    O\n","13                     (be, AUX, O)              O    O\n","14                  (made, VERB, O)              O    O\n","15                     (on, ADP, O)              O    O\n","16               (clinical, ADJ, O)              O    O\n","17              (features, NOUN, O)              O    O\n","18                  (alone, ADV, O)              O    O\n","19                    (., PUNCT, O)              O    O\n","\n","Sentence Nr:  563\n","                              WORD       GOLD       PRED\n","0                  (Other, ADJ, O)          O          O\n","1              (symptoms, NOUN, O)          O          O\n","2                   (may, VERB, O)          O          O\n","3               (include, VERB, O)          O          O\n","4         (mental, ADJ, B-DISEASE)  B-DISEASE  B-DISEASE\n","5   (retardation, NOUN, I-DISEASE)  I-DISEASE  I-DISEASE\n","6                    (,, PUNCT, O)          O          O\n","7           (speech, NOUN, B-SIGN)     B-SIGN     B-SIGN\n","8         (problems, NOUN, I-SIGN)     I-SIGN     I-SIGN\n","9                    (,, PUNCT, O)          O          O\n","10            (bone, NOUN, B-SIGN)     B-SIGN     B-SIGN\n","11     (deformities, NOUN, I-SIGN)     I-SIGN     I-SIGN\n","12               (of, ADP, I-SIGN)     I-SIGN     I-SIGN\n","13              (the, DET, I-SIGN)     I-SIGN     I-SIGN\n","14            (arms, NOUN, I-SIGN)     I-SIGN     I-SIGN\n","15                 (and, CCONJ, O)          O          O\n","16            (legs, NOUN, I-SIGN)     I-SIGN     I-SIGN\n","17                   (,, PUNCT, O)          O          O\n","18              (and/or, CCONJ, O)          O          O\n","19        (seizures, NOUN, B-SIGN)     B-SIGN     B-SIGN\n","20                   (., PUNCT, O)          O          O\n","\n","Sentence Nr:  501\n","                          WORD       GOLD           PRED\n","0                (The, DET, O)          O              O\n","1         (diagnosis, NOUN, O)          O              O\n","2                 (of, ADP, O)          O              O\n","3    (Paget, PROPN, B-DISEASE)  B-DISEASE  B-RAREDISEASE\n","4        (’s, PART, I-DISEASE)  I-DISEASE  I-RAREDISEASE\n","5   (disease, NOUN, I-DISEASE)  I-DISEASE  I-RAREDISEASE\n","6               (may, VERB, O)          O              O\n","7                 (be, AUX, O)          O              O\n","8         (confirmed, VERB, O)          O              O\n","9                 (by, ADP, O)          O              O\n","10                 (a, DET, O)          O              O\n","11          (thorough, ADJ, O)          O              O\n","12          (clinical, ADJ, O)          O              O\n","13       (evaluation, NOUN, O)          O              O\n","14               (,, PUNCT, O)          O              O\n","15          (detailed, ADJ, O)          O              O\n","16          (patient, NOUN, O)          O              O\n","17          (history, NOUN, O)          O              O\n","18               (,, PUNCT, O)          O              O\n","19             (and, CCONJ, O)          O              O\n","20                 (a, DET, O)          O              O\n","21          (variety, NOUN, O)          O              O\n","22                (of, ADP, O)          O              O\n","23       (specialized, ADJ, O)          O              O\n","24            (tests, NOUN, O)          O              O\n","25               (,, PUNCT, O)          O              O\n","26              (such, ADJ, O)          O              O\n","27              (as, SCONJ, O)          O              O\n","28            (blood, NOUN, O)          O              O\n","29            (tests, NOUN, O)          O              O\n","30               (,, PUNCT, O)          O              O\n","31                (x, NOUN, O)          O              O\n","32                (-, NOUN, O)          O              O\n","33             (rays, NOUN, O)          O              O\n","34               (,, PUNCT, O)          O              O\n","35             (and, CCONJ, O)          O              O\n","36            (urine, NOUN, O)          O              O\n","37            (tests, NOUN, O)          O              O\n","38               (., PUNCT, O)          O              O\n","\n","Sentence Nr:  457\n","                          WORD       GOLD           PRED\n","0    (Paget, PROPN, B-DISEASE)  B-DISEASE  B-RAREDISEASE\n","1        (’s, PART, I-DISEASE)  I-DISEASE  I-RAREDISEASE\n","2   (disease, NOUN, I-DISEASE)  I-DISEASE  I-RAREDISEASE\n","3           (affects, VERB, O)          O              O\n","4       (individuals, NOUN, O)          O              O\n","5                 (of, ADP, O)          O              O\n","6                (all, DET, O)          O              O\n","7             (ethnic, ADJ, O)          O              O\n","8              (and, CCONJ, O)          O              O\n","9             (racial, ADJ, O)          O              O\n","10           (groups, NOUN, O)          O              O\n","11               (., PUNCT, O)          O              O\n","\n","Sentence Nr:  285\n","                                   WORD           GOLD           PRED\n","0                       (First, ADV, O)              O              O\n","1                  (described, VERB, O)              O              O\n","2                          (in, ADP, O)              O              O\n","3                         (the, DET, O)              O              O\n","4                     (medical, ADJ, O)              O              O\n","5                 (literature, NOUN, O)              O              O\n","6                          (in, ADP, O)              O              O\n","7                        (1906, NUM, O)              O              O\n","8                         (,, PUNCT, O)              O              O\n","9   (dyskeratosis, NOUN, B-RAREDISEASE)  B-RAREDISEASE  B-RAREDISEASE\n","10    (congenita, PROPN, I-RAREDISEASE)  I-RAREDISEASE  I-RAREDISEASE\n","11                        (was, AUX, O)              O              O\n","12                 (originally, ADV, O)              O              O\n","13                   (thought, VERB, O)              O              O\n","14                        (to, PART, O)              O              O\n","15                         (be, AUX, O)              O              O\n","16                          (a, DET, O)              O              O\n","17              (skin, NOUN, B-DISEASE)      B-DISEASE              O\n","18           (disease, NOUN, I-DISEASE)      I-DISEASE              O\n","19                       (that, DET, O)              O              O\n","20                       (also, ADV, O)              O              O\n","21                   (affects, VERB, O)              O              O\n","22                        (the, DET, O)              O              O\n","23                     (nails, NOUN, O)              O              O\n","24                      (and, CCONJ, O)              O              O\n","25                        (the, DET, O)              O              O\n","26                     (mouth, NOUN, O)              O              O\n","27                        (., PUNCT, O)              O              O\n","\n","Sentence Nr:  1508\n","                       WORD GOLD    PRED\n","0            (Many, ADJ, O)    O       O\n","1          (cases, NOUN, O)    O       O\n","2             (are, AUX, O)    O       O\n","3   (misdiagnosed, VERB, O)    O       O\n","4            (or, CCONJ, O)    O       O\n","5    (undiagnosed, VERB, O)    O       O\n","6             (,, PUNCT, O)    O       O\n","7      (especially, ADV, O)    O       O\n","8              (in, ADP, O)    O       O\n","9       (children, NOUN, O)    O       O\n","10           (with, ADP, O)    O       O\n","11          (fewer, ADJ, O)    O       O\n","12      (problems, NOUN, O)    O  I-SIGN\n","13            (., PUNCT, O)    O       O\n","\n","Sentence Nr:  209\n","                            WORD           GOLD           PRED\n","0                  (The, DET, O)              O              O\n","1               (birth, NOUN, O)              O              O\n","2          (prevalence, NOUN, O)              O              O\n","3                   (of, ADP, O)              O              O\n","4   (LHON, PROPN, B-RAREDISEASE)  B-RAREDISEASE  B-RAREDISEASE\n","5                   (is, AUX, O)              O              O\n","6        (approximately, ADV, O)              O              O\n","7                    (1, NUM, O)              O              O\n","8                   (in, ADP, O)              O              O\n","9               (50,000, NUM, O)              O              O\n","10             (people, NOUN, O)              O              O\n","11                 (., PUNCT, O)              O              O\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9gz5IiK82d-","executionInfo":{"status":"ok","timestamp":1625741376920,"user_tz":-120,"elapsed":219,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"13a3ff53-e65d-4462-905d-6bd5f4019bc7"},"source":["if allTypes:\n","    test_labels = ['DISEASE', 'RAREDISEASE', 'SYMPTOM', 'SIGN']\n","else:\n","    test_labels = ['RAREDISEASE', 'SIGN-SYM']\n","\n","test_to_use_gold = result_examples_y_gold\n","test_to_use_pred = result_examples_y_pred\n","\n","evaluator_examples = Evaluator(test_to_use_gold, test_to_use_pred, test_labels)\n","results_examples, results_agg_examples = evaluator_examples.evaluate()\n","\n","print('## OVERALL RESULTS')\n","for item in results_examples.keys():\n","    print('\\tEvaluation Metric: ', item)\n","    print('\\t', results_examples[item])\n","print('## RESULTS AT ENTITY LEVEL')\n","for entity in results_agg_examples.keys():\n","    print('Entity: ', entity)\n","    for item in results_agg_examples[entity].keys():\n","        print('\\tEvaluation Metric: ', item)\n","        print('\\t', results_agg_examples[entity][item])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-07-08 10:49:36 root INFO: Imported 10 predictions for 10 true examples\n"],"name":"stderr"},{"output_type":"stream","text":["## OVERALL RESULTS\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 8, 'incorrect': 2, 'partial': 0, 'missed': 3, 'spurious': 1, 'possible': 13, 'actual': 11, 'precision': 0.7272727272727273, 'recall': 0.6153846153846154}\n","\tEvaluation Metric:  partial\n","\t {'correct': 10, 'incorrect': 0, 'partial': 0, 'missed': 3, 'spurious': 1, 'possible': 13, 'actual': 11, 'precision': 0.9090909090909091, 'recall': 0.7692307692307693}\n","\tEvaluation Metric:  strict\n","\t {'correct': 8, 'incorrect': 2, 'partial': 0, 'missed': 3, 'spurious': 1, 'possible': 13, 'actual': 11, 'precision': 0.7272727272727273, 'recall': 0.6153846153846154}\n","\tEvaluation Metric:  exact\n","\t {'correct': 10, 'incorrect': 0, 'partial': 0, 'missed': 3, 'spurious': 1, 'possible': 13, 'actual': 11, 'precision': 0.9090909090909091, 'recall': 0.7692307692307693}\n","## RESULTS AT ENTITY LEVEL\n","Entity:  DISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 1, 'incorrect': 2, 'partial': 0, 'missed': 1, 'spurious': 1, 'possible': 4, 'actual': 4, 'precision': 0.25, 'recall': 0.25}\n","\tEvaluation Metric:  partial\n","\t {'correct': 3, 'incorrect': 0, 'partial': 0, 'missed': 1, 'spurious': 1, 'possible': 4, 'actual': 4, 'precision': 0.75, 'recall': 0.75}\n","\tEvaluation Metric:  strict\n","\t {'correct': 1, 'incorrect': 2, 'partial': 0, 'missed': 1, 'spurious': 1, 'possible': 4, 'actual': 4, 'precision': 0.25, 'recall': 0.25}\n","\tEvaluation Metric:  exact\n","\t {'correct': 3, 'incorrect': 0, 'partial': 0, 'missed': 1, 'spurious': 1, 'possible': 4, 'actual': 4, 'precision': 0.75, 'recall': 0.75}\n","Entity:  RAREDISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 3, 'incorrect': 0, 'partial': 0, 'missed': 1, 'spurious': 1, 'possible': 4, 'actual': 4, 'precision': 0.75, 'recall': 0.75}\n","\tEvaluation Metric:  partial\n","\t {'correct': 3, 'incorrect': 0, 'partial': 0, 'missed': 1, 'spurious': 1, 'possible': 4, 'actual': 4, 'precision': 0.75, 'recall': 0.75}\n","\tEvaluation Metric:  strict\n","\t {'correct': 3, 'incorrect': 0, 'partial': 0, 'missed': 1, 'spurious': 1, 'possible': 4, 'actual': 4, 'precision': 0.75, 'recall': 0.75}\n","\tEvaluation Metric:  exact\n","\t {'correct': 3, 'incorrect': 0, 'partial': 0, 'missed': 1, 'spurious': 1, 'possible': 4, 'actual': 4, 'precision': 0.75, 'recall': 0.75}\n","Entity:  SYMPTOM\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 1, 'possible': 0, 'actual': 1, 'precision': 0.0, 'recall': 0}\n","\tEvaluation Metric:  partial\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 1, 'possible': 0, 'actual': 1, 'precision': 0.0, 'recall': 0}\n","\tEvaluation Metric:  strict\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 1, 'possible': 0, 'actual': 1, 'precision': 0.0, 'recall': 0}\n","\tEvaluation Metric:  exact\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 1, 'possible': 0, 'actual': 1, 'precision': 0.0, 'recall': 0}\n","Entity:  SIGN\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 4, 'incorrect': 0, 'partial': 0, 'missed': 1, 'spurious': 1, 'possible': 5, 'actual': 5, 'precision': 0.8, 'recall': 0.8}\n","\tEvaluation Metric:  partial\n","\t {'correct': 4, 'incorrect': 0, 'partial': 0, 'missed': 1, 'spurious': 1, 'possible': 5, 'actual': 5, 'precision': 0.8, 'recall': 0.8}\n","\tEvaluation Metric:  strict\n","\t {'correct': 4, 'incorrect': 0, 'partial': 0, 'missed': 1, 'spurious': 1, 'possible': 5, 'actual': 5, 'precision': 0.8, 'recall': 0.8}\n","\tEvaluation Metric:  exact\n","\t {'correct': 4, 'incorrect': 0, 'partial': 0, 'missed': 1, 'spurious': 1, 'possible': 5, 'actual': 5, 'precision': 0.8, 'recall': 0.8}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lsaLVhqI84WD","executionInfo":{"status":"ok","timestamp":1625741379571,"user_tz":-120,"elapsed":566,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"5e40a5be-632c-46d3-bdc5-f6e074375fdb"},"source":["evaluator_all = Evaluator(no_padded_y_gold, no_padded_y_pred, test_labels)\n","results_all, results_agg_all = evaluator_all.evaluate()\n","\n","print('## OVERALL RESULTS')\n","for item in results_all.keys():\n","    print('\\tEvaluation Metric: ', item)\n","    print('\\t', results_all[item])\n","print('## RESULTS AT ENTITY LEVEL')\n","for entity in results_agg_all.keys():\n","    print('Entity: ', entity)\n","    for item in results_agg_all[entity].keys():\n","        print('\\tEvaluation Metric: ', item)\n","        print('\\t', results_agg_all[entity][item])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-07-08 10:49:38 root INFO: Imported 1772 predictions for 1772 true examples\n"],"name":"stderr"},{"output_type":"stream","text":["## OVERALL RESULTS\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 1396, 'incorrect': 135, 'partial': 0, 'missed': 1046, 'spurious': 1023, 'possible': 2577, 'actual': 2554, 'precision': 0.5465935787000783, 'recall': 0.5417151726814124}\n","\tEvaluation Metric:  partial\n","\t {'correct': 1267, 'incorrect': 0, 'partial': 264, 'missed': 1046, 'spurious': 1023, 'possible': 2577, 'actual': 2554, 'precision': 0.5477682067345341, 'recall': 0.5428793170353123}\n","\tEvaluation Metric:  strict\n","\t {'correct': 1151, 'incorrect': 380, 'partial': 0, 'missed': 1046, 'spurious': 1023, 'possible': 2577, 'actual': 2554, 'precision': 0.45066562255285825, 'recall': 0.4466433837795887}\n","\tEvaluation Metric:  exact\n","\t {'correct': 1267, 'incorrect': 264, 'partial': 0, 'missed': 1046, 'spurious': 1023, 'possible': 2577, 'actual': 2554, 'precision': 0.4960845732184808, 'recall': 0.4916569654637175}\n","## RESULTS AT ENTITY LEVEL\n","Entity:  DISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 208, 'incorrect': 89, 'partial': 0, 'missed': 157, 'spurious': 1023, 'possible': 454, 'actual': 1320, 'precision': 0.15757575757575756, 'recall': 0.4581497797356828}\n","\tEvaluation Metric:  partial\n","\t {'correct': 280, 'incorrect': 0, 'partial': 17, 'missed': 157, 'spurious': 1023, 'possible': 454, 'actual': 1320, 'precision': 0.21856060606060607, 'recall': 0.6354625550660793}\n","\tEvaluation Metric:  strict\n","\t {'correct': 197, 'incorrect': 100, 'partial': 0, 'missed': 157, 'spurious': 1023, 'possible': 454, 'actual': 1320, 'precision': 0.14924242424242423, 'recall': 0.43392070484581496}\n","\tEvaluation Metric:  exact\n","\t {'correct': 280, 'incorrect': 17, 'partial': 0, 'missed': 157, 'spurious': 1023, 'possible': 454, 'actual': 1320, 'precision': 0.21212121212121213, 'recall': 0.6167400881057269}\n","Entity:  RAREDISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 670, 'incorrect': 20, 'partial': 0, 'missed': 407, 'spurious': 1023, 'possible': 1097, 'actual': 1713, 'precision': 0.3911266783420899, 'recall': 0.6107566089334548}\n","\tEvaluation Metric:  partial\n","\t {'correct': 604, 'incorrect': 0, 'partial': 86, 'missed': 407, 'spurious': 1023, 'possible': 1097, 'actual': 1713, 'precision': 0.37769994162288384, 'recall': 0.5897903372835005}\n","\tEvaluation Metric:  strict\n","\t {'correct': 590, 'incorrect': 100, 'partial': 0, 'missed': 407, 'spurious': 1023, 'possible': 1097, 'actual': 1713, 'precision': 0.344424985405721, 'recall': 0.5378304466727438}\n","\tEvaluation Metric:  exact\n","\t {'correct': 604, 'incorrect': 86, 'partial': 0, 'missed': 407, 'spurious': 1023, 'possible': 1097, 'actual': 1713, 'precision': 0.3525977816695855, 'recall': 0.5505925250683683}\n","Entity:  SYMPTOM\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 22, 'incorrect': 7, 'partial': 0, 'missed': 25, 'spurious': 1023, 'possible': 54, 'actual': 1052, 'precision': 0.02091254752851711, 'recall': 0.4074074074074074}\n","\tEvaluation Metric:  partial\n","\t {'correct': 27, 'incorrect': 0, 'partial': 2, 'missed': 25, 'spurious': 1023, 'possible': 54, 'actual': 1052, 'precision': 0.026615969581749048, 'recall': 0.5185185185185185}\n","\tEvaluation Metric:  strict\n","\t {'correct': 22, 'incorrect': 7, 'partial': 0, 'missed': 25, 'spurious': 1023, 'possible': 54, 'actual': 1052, 'precision': 0.02091254752851711, 'recall': 0.4074074074074074}\n","\tEvaluation Metric:  exact\n","\t {'correct': 27, 'incorrect': 2, 'partial': 0, 'missed': 25, 'spurious': 1023, 'possible': 54, 'actual': 1052, 'precision': 0.025665399239543727, 'recall': 0.5}\n","Entity:  SIGN\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 496, 'incorrect': 19, 'partial': 0, 'missed': 457, 'spurious': 1023, 'possible': 972, 'actual': 1538, 'precision': 0.32249674902470743, 'recall': 0.5102880658436214}\n","\tEvaluation Metric:  partial\n","\t {'correct': 356, 'incorrect': 0, 'partial': 159, 'missed': 457, 'spurious': 1023, 'possible': 972, 'actual': 1538, 'precision': 0.2831599479843953, 'recall': 0.4480452674897119}\n","\tEvaluation Metric:  strict\n","\t {'correct': 342, 'incorrect': 173, 'partial': 0, 'missed': 457, 'spurious': 1023, 'possible': 972, 'actual': 1538, 'precision': 0.2223667100130039, 'recall': 0.35185185185185186}\n","\tEvaluation Metric:  exact\n","\t {'correct': 356, 'incorrect': 159, 'partial': 0, 'missed': 457, 'spurious': 1023, 'possible': 972, 'actual': 1538, 'precision': 0.23146944083224968, 'recall': 0.3662551440329218}\n"],"name":"stdout"}]}]}