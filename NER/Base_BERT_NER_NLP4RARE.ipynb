{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Base_BERT_NER_NLP4RARE.ipynb","provenance":[{"file_id":"1kul7il5RPYYnzZMFr36PiIxugA0X3-y2","timestamp":1625402532957},{"file_id":"1c-fOOTd8KeU8QGKdKVyCwdfKlZjQgCF3","timestamp":1625314379253},{"file_id":"1ley57tuXXLuPfr2v6nntDKL0ggJ09cwx","timestamp":1612919533273},{"file_id":"1LCJt3fu3pW0hFe7L19Uu4MMRrW9Z9p5N","timestamp":1612543820837}],"collapsed_sections":[]},"environment":{"name":"pytorch-gpu.1-4.m55","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m55"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5ed6987ecd954f02b7e3fb4494dedeb2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4bf80fab3a1c4d39b00a990813ccedb3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9e38d5ebfc1749d1be2ed531da071245","IPY_MODEL_e69f872d01df4ff3aa8fcacd4f53cc39"]}},"4bf80fab3a1c4d39b00a990813ccedb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9e38d5ebfc1749d1be2ed531da071245":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2efad9071f2e4f72aaae79d2137ec8af","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cc2231d6036a48f09ffab5b3e5abb635"}},"e69f872d01df4ff3aa8fcacd4f53cc39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b9ebf56c50414ca1906232271eceaef2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:11&lt;00:00, 2.42B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eca98969d11a46c5a2465bb537846231"}},"2efad9071f2e4f72aaae79d2137ec8af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cc2231d6036a48f09ffab5b3e5abb635":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9ebf56c50414ca1906232271eceaef2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eca98969d11a46c5a2465bb537846231":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1382a9c164c9433a9c2fc1550a1f7b62":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c00b3aa796074f0ba3fad8b2694cc52d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_58a24b2e136a449ca610312c1cf89d95","IPY_MODEL_3781bcc6896c46f28f8bd1e1d73a5221"]}},"c00b3aa796074f0ba3fad8b2694cc52d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"58a24b2e136a449ca610312c1cf89d95":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ac8343d5bdfe4541a84cbb6041922652","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0dd75715edbc47848bf4c39709c00d38"}},"3781bcc6896c46f28f8bd1e1d73a5221":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_776fa680061d48ba9ef080301589f93b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:00&lt;00:00, 5.29kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5feec102e98f459399bc72fe1ad361b1"}},"ac8343d5bdfe4541a84cbb6041922652":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0dd75715edbc47848bf4c39709c00d38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"776fa680061d48ba9ef080301589f93b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5feec102e98f459399bc72fe1ad361b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7bb5e4fe825646fe867981ff154ecab5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_af5b2c5ec1ec4c46b2be8aa70bb41192","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_291bdfe980d84f0cae6df6c8ab6c35b7","IPY_MODEL_aa257372c0b64eec9ca1c2629bfe9b8c"]}},"af5b2c5ec1ec4c46b2be8aa70bb41192":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"291bdfe980d84f0cae6df6c8ab6c35b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_70c5bf742efb45f0b0d24b31e6ebea37","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_df8c47f665d442f982337c19bee8d9c3"}},"aa257372c0b64eec9ca1c2629bfe9b8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fea1fa96af3d4848935e7f78edd62cd9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:11&lt;00:00, 20.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eae8b0eec2df470c8ca88c02245d5b4a"}},"70c5bf742efb45f0b0d24b31e6ebea37":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"df8c47f665d442f982337c19bee8d9c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fea1fa96af3d4848935e7f78edd62cd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eae8b0eec2df470c8ca88c02245d5b4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea498fbcbd504a16b5a8cd594a15469d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cb85683206d547ccbeac63f6430ad830","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c834be49accc42a3b767dd1e527ce5b0","IPY_MODEL_ac1026cc1364462cbca284e8316e0b19"]}},"cb85683206d547ccbeac63f6430ad830":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c834be49accc42a3b767dd1e527ce5b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_84b14f61378b4efd8bb1f0cdffe01d21","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1a8d5869088c46aca4ace36bbb8ae342"}},"ac1026cc1364462cbca284e8316e0b19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3963bb81d021418f9595688d5a65286d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 2.05MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e0a628a6ec6c4a1d9cf2345256fe5c12"}},"84b14f61378b4efd8bb1f0cdffe01d21":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1a8d5869088c46aca4ace36bbb8ae342":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3963bb81d021418f9595688d5a65286d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e0a628a6ec6c4a1d9cf2345256fe5c12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78b7af1dc6714c8193109e8af42936af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_225bdfcf606943268dc20f54bf7e56e3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9bfff225792d41e585370709093bbce9","IPY_MODEL_225b554af58348f3a2927428a4608fe7"]}},"225bdfcf606943268dc20f54bf7e56e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9bfff225792d41e585370709093bbce9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b8c10f4f29fa4a2b833755192c51c51a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6dbdcea316a942529a300b1d01078560"}},"225b554af58348f3a2927428a4608fe7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7ec2b58ef9cb4269a286ceb475e9c19f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:09&lt;00:00, 45.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7f5d5dcdf88b468a8e23000c1fad5a58"}},"b8c10f4f29fa4a2b833755192c51c51a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6dbdcea316a942529a300b1d01078560":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ec2b58ef9cb4269a286ceb475e9c19f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7f5d5dcdf88b468a8e23000c1fad5a58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"AcQ7f6ku4TCy"},"source":["# Google's BERT approach for detecting rare diseases\n","\n","This notebook contains the code to develop a Google's BERT model to detect rare diseases from texts.\n","\n","The BERT base model is a pretrained model on English language using a masked language modeling (MLM) objective. It was first introduced in this [paper](https://arxiv.org/abs/1810.04805) and first released in this [repository](https://github.com/google-research/bert). The model used in this notebook is uncased: it does not make a difference between english and English.\n","\n","BERT is a transformers model pretrained on a large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts.\n","\n","The BERT model was pretrained on [BookCorpus](https://yknzhu.wixsite.com/mbweb), a dataset consisting of 11,038 unpublished books and [English Wikipedia](https://en.wikipedia.org/wiki/English_Wikipedia) (excluding lists, tables and headers).\n","\n","To accomplish this, we will use some tools developed in the [transformers](https://huggingface.co/transformers/index.html) library, which is a library that recopiles some of the State-of-the-art Natural Language Processing for Pytorch and TensorFlow.\n","\n","To make use of the pre-trained model with the hugging face `transformers` library, we need the model's weights to be in a form which pyTorch understands. The original model was trained using tensorflow so we need to convert the weights into pyTorch weights. We can then import and use it."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E-awiIaFW2Nc","executionInfo":{"status":"ok","timestamp":1625759938098,"user_tz":-120,"elapsed":12914,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"b3934f12-138e-4557-b767-b4004aedab27"},"source":["if 'google.colab' in str(get_ipython()):\n","    print('Running on CoLab')\n","    from google.colab import drive\n","    #drive.flush_and_unmount()\n","    drive.mount('/content/drive')\n","    root = '/content/drive/My Drive/Colab Notebooks'\n","else:\n","    print('Not running on CoLab')\n","    root = './'\n","\n","print(\"Current directory: {}\".format(root))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running on CoLab\n","Mounted at /content/drive\n","Current directory: /content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XLKP1xZe17qh"},"source":["## 1. Getting the resources\n","\n","First of all, we will install the needed packages."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eiDJciIUZ1fg","executionInfo":{"status":"ok","timestamp":1625759957939,"user_tz":-120,"elapsed":19844,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"a50d4f1f-be22-47fa-8954-18c1c072fa7c"},"source":["!pip install pytorch_transformers\n","!pip install transformers\n","!pip install seqeval\n","!pip install sklearn-crfsuite"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pytorch_transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n","\r\u001b[K     |█▉                              | 10kB 23.0MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 29.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 35.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 25.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 28.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 28.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 29.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 29.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 29.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 29.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 29.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 29.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 29.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 29.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 29.3MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.41.1)\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/8a/bfe42e25206da14a311a76798248def9d0f5815bb5651fa4090af7fc4683/boto3-1.17.107-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 45.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 47.0MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.9.0+cu102)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 36.7MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (1.24.3)\n","Collecting s3transfer<0.5.0,>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.3MB/s \n","\u001b[?25hCollecting botocore<1.21.0,>=1.20.107\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/85/b2e0366a63f4f0aedd4cca8b7bf8b2d6e6adc0f3d72435aa5174d0ec80e2/botocore-1.20.107-py2.py3-none-any.whl (7.7MB)\n","\u001b[K     |████████████████████████████████| 7.7MB 44.6MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.107->boto3->pytorch_transformers) (2.8.1)\n","\u001b[31mERROR: botocore 1.20.107 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: jmespath, botocore, s3transfer, boto3, sacremoses, sentencepiece, pytorch-transformers\n","Successfully installed boto3-1.17.107 botocore-1.20.107 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.4.2 sacremoses-0.0.45 sentencepiece-0.1.96\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 16.5MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 28.6MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Collecting huggingface-hub==0.0.12\n","  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.12 tokenizers-0.10.3 transformers-4.8.2\n","Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16184 sha256=585a6677722a7fb141868ddfa40a50f0a63fd864bd3b84c1a4a57440d61e306b\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Collecting sklearn-crfsuite\n","  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n","Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (1.15.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.8.9)\n","Collecting python-crfsuite>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n","\u001b[K     |████████████████████████████████| 747kB 30.2MB/s \n","\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite\n","Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ULc2U_O924aK"},"source":["The pretrained 24 smaller `BERT` models (English only, uncased, trained with WordPiece masking) can be all downloaded from [here](https://storage.googleapis.com/bert_models/2020_02_20/all_bert_models.zip). The smaller BERT models are intended for environments with restricted computational resources.\n","\n","Another option to use these models is to load them directly from the `transformers library`, which is the way used in this notebook."]},{"cell_type":"markdown","metadata":{"id":"3SWmvzdm3D7a"},"source":["## 2. Data loading and first insights\n","\n","In this step we will download the data and define all of the main paths that our model includes.\n","\n","It is also possible to select the desired language (`en` for english and `es` for spanish) and whether to consider all the entities from the model or not (`allTypes` variable)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ytuVTGvFameo","executionInfo":{"status":"ok","timestamp":1625759957940,"user_tz":-120,"elapsed":6,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"d9f85423-ed48-4608-f116-008896b0e88d"},"source":["LANG = 'en'  #This system will also process texts written in Spanish, LANG='es'\n","allTypes = True\n","sTypes = ''\n","if allTypes:\n","    sTypes = '_all'\n","\n","#path_data=root+'data/{}/'.format(LANG) #folder where you can find the datasets\n","path_data = root + '/ner/data/gold_nlp4rare_corpus/' #folder where you can find the datasets\n","path_models = root + '/ner/models/{}/'.format(LANG) #folder to save the models\n","checkpoints = root + '/ner/checkpoints/'\n","path_scores = root + '/ner/scores/{}/'.format(LANG) #folder to save the scores\n","path_outputs = root + '/ner/outputs/{}/'.format(LANG) #folder to save the scores\n","\n","print('Datasets:',path_data)\n","print('Path to save this model:',path_models)\n","print('Path for checkpoints:',checkpoints)\n","print('Path to save the scores:',path_scores)\n","print('Path to save the outputs:',path_outputs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Datasets: /content/drive/My Drive/Colab Notebooks/ner/data/gold_nlp4rare_corpus/\n","Path to save this model: /content/drive/My Drive/Colab Notebooks/ner/models/en/\n","Path for checkpoints: /content/drive/My Drive/Colab Notebooks/ner/checkpoints/\n","Path to save the scores: /content/drive/My Drive/Colab Notebooks/ner/scores/en/\n","Path to save the outputs: /content/drive/My Drive/Colab Notebooks/ner/outputs/en/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBUx_tlSbcGu","executionInfo":{"status":"ok","timestamp":1625759960468,"user_tz":-120,"elapsed":2074,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"9a0d8649-da1b-47bf-8e34-adc08d3a9ed5"},"source":["import pandas as pd\n","\n","df_train = pd.read_csv(path_data+'train{}.csv'.format(sTypes),index_col=0)\n","print('size of the training dataset: {}'.format(len(df_train)))\n","df_dev = pd.read_csv(path_data+'dev{}.csv'.format(sTypes),index_col=0)\n","print('size of the development dataset: {}'.format(len(df_dev)))\n","df_test = pd.read_csv(path_data+'test{}.csv'.format(sTypes),index_col=0)\n","print('size of the test dataset: {}'.format(len(df_test)))\n","print('datasets loaded!\\n')\n","\n","#number of labels (IOB tags)\n","tags = df_train['Tag'].unique()\n","num_tags = df_train['Tag'].nunique()\n","print('Labels: {}'.format(tags))\n","print('Nr of labels: {}'.format(num_tags))\n","\n","# Overall statistics for the number of words in each text\n","count_df_train = df_train.groupby('Sentence #').count()\n","statistics_train = count_df_train['Word'].describe()\n","print('\\nSome statistics of the sentences in the training dataset:')\n","print(statistics_train)\n","\n","count_df_dev = df_dev.groupby('Sentence #').count()\n","statistics_dev = count_df_dev['Word'].describe()\n","print('\\nSome statistics of the sentences in the development dataset:')\n","print(statistics_dev)\n","\n","#The lenth of the longest sentence. Lenght is the number of words.\n","MAX_LEN_TRAIN = int(statistics_train['max'])\n","MAX_LEN_DEV = int(statistics_dev['max'])\n","MAX_LEN = max(MAX_LEN_TRAIN, MAX_LEN_DEV)\n","print('\\n')\n","print('The maximum length of sentences in TRAIN is: ', MAX_LEN_TRAIN)\n","print('The maximum length of sentences in DEV is: ', MAX_LEN_DEV)\n","print('The maximum length of sentences in TOTAL is:', MAX_LEN)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["size of the training dataset: 135656\n","size of the development dataset: 18492\n","size of the test dataset: 37837\n","datasets loaded!\n","\n","Labels: ['O' 'B-RAREDISEASE' 'I-RAREDISEASE' 'B-DISEASE' 'I-DISEASE' 'B-SIGN'\n"," 'I-SIGN' 'B-SYMPTOM' 'I-SYMPTOM']\n","Nr of labels: 9\n","\n","Some statistics of the sentences in the training dataset:\n","count    6451.000000\n","mean       21.028678\n","std        10.653876\n","min         1.000000\n","25%        13.000000\n","50%        19.000000\n","75%        26.000000\n","max        90.000000\n","Name: Word, dtype: float64\n","\n","Some statistics of the sentences in the development dataset:\n","count    903.000000\n","mean      20.478405\n","std       10.105284\n","min        1.000000\n","25%       13.000000\n","50%       18.000000\n","75%       25.000000\n","max       71.000000\n","Name: Word, dtype: float64\n","\n","\n","The maximum length of sentences in TRAIN is:  90\n","The maximum length of sentences in DEV is:  71\n","The maximum length of sentences in TOTAL is: 90\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ltOsBqAv4N_r"},"source":["We visualize next the distribution of each of the datasets according to its entities."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLdpET-UblbE","executionInfo":{"status":"ok","timestamp":1625759960469,"user_tz":-120,"elapsed":4,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"e02905a9-70b8-4ed8-b58b-e21071fa3d16"},"source":["separator = '*'*60\n","# Tag statistics train df\n","print('TRAIN:\\n', df_train['Tag'].value_counts(), sep='\\n', end='\\n')\n","print()\n","print('Percentages:', df_train['Tag'].value_counts(normalize=True)*100, sep='\\n', end='\\n')\n","\n","# Tag statistics dev df\n","print('', separator, '', sep='\\n')\n","print('DEV:\\n', df_dev['Tag'].value_counts(), sep='\\n', end='\\n')\n","print()\n","print('Percentages:', df_dev['Tag'].value_counts(normalize=True)*100, sep='\\n', end='\\n')\n","\n","# Tag statistics test df\n","print('', separator, '', sep='\\n')\n","print('TEST:\\n', df_test['Tag'].value_counts(), sep='\\n', end='\\n')\n","print()\n","print('Percentages:', df_test['Tag'].value_counts(normalize=True)*100, sep='\\n', end='\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TRAIN:\n","\n","O                113555\n","I-SIGN             7584\n","I-RAREDISEASE      4116\n","B-RAREDISEASE      3555\n","B-SIGN             2914\n","I-DISEASE          1735\n","B-DISEASE          1596\n","I-SYMPTOM           304\n","B-SYMPTOM           297\n","Name: Tag, dtype: int64\n","\n","Percentages:\n","O                83.708056\n","I-SIGN            5.590612\n","I-RAREDISEASE     3.034145\n","B-RAREDISEASE     2.620599\n","B-SIGN            2.148080\n","I-DISEASE         1.278970\n","B-DISEASE         1.176505\n","I-SYMPTOM         0.224096\n","B-SYMPTOM         0.218936\n","Name: Tag, dtype: float64\n","\n","************************************************************\n","\n","DEV:\n","\n","O                15131\n","I-SIGN            1337\n","I-RAREDISEASE      626\n","B-RAREDISEASE      513\n","B-SIGN             405\n","I-DISEASE          224\n","B-DISEASE          218\n","I-SYMPTOM           20\n","B-SYMPTOM           18\n","Name: Tag, dtype: int64\n","\n","Percentages:\n","O                81.824573\n","I-SIGN            7.230154\n","I-RAREDISEASE     3.385248\n","B-RAREDISEASE     2.774173\n","B-SIGN            2.190136\n","I-DISEASE         1.211335\n","B-DISEASE         1.178888\n","I-SYMPTOM         0.108155\n","B-SYMPTOM         0.097339\n","Name: Tag, dtype: float64\n","\n","************************************************************\n","\n","TEST:\n","\n","O                31594\n","I-SIGN            2215\n","I-RAREDISEASE     1179\n","B-RAREDISEASE     1073\n","B-SIGN             803\n","B-DISEASE          443\n","I-DISEASE          400\n","I-SYMPTOM           80\n","B-SYMPTOM           50\n","Name: Tag, dtype: int64\n","\n","Percentages:\n","O                83.500278\n","I-SIGN            5.854058\n","I-RAREDISEASE     3.115998\n","B-RAREDISEASE     2.835849\n","B-SIGN            2.122261\n","B-DISEASE         1.170812\n","I-DISEASE         1.057166\n","I-SYMPTOM         0.211433\n","B-SYMPTOM         0.132146\n","Name: Tag, dtype: float64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D30_dqal47wo"},"source":["## 3. Imports and pre-processing of the data\n","\n","First, all the steps to import the necessary packages to use the model are defined. After that, the pre processing of the data is necessary as the `Bert` model need to meet some special requirements."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"id":"wNJcYiT0eXbV","executionInfo":{"status":"ok","timestamp":1625759969764,"user_tz":-120,"elapsed":9298,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"fa087aa5-cd42-453d-e39d-0143acac2c2e"},"source":["#importing a few necessary packages and setting the DATA directory\n","DATA_DIR=\".\"\n","import os\n","import numpy as np\n","import pickle\n","import tensorflow as tf\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","# install BERT\n","!pip install pytorch_pretrained_bert pytorch-nlp\n","\n","# BERT imports\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from pytorch_pretrained_bert import BertAdam\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","# specify GPU device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pytorch_pretrained_bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 29.4MB/s \n","\u001b[?25hCollecting pytorch-nlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n","\u001b[K     |████████████████████████████████| 92kB 12.3MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.9.0+cu102)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.17.107)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n","Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.4.2)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n","Requirement already satisfied: botocore<1.21.0,>=1.20.107 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.20.107)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.107->boto3->pytorch_pretrained_bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.107->boto3->pytorch_pretrained_bert) (1.15.0)\n","Installing collected packages: pytorch-pretrained-bert, pytorch-nlp\n","Successfully installed pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla T4'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"epO0H4UI5awo"},"source":["The model does not process text, so we need to transform all the pre-defined entities (labels) to a language that can be interpreted by the model, i.e., numbers.\n","\n","To do that, we create a dictionary with the desired labels following the IOB scheme."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AD4URCopex4w","executionInfo":{"status":"ok","timestamp":1625759969764,"user_tz":-120,"elapsed":6,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"df5894b1-f030-41ce-d8ab-1cde09b18a1a"},"source":["# We have to create a dictionary for the labels (IOB labels):\n","# label is key and value is index.\n","tag_index = {t : i + 1 for i, t in enumerate(tags)}\n","#we have to add a new label for pad tokens\n","tag_index[\"PAD\"] = 0\n","\n","print('Dictionary for labels:', tag_index)\n","print('Number of tags added the tag for pad tokens:', len(tag_index))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dictionary for labels: {'O': 1, 'B-RAREDISEASE': 2, 'I-RAREDISEASE': 3, 'B-DISEASE': 4, 'I-DISEASE': 5, 'B-SIGN': 6, 'I-SIGN': 7, 'B-SYMPTOM': 8, 'I-SYMPTOM': 9, 'PAD': 0}\n","Number of tags added the tag for pad tokens: 10\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DL-1sfr-58qn"},"source":["Next, we perform the first step of preprocessing of the data. Here, a class `SentenceGetter` in combination to a function `vectorization` are defined to extract the desired features from the input data."]},{"cell_type":"code","metadata":{"id":"YIUm7FCEgfFK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625759970664,"user_tz":-120,"elapsed":903,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"f9b7c8f0-bbf5-4d62-d728-e0d7375502c2"},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","class SentenceGetter(object):\n","    \"\"\"This is a class to get sentence. Each sentence will be a list of tuples with its words, tag and pos.\"\"\"\n","    def __init__(self, df):\n","        self.n_sent = 1\n","        self.df = df\n","        self.empty = False\n","        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n","                                                       s['POS'].values.tolist(),\n","                                                       s['Tag'].values.tolist())]\n","        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n","        self.sentences = [s for s in self.grouped]\n","        \n","    def get_text(self):\n","        try:\n","            #s = self.grouped['Sentence: {}'.format(self.n_sent)]\n","            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n","            self.n_sent +=1\n","            return s\n","        except:\n","            return None\n","\n","def vectorization(df, tag_index):\n","    \"\"\"This functions gets the dataframe with the dataset and transform it to vectors. \n","    First, its sentences are retrieved. Then, for each sentence, the function creates a list\n","    with its corresponding indexes. In addition to X (which are the sentences transformed to vectors),\n","    the functions also returns the corresponding labels for each token\"\"\"\n","    \n","    df = df[['Sentence #','Word','POS','Tag']]\n","    \n","    # Getting full sentences\n","    getter = SentenceGetter(df)\n","    sentences = getter.sentences\n","\n","    X = [[w[0] for w in s] for s in sentences]\n","\n","    # Convert label to index\n","    y = [[tag_index[w[2]] for w in s] for s in sentences]\n","    \n","    return (X, y)\n","\n","# vectorization of datasets\n","sentences_train, labels_train = vectorization(df_train, tag_index)\n","sentences_dev, labels_dev = vectorization(df_dev, tag_index)\n","sentences_test, labels_test = vectorization(df_test, tag_index)\n","print('Datasets loaded!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Datasets loaded!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NK85yt-p64ft"},"source":["Same as for the labels, all of the retrieved words for each sentence is necessary to be converted to numbers to use them in the model. For that, we use the tokenization of the Bert model.\n","\n","Afterwards, we also load the model to use as the architecture."]},{"cell_type":"code","metadata":{"id":"XVFBcuyehFFD","colab":{"base_uri":"https://localhost:8080/","height":381,"referenced_widgets":["5ed6987ecd954f02b7e3fb4494dedeb2","4bf80fab3a1c4d39b00a990813ccedb3","9e38d5ebfc1749d1be2ed531da071245","e69f872d01df4ff3aa8fcacd4f53cc39","2efad9071f2e4f72aaae79d2137ec8af","cc2231d6036a48f09ffab5b3e5abb635","b9ebf56c50414ca1906232271eceaef2","eca98969d11a46c5a2465bb537846231","1382a9c164c9433a9c2fc1550a1f7b62","c00b3aa796074f0ba3fad8b2694cc52d","58a24b2e136a449ca610312c1cf89d95","3781bcc6896c46f28f8bd1e1d73a5221","ac8343d5bdfe4541a84cbb6041922652","0dd75715edbc47848bf4c39709c00d38","776fa680061d48ba9ef080301589f93b","5feec102e98f459399bc72fe1ad361b1","7bb5e4fe825646fe867981ff154ecab5","af5b2c5ec1ec4c46b2be8aa70bb41192","291bdfe980d84f0cae6df6c8ab6c35b7","aa257372c0b64eec9ca1c2629bfe9b8c","70c5bf742efb45f0b0d24b31e6ebea37","df8c47f665d442f982337c19bee8d9c3","fea1fa96af3d4848935e7f78edd62cd9","eae8b0eec2df470c8ca88c02245d5b4a","ea498fbcbd504a16b5a8cd594a15469d","cb85683206d547ccbeac63f6430ad830","c834be49accc42a3b767dd1e527ce5b0","ac1026cc1364462cbca284e8316e0b19","84b14f61378b4efd8bb1f0cdffe01d21","1a8d5869088c46aca4ace36bbb8ae342","3963bb81d021418f9595688d5a65286d","e0a628a6ec6c4a1d9cf2345256fe5c12","78b7af1dc6714c8193109e8af42936af","225bdfcf606943268dc20f54bf7e56e3","9bfff225792d41e585370709093bbce9","225b554af58348f3a2927428a4608fe7","b8c10f4f29fa4a2b833755192c51c51a","6dbdcea316a942529a300b1d01078560","7ec2b58ef9cb4269a286ceb475e9c19f","7f5d5dcdf88b468a8e23000c1fad5a58"]},"executionInfo":{"status":"ok","timestamp":1625759982460,"user_tz":-120,"elapsed":11798,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"d22609da-b303-4ae0-a64c-9c43d248202b"},"source":["from transformers import AutoTokenizer, AutoModelForTokenClassification\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n","model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_tags+1)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ed6987ecd954f02b7e3fb4494dedeb2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1382a9c164c9433a9c2fc1550a1f7b62","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bb5e4fe825646fe867981ff154ecab5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea498fbcbd504a16b5a8cd594a15469d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78b7af1dc6714c8193109e8af42936af","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"-1977pMY7N60"},"source":["Here, an example of tokenization is provided to check how this process works.\n","\n","Through this example, we can see how the original sentence is transformed to new subwords or 'tokens', and after that the tokenizer assign them a number according to its internal vocabulary. \n","\n","As new subwords are created, the original lenght of the sentence is modified. Then, the original labels are no longer valid, and a new processing of the labels is necessary to correct this disalignment between words and labels."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GHEDBh2dvR5u","executionInfo":{"status":"ok","timestamp":1625759982461,"user_tz":-120,"elapsed":7,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"8ddad1e3-8e4c-4ed8-8b0d-ba1e64c49900"},"source":["# Example of BERT tokenization\n","selected_index = np.random.randint(1, 6461)\n","# selected_index = 344\n","# selected_index = 4\n","selected_sentence = sentences_train[selected_index]\n","tokenized_input = tokenizer(selected_sentence, is_split_into_words=True, add_special_tokens=False)\n","tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n","print(\"Sentence used: {}\\nOriginal sentence:\\n\\t{}\".format(selected_index, selected_sentence))\n","print(\"Tokenization of the sentence:\\n\\t{}\".format(tokens))\n","print('Tokenized ids for the sentence:\\n\\t{}'.format(tokenized_input[\"input_ids\"]))\n","print(\"Length:\\n\\tOriginal sentence: {}\\n\\tTokenized sentence: {}\\n\\tTokenized ids: {}\".format(len(selected_sentence), len(tokens), len(tokenized_input[\"input_ids\"])))\n","\n","# Example label alignment after BERT tokenization\n","selected_original_labels = labels_train[selected_index]\n","\n","print('')\n","print('Original labels:\\n\\t{}'.format(selected_original_labels))\n","\n","word_ids = []\n","index = 0\n","current_word = ''\n","for token in tokens:\n","    if token.startswith(\"##\"):\n","        word_ids.append(index-1)\n","    elif token in current_word:\n","        if len(tokenizer.tokenize(current_word)) != 1:\n","            subtokens_qty = len(tokenizer.tokenize(current_word))\n","            for subtoken in tokenizer.tokenize(current_word):\n","                if token == subtoken:\n","                    word_ids.append(index-1)\n","                    break\n","                subtokens_qty -= 1\n","                if subtokens_qty == 0:\n","                    word_ids.append(index)\n","                    current_word = selected_sentence[index].lower()\n","                    index += 1\n","        else:\n","            word_ids.append(index)\n","            current_word = selected_sentence[index].lower()\n","            index += 1\n","    else:\n","        word_ids.append(index)\n","        current_word = selected_sentence[index].lower()\n","        index += 1\n","\n","print('New assigned word_ids:\\n\\t{}'.format(word_ids))\n","\n","aligned_labels = []\n","old_index = -1\n","\n","if allTypes:\n","    for i in word_ids:\n","        if (i == old_index) and ( (selected_original_labels[i] == 2) or (selected_original_labels[i] == 4) or (selected_original_labels[i] == 6) or (selected_original_labels[i] == 8) ):\n","            aligned_labels.append(selected_original_labels[i]+1)\n","        else:\n","            aligned_labels.append(selected_original_labels[i])\n","        old_index = i\n","else:\n","    for i in word_ids:\n","        if (i == old_index) and ( (selected_original_labels[i] == 2) or (selected_original_labels[i] == 4) ):\n","            aligned_labels.append(selected_original_labels[i]+1)\n","        else:\n","            aligned_labels.append(selected_original_labels[i])\n","        old_index = i\n","\n","# print('')\n","# print('Original labels:\\n\\t{}'.format(selected_original_labels))\n","# print('New assigned word_ids:\\n\\t{}'.format(word_ids))\n","print('New label alignment:\\n\\t{}'.format(aligned_labels))\n","print(\"Length:\\n\\tOriginal labels: {}\\n\\tNew assigned word_ids: {}\\n\\tNew label alignment: {}\".format(len(selected_original_labels), len(word_ids), len(aligned_labels)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sentence used: 519\n","Original sentence:\n","\t['Spondylothoracic', 'dysplasia', 'occurs', 'with', 'greater', 'frequency', 'in', 'Puerto', 'Rico', 'and', 'in', 'individuals', 'of', 'Puerto', 'Rican', 'heritage', ',', 'accounting', 'for', 'about', 'half', 'of', 'all', 'affected', 'individuals', 'reported', 'in', 'the', 'medical', 'literature', '.', ' ']\n","Tokenization of the sentence:\n","\t['sp', '##ond', '##yl', '##otho', '##rac', '##ic', 'd', '##ys', '##pl', '##asia', 'occurs', 'with', 'greater', 'frequency', 'in', 'puerto', 'rico', 'and', 'in', 'individuals', 'of', 'puerto', 'rican', 'heritage', ',', 'accounting', 'for', 'about', 'half', 'of', 'all', 'affected', 'individuals', 'reported', 'in', 'the', 'medical', 'literature', '.']\n","Tokenized ids for the sentence:\n","\t[11867, 15422, 8516, 29288, 22648, 2594, 1040, 7274, 24759, 15396, 5158, 2007, 3618, 6075, 1999, 5984, 7043, 1998, 1999, 3633, 1997, 5984, 13641, 4348, 1010, 9529, 2005, 2055, 2431, 1997, 2035, 5360, 3633, 2988, 1999, 1996, 2966, 3906, 1012]\n","Length:\n","\tOriginal sentence: 32\n","\tTokenized sentence: 39\n","\tTokenized ids: 39\n","\n","Original labels:\n","\t[2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","New assigned word_ids:\n","\t[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n","New label alignment:\n","\t[2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","Length:\n","\tOriginal labels: 32\n","\tNew assigned word_ids: 39\n","\tNew label alignment: 39\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueA3oqQ-VoLL","executionInfo":{"status":"ok","timestamp":1625759982462,"user_tz":-120,"elapsed":6,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"6a903116-1ba1-441c-d7f9-305dfc61443c"},"source":["# print(tokenizer.tokenize('1%-2'))\n","# print(tokenizer.tokenize('and'))\n","# print(tokenizer.tokenize('NMOSD'))\n","subtoken_to_analyze = '2'\n","strings = ['1%-2', 'and', 'with', 'NMOSD', '2,000', ',', '2-2', '222', '24-hour']\n","\n","for string in strings: \n","    print('[', string, ']')\n","    if len(tokenizer.tokenize(string)) != 1:\n","        print('\\t({})'.format(tokenizer.tokenize(string)))\n","        print('\\tnot unique word')\n","        subtokens_qty = len(tokenizer.tokenize(string))\n","        for subtoken in tokenizer.tokenize(string):\n","            if subtoken_to_analyze.lower() == subtoken:\n","                print('------> <{}> belongs to last word'.format(subtoken_to_analyze))\n","                break\n","            subtokens_qty -= 1\n","            if subtokens_qty == 0:\n","                print('------> <{}> does NOT belong to last word'.format(subtoken_to_analyze))\n","    else:\n","        print('\\tunique word')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ 1%-2 ]\n","\t(['1', '%', '-', '2'])\n","\tnot unique word\n","------> <2> belongs to last word\n","[ and ]\n","\tunique word\n","[ with ]\n","\tunique word\n","[ NMOSD ]\n","\t(['nm', '##os', '##d'])\n","\tnot unique word\n","------> <2> does NOT belong to last word\n","[ 2,000 ]\n","\t(['2', ',', '000'])\n","\tnot unique word\n","------> <2> belongs to last word\n","[ , ]\n","\tunique word\n","[ 2-2 ]\n","\t(['2', '-', '2'])\n","\tnot unique word\n","------> <2> belongs to last word\n","[ 222 ]\n","\tunique word\n","[ 24-hour ]\n","\t(['24', '-', 'hour'])\n","\tnot unique word\n","------> <2> does NOT belong to last word\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y3P5E_Gz8H2o"},"source":["After the example, we proceed with the same operation to the full datasets."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_MoZWkQ1mGmE","executionInfo":{"status":"ok","timestamp":1625760145580,"user_tz":-120,"elapsed":163122,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"082fc9c1-4742-411d-8167-a56eb511b350"},"source":["def align_labels(original_sentences, original_labels, MAX_LEN):\n","    \"\"\"\n","    This function assign the new labels following the original input and according to\n","    the results from the Tokenization to create a good alignment between words/subwords\n","    and labels.\n","    Besides this, it provides the new maximum lenght of the sentences after the Tokenization\n","    for future padding purposes.\n","    \"\"\"\n","    tokenized_input = tokenizer(original_sentences, is_split_into_words=True, add_special_tokens=False)\n","    tokens = [tokenizer.convert_ids_to_tokens(t) for t in tokenized_input[\"input_ids\"]]\n","    list_len = [len(i) for i in tokens]\n","    MAX_LEN = max(max(list_len), MAX_LEN) \n","\n","    word_ids_global = []\n","    for nr_sentence, list_tokens in enumerate(tokens):\n","        word_ids = []\n","        index = 0\n","        current_word = ''\n","        for token in list_tokens:\n","            if token.startswith(\"##\"):\n","                word_ids.append(index-1)\n","            elif token in current_word:\n","                if len(tokenizer.tokenize(current_word)) != 1:\n","                    subtokens_qty = len(tokenizer.tokenize(current_word))\n","                    for subtoken in tokenizer.tokenize(current_word):\n","                        if token == subtoken:\n","                            word_ids.append(index-1)\n","                            break\n","                        subtokens_qty -= 1\n","                        if subtokens_qty == 0:\n","                            word_ids.append(index)\n","                            current_word = original_sentences[nr_sentence][index].lower()\n","                            index += 1\n","                else:\n","                    word_ids.append(index)\n","                    current_word = original_sentences[nr_sentence][index].lower()\n","                    index += 1\n","            else:\n","                word_ids.append(index)\n","                current_word = original_sentences[nr_sentence][index].lower()\n","                index += 1\n","        word_ids_global.append(word_ids)\n","\n","    aligned_global = []\n","    for nr_sentence, list_word_ids in enumerate(word_ids_global):\n","        aligned_labels = []\n","        old_index = -1\n","        if allTypes:\n","            for i in list_word_ids:\n","                if (i == old_index) and ( (original_labels[nr_sentence][i] == 2) or (original_labels[nr_sentence][i] == 4) or (original_labels[nr_sentence][i] == 6) or (original_labels[nr_sentence][i] == 8) ):\n","                    aligned_labels.append(original_labels[nr_sentence][i]+1)\n","                else:\n","                    aligned_labels.append(original_labels[nr_sentence][i])\n","                old_index = i\n","        else:\n","            for i in list_word_ids:\n","                if (i == old_index) and ( (original_labels[nr_sentence][i] == 2) or (original_labels[nr_sentence][i] == 4) ):\n","                    aligned_labels.append(original_labels[nr_sentence][i]+1)\n","                else:\n","                    aligned_labels.append(original_labels[nr_sentence][i])\n","                old_index = i\n","        aligned_global.append(aligned_labels)\n","\n","    return MAX_LEN, aligned_global\n","\n","print('Aligning labels...')\n","train_max_len, aligned_labels_train = align_labels(sentences_train, labels_train, MAX_LEN)\n","dev_max_len, aligned_labels_dev = align_labels(sentences_dev, labels_dev, MAX_LEN)\n","test_max_len, aligned_labels_test = align_labels(sentences_test, labels_test, MAX_LEN)\n","print('Labels aligned!')\n","CORRECTED_MAX_LEN = max(train_max_len, dev_max_len)\n","print('New defined MAX_LEN after tokenization is: ', CORRECTED_MAX_LEN)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Aligning labels...\n","Labels aligned!\n","New defined MAX_LEN after tokenization is:  113\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NZrwapYI85Bt"},"source":["The pre-processing of the data is finished with the padding of the new labels to the maximum lenght and the tokenization of the words."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7BvTz40BSMeJ","executionInfo":{"status":"ok","timestamp":1625760146825,"user_tz":-120,"elapsed":1249,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"ac26b515-1797-4e43-ce32-a5a9577b3e01"},"source":["# Padding labels according to corrected MAX_LEN\n","final_train_labels = pad_sequences(maxlen=CORRECTED_MAX_LEN, sequences=aligned_labels_train, padding=\"post\", value=tag_index[\"PAD\"]).tolist()\n","final_dev_labels = pad_sequences(maxlen=CORRECTED_MAX_LEN, sequences=aligned_labels_dev, padding=\"post\", value=tag_index[\"PAD\"]).tolist()\n","final_test_labels = pad_sequences(maxlen=CORRECTED_MAX_LEN, sequences=aligned_labels_test, padding=\"post\", value=tag_index[\"PAD\"]).tolist()\n","print('Labels padded')\n","\n","# Tokenize inputs according to corrected MAX_LEN\n","# train dataset\n","tokenized_input_train = tokenizer(sentences_train, truncation=True, max_length=CORRECTED_MAX_LEN, padding='max_length', is_split_into_words=True, add_special_tokens=False)\n","print('\\nTrain dataset:\\n\\tsentences lenght: {}.\\n\\tlabels lenght: {}.\\n\\tinput_ids length: {}.'.format(len(sentences_train), len(labels_train), len(tokenized_input_train['input_ids'])))\n","\n","# dev dataset\n","tokenized_input_dev = tokenizer(sentences_dev, truncation=True, max_length=CORRECTED_MAX_LEN, padding='max_length', is_split_into_words=True, add_special_tokens=False)\n","print('\\nDev dataset:\\n\\tsentences lenght: {}.\\n\\tlabels lenght: {}.\\n\\tinput_ids length: {}.'.format(len(sentences_dev), len(labels_dev), len(tokenized_input_dev['input_ids'])))\n","\n","# test dataset\n","tokenized_input_test = tokenizer(sentences_test, truncation=True, max_length=CORRECTED_MAX_LEN, padding='max_length', is_split_into_words=True, add_special_tokens=False)\n","print('\\nTest dataset:\\n\\tsentences lenght: {}.\\n\\tlabels lenght: {}.\\n\\tinput_ids length: {}.'.format(len(sentences_test), len(labels_test), len(tokenized_input_test['input_ids'])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Labels padded\n","\n","Train dataset:\n","\tsentences lenght: 6451.\n","\tlabels lenght: 6451.\n","\tinput_ids length: 6451.\n","\n","Dev dataset:\n","\tsentences lenght: 903.\n","\tlabels lenght: 903.\n","\tinput_ids length: 903.\n","\n","Test dataset:\n","\tsentences lenght: 1772.\n","\tlabels lenght: 1772.\n","\tinput_ids length: 1772.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GWN1XXZa9Fuj"},"source":["We now extract one example from the processed data to check the dimensions and alignment among all of the inputs."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9WxrBL85iDjQ","executionInfo":{"status":"ok","timestamp":1625760146826,"user_tz":-120,"elapsed":5,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"f7b4138c-614a-46ac-a860-fb3083042c68"},"source":["# Checking all is right\n","print(tokenized_input_dev.keys())\n","print(tokenized_input_dev['input_ids'][0])\n","print(tokenized_input_dev['attention_mask'][0])\n","print(final_dev_labels[0])\n","print('Length inputs: {}.\\nLength masks: {}.\\nLength labels: {}.'.format(len(tokenized_input_dev['input_ids'][0]), len(tokenized_input_dev['attention_mask'][0]), len(final_dev_labels[0])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n","[4937, 3239, 8715, 1006, 8292, 2015, 1007, 2003, 1037, 4678, 10381, 21716, 27642, 8761, 2008, 2089, 2022, 10358, 2012, 4182, 1012, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[2, 3, 3, 1, 2, 3, 1, 1, 1, 1, 4, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Length inputs: 113.\n","Length masks: 113.\n","Length labels: 113.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u2bbyah39e_t"},"source":["## 4. Definition of the model\n","\n","For reproducibility reasons, we fix a seed for PyTorch and convert all the data into tensors as the model requires."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XwA5hL_tj7zj","executionInfo":{"status":"ok","timestamp":1625760147159,"user_tz":-120,"elapsed":336,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"4e3b5e1d-0fe5-4c66-af8a-661abe62bb4a"},"source":["import torch\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","np.random.seed(42)\n","torch.backends.cudnn.deterministic=True\n","batch_size = 32 # 64\n","\n","# Convert all of our data into torch tensors, the required datatype for our model\n","train_inputs = torch.tensor(tokenized_input_train[\"input_ids\"])\n","train_masks = torch.tensor(tokenized_input_train[\"attention_mask\"])\n","train_labels = torch.tensor(final_train_labels)\n","\n","validation_inputs = torch.tensor(tokenized_input_dev[\"input_ids\"])\n","validation_masks = torch.tensor(tokenized_input_dev[\"attention_mask\"])\n","validation_labels = torch.tensor(final_dev_labels)\n","\n","test_inputs = torch.tensor(tokenized_input_test[\"input_ids\"])\n","test_masks = torch.tensor(tokenized_input_test[\"attention_mask\"])\n","test_labels = torch.tensor(final_test_labels)\n","\n","# Checking outputs\n","print('Train tensor shapes:')\n","print('Inputs: ', train_inputs.shape)\n","print('Masks: ', train_masks.shape)\n","print('Labels: ', train_labels.shape)\n","print('\\nValidation tensor shapes:')\n","print('Inputs: ', validation_inputs.shape)\n","print('Masks: ', validation_masks.shape)\n","print('Labels: ', validation_labels.shape)\n","print('\\nTest tensor shapes:')\n","print('Inputs: ', test_inputs.shape)\n","print('Masks: ', test_masks.shape)\n","print('Labels: ', test_labels.shape)\n","\n","# Create an iterator of our data with torch DataLoader \n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","shuffled_train_data = torch.utils.data.Subset(train_data, torch.randperm(len(train_data)).tolist())\n","train_dataloader = DataLoader(shuffled_train_data, batch_size=batch_size, shuffle=False)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","shuffled_validation_data = torch.utils.data.Subset(validation_data, torch.randperm(len(validation_data)).tolist())\n","validation_dataloader = DataLoader(shuffled_validation_data, batch_size=len(labels_dev), shuffle=False)\n","\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","shuffled_test_data = torch.utils.data.Subset(test_data, torch.randperm(len(test_data)).tolist())\n","test_dataloader = DataLoader(shuffled_test_data, batch_size=len(labels_test), shuffle=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train tensor shapes:\n","Inputs:  torch.Size([6451, 113])\n","Masks:  torch.Size([6451, 113])\n","Labels:  torch.Size([6451, 113])\n","\n","Validation tensor shapes:\n","Inputs:  torch.Size([903, 113])\n","Masks:  torch.Size([903, 113])\n","Labels:  torch.Size([903, 113])\n","\n","Test tensor shapes:\n","Inputs:  torch.Size([1772, 113])\n","Masks:  torch.Size([1772, 113])\n","Labels:  torch.Size([1772, 113])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AivweFUEgyrk"},"source":["We now charge the model into the cuda core."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0KWfz6HVpsN9","executionInfo":{"status":"ok","timestamp":1625760159070,"user_tz":-120,"elapsed":11912,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"57a60615-242f-4f7e-ac0a-801fcd84c3ef"},"source":["model.cuda()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"Pipz0b42-N_w"},"source":["Here, an example of the evaluation report is provided. For this, we use the `seqeval` library along with the labels or tags we desire to compute."]},{"cell_type":"code","metadata":{"id":"L9sQnkf_7fxU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625760159071,"user_tz":-120,"elapsed":14,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"b4aab105-8f42-4643-8c58-bd736393f356"},"source":["from sklearn_crfsuite.metrics import flat_classification_report\n","from seqeval.metrics.sequence_labeling import get_entities\n","from seqeval.metrics import classification_report, accuracy_score\n","from seqeval.scheme import IOB2\n","\n","\n","if allTypes:\n","    tags_metrics = ['O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'B-DISEASE', 'I-DISEASE', 'B-SIGN', 'I-SIGN', 'B-SYMPTOM', 'I-SYMPTOM']\n","else:\n","    tags_metrics = ['O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'B-SIGN-SYM', 'I-SIGN-SYM']\n","\n","\n","# Example of metrics\n","_labels = final_dev_labels[-10:]\n","_labels_output = [\n","        [l for l in sentence if l != 0]\n","        for sentence in _labels\n","    ]\n","_converted = [\n","        [tags_metrics[l-1] for l in sentence if l != 0]\n","        for sentence in _labels\n","    ]\n","_report = flat_classification_report(y_true=_converted, y_pred=_converted, labels=tags_metrics, digits=4)\n","\n","print('Tags: {}\\nEntities in tag: {}'.format(tags_metrics, get_entities(tags_metrics)))\n","print()\n","print('Nr of sentences with labels: {}\\nExample of labels: {}\\nConverted labels: {}'.format(len(_labels), _labels_output, _converted))\n","print()\n","print(_report)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tags: ['O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'B-DISEASE', 'I-DISEASE', 'B-SIGN', 'I-SIGN', 'B-SYMPTOM', 'I-SYMPTOM']\n","Entities in tag: [('RAREDISEASE', 1, 2), ('DISEASE', 3, 4), ('SIGN', 5, 6), ('SYMPTOM', 7, 8)]\n","\n","Nr of sentences with labels: 10\n","Example of labels: [[2, 3, 3, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 5, 5, 5, 5, 5, 5, 1], [1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1], [2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n","Converted labels: [['B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'O'], ['O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'B-DISEASE', 'I-DISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n","\n","               precision    recall  f1-score   support\n","\n","            O     1.0000    1.0000    1.0000       166\n","B-RAREDISEASE     1.0000    1.0000    1.0000         8\n","I-RAREDISEASE     1.0000    1.0000    1.0000        23\n","    B-DISEASE     1.0000    1.0000    1.0000         3\n","    I-DISEASE     1.0000    1.0000    1.0000         8\n","       B-SIGN     0.0000    0.0000    0.0000         0\n","       I-SIGN     0.0000    0.0000    0.0000         0\n","    B-SYMPTOM     0.0000    0.0000    0.0000         0\n","    I-SYMPTOM     0.0000    0.0000    0.0000         0\n","\n","    micro avg     1.0000    1.0000    1.0000       208\n","    macro avg     0.5556    0.5556    0.5556       208\n"," weighted avg     1.0000    1.0000    1.0000       208\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"zZ2zHZOn-gRL"},"source":["## 5. Fine tuning the model and training\n","\n","Finally, we define the model parameters and hyper parameters and its training."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jy6n8WG3rAQp","executionInfo":{"status":"ok","timestamp":1625760159072,"user_tz":-120,"elapsed":9,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"152db6fb-440c-4ab4-b148-3619d46d18fd"},"source":["# BERT fine-tuning parameters\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n","\n","optimizer = BertAdam(optimizer_grouped_parameters,\n","                     lr=2e-5,\n","                     warmup=.1)\n","\n","# Function to compute the metrics of our predictions vs labels\n","def flat_accuracy(predictions, labels):\n","    \"\"\"\n","    This function computes the accuracy of the network as a float number.\n","    \"\"\"\n","    pred_flat = np.argmax(predictions, axis=2).flatten()\n","    labels_flat = labels.flatten()\n","    valid_predictions = [tags_metrics[p-1] for (p, l) in zip(pred_flat, labels_flat) if l != 0]\n","    valid_flags = [tags_metrics[l-1] for (p, l) in zip(pred_flat, labels_flat) if l != 0]\n","    return accuracy_score(y_true=valid_flags, y_pred=valid_predictions)\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def compute_nn_metrics(predictions, labels, tags=tags_metrics, entity_level=False, imbalanced=False):\n","    \"\"\"\n","    This function computes the metrics of the network through the seqeval model.\n","    \"\"\"\n","    pred_flat = np.argmax(predictions, axis=2).flatten()\n","    labels_flat = labels.flatten()\n","    imbalanced_tags = [t for t in tags]\n","    imbalanced_tags.remove('O')\n","    valid_predictions = [[tags_metrics[p-1] for (p, l) in zip(pred_flat, labels_flat) if l != 0]]\n","    valid_flags = [[tags_metrics[l-1] for (p, l) in zip(pred_flat, labels_flat) if l != 0]]\n","    if entity_level:\n","        return classification_report(y_true=valid_flags, y_pred=valid_predictions, scheme=IOB2, zero_division=0, digits=4)\n","    else:\n","        if imbalanced:\n","            return flat_classification_report(y_true=valid_flags, y_pred=valid_predictions, labels=imbalanced_tags, zero_division=0, digits=4)\n","        else:\n","            return flat_classification_report(y_true=valid_flags, y_pred=valid_predictions, labels=tags, zero_division=0, digits=4)\n","        \n","\n","torch.cuda.empty_cache() \n","# Store our loss and accuracy for plotting\n","train_loss_set = []\n","eval_accuracy_set = []\n","# Number of training epochs \n","epochs = 9\n","\n","print('Model finetuned!\\nNr of epochs to use: {}'.format(epochs))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["t_total value of -1 results in schedule not being applied\n"],"name":"stderr"},{"output_type":"stream","text":["Model finetuned!\n","Nr of epochs to use: 9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1HlVLO_rgJP","executionInfo":{"status":"ok","timestamp":1625761505781,"user_tz":-120,"elapsed":1346715,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"4558e4f2-58ef-48dd-f231-d2141c3d507a"},"source":["# BERT training loop\n","for _ in trange(epochs, desc=\"Epoch\"):  \n","  \n","    ## TRAINING\n","\n","    # Set our model to training mode\n","    model.train()  \n","    # Tracking variables\n","    tr_loss, train_accuracy = 0, 0\n","    nb_train_steps = 0\n","    # Train the data for one epoch\n","    for step, batch in enumerate(train_dataloader):\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Clear out the gradients (by default they accumulate)\n","        optimizer.zero_grad()\n","        # Forward pass\n","        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","        train_loss_set.append(loss.item())   \n","        # Backward pass\n","        loss.backward()\n","        # Update parameters and take a step using the computed gradient\n","        optimizer.step()\n","        # Update tracking variables\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        tmp_train_accuracy = flat_accuracy(logits, label_ids)\n","        train_accuracy += tmp_train_accuracy\n","        tr_loss += loss.item()\n","        nb_train_steps += 1\n","    print(\"\\nTrain loss: {}\".format(tr_loss/nb_train_steps))\n","    print(\"Total Train Accuracy: {}\".format(train_accuracy/nb_train_steps))\n","\n","    ## VALIDATION\n","\n","    # Put model in evaluation mode\n","    model.eval()\n","    # Tracking variables \n","    eval_accuracy = 0\n","    nb_eval_steps = 0\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","        with torch.no_grad():\n","            # Forward pass, calculate logit predictions\n","            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","            logits = outputs.logits\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        eval_metrics = compute_nn_metrics(logits, label_ids)\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy   \n","        eval_accuracy_set.append(tmp_eval_accuracy)    \n","        nb_eval_steps += 1\n","    print('\\nMetrics report in Validation:\\n{}'.format(eval_metrics))\n","    print(\"Total Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\rEpoch:   0%|          | 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Train loss: 0.44848302117373684\n","Total Train Accuracy: 0.8553626908954692\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  11%|█         | 1/9 [02:17<18:20, 137.59s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9502    0.9600    0.9551     16334\n","B-RAREDISEASE     0.7830    0.8791    0.8283       513\n","I-RAREDISEASE     0.8453    0.9099    0.8764      1909\n","    B-DISEASE     0.6303    0.4771    0.5431       218\n","    I-DISEASE     0.5560    0.5245    0.5398       530\n","       B-SIGN     0.5838    0.7136    0.6422       405\n","       I-SIGN     0.7103    0.5941    0.6470      1993\n","    B-SYMPTOM     0.0000    0.0000    0.0000        18\n","    I-SYMPTOM     0.0000    0.0000    0.0000        40\n","\n","     accuracy                         0.8982     21960\n","    macro avg     0.5621    0.5620    0.5591     21960\n"," weighted avg     0.8935    0.8982    0.8949     21960\n","\n","Total Validation Accuracy: 0.8981785063752277\n","\n","Train loss: 0.20427991650851057\n","Total Train Accuracy: 0.9307160042413355\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  22%|██▏       | 2/9 [04:45<16:25, 140.83s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9661    0.9496    0.9577     16334\n","B-RAREDISEASE     0.8185    0.8967    0.8558       513\n","I-RAREDISEASE     0.8553    0.9508    0.9005      1909\n","    B-DISEASE     0.7012    0.5275    0.6021       218\n","    I-DISEASE     0.6553    0.5453    0.5953       530\n","       B-SIGN     0.6162    0.7531    0.6778       405\n","       I-SIGN     0.6839    0.7165    0.6998      1993\n","    B-SYMPTOM     0.6667    0.2222    0.3333        18\n","    I-SYMPTOM     0.5556    0.3750    0.4478        40\n","\n","     accuracy                         0.9081     21960\n","    macro avg     0.7243    0.6596    0.6745     21960\n"," weighted avg     0.9098    0.9081    0.9081     21960\n","\n","Total Validation Accuracy: 0.9080601092896174\n","\n","Train loss: 0.13252825781444807\n","Total Train Accuracy: 0.956617095733282\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  33%|███▎      | 3/9 [07:17<14:24, 144.05s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9543    0.9696    0.9619     16334\n","B-RAREDISEASE     0.8262    0.8986    0.8609       513\n","I-RAREDISEASE     0.8678    0.9424    0.9036      1909\n","    B-DISEASE     0.6931    0.6009    0.6437       218\n","    I-DISEASE     0.6529    0.5962    0.6233       530\n","       B-SIGN     0.7224    0.6617    0.6907       405\n","       I-SIGN     0.7798    0.6342    0.6995      1993\n","    B-SYMPTOM     0.3929    0.6111    0.4783        18\n","    I-SYMPTOM     0.4250    0.4250    0.4250        40\n","\n","     accuracy                         0.9155     21960\n","    macro avg     0.7016    0.7044    0.6985     21960\n"," weighted avg     0.9124    0.9155    0.9130     21960\n","\n","Total Validation Accuracy: 0.9155282331511839\n","\n","Train loss: 0.09982695573442939\n","Total Train Accuracy: 0.9676845008952502\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  44%|████▍     | 4/9 [09:48<12:11, 146.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9486    0.9714    0.9599     16334\n","B-RAREDISEASE     0.8367    0.8986    0.8665       513\n","I-RAREDISEASE     0.8785    0.9466    0.9112      1909\n","    B-DISEASE     0.7305    0.5596    0.6338       218\n","    I-DISEASE     0.7242    0.5698    0.6378       530\n","       B-SIGN     0.7010    0.6889    0.6949       405\n","       I-SIGN     0.7599    0.6162    0.6805      1993\n","    B-SYMPTOM     0.5556    0.2778    0.3704        18\n","    I-SYMPTOM     0.5789    0.2750    0.3729        40\n","\n","     accuracy                         0.9145     21960\n","    macro avg     0.7460    0.6449    0.6809     21960\n"," weighted avg     0.9097    0.9145    0.9107     21960\n","\n","Total Validation Accuracy: 0.9144808743169399\n","\n","Train loss: 0.08067422480055012\n","Total Train Accuracy: 0.974605717268445\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  56%|█████▌    | 5/9 [12:20<09:51, 147.82s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9576    0.9656    0.9616     16334\n","B-RAREDISEASE     0.8466    0.8928    0.8691       513\n","I-RAREDISEASE     0.8888    0.9293    0.9086      1909\n","    B-DISEASE     0.7067    0.6743    0.6901       218\n","    I-DISEASE     0.6513    0.6943    0.6721       530\n","       B-SIGN     0.7178    0.7160    0.7169       405\n","       I-SIGN     0.7621    0.6573    0.7058      1993\n","    B-SYMPTOM     0.5000    0.6111    0.5500        18\n","    I-SYMPTOM     0.5882    0.5000    0.5405        40\n","\n","     accuracy                         0.9176     21960\n","    macro avg     0.7355    0.7379    0.7350     21960\n"," weighted avg     0.9159    0.9176    0.9163     21960\n","\n","Total Validation Accuracy: 0.9175774134790529\n","\n","Train loss: 0.06042710548073127\n","Total Train Accuracy: 0.9810739414974176\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  67%|██████▋   | 6/9 [14:51<07:26, 148.91s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9579    0.9657    0.9618     16334\n","B-RAREDISEASE     0.8555    0.8772    0.8662       513\n","I-RAREDISEASE     0.8926    0.9314    0.9116      1909\n","    B-DISEASE     0.7065    0.6514    0.6778       218\n","    I-DISEASE     0.6931    0.6774    0.6851       530\n","       B-SIGN     0.7287    0.6963    0.7121       405\n","       I-SIGN     0.7513    0.6744    0.7107      1993\n","    B-SYMPTOM     0.4667    0.7778    0.5833        18\n","    I-SYMPTOM     0.4400    0.5500    0.4889        40\n","\n","     accuracy                         0.9183     21960\n","    macro avg     0.7213    0.7557    0.7331     21960\n"," weighted avg     0.9166    0.9183    0.9171     21960\n","\n","Total Validation Accuracy: 0.9182604735883424\n","\n","Train loss: 0.04586311814716399\n","Total Train Accuracy: 0.9862901345579516\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  78%|███████▊  | 7/9 [17:23<04:59, 149.74s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9553    0.9676    0.9614     16334\n","B-RAREDISEASE     0.8382    0.8889    0.8628       513\n","I-RAREDISEASE     0.8913    0.9146    0.9028      1909\n","    B-DISEASE     0.6857    0.6606    0.6729       218\n","    I-DISEASE     0.6373    0.6830    0.6594       530\n","       B-SIGN     0.6992    0.6889    0.6940       405\n","       I-SIGN     0.7730    0.6458    0.7037      1993\n","    B-SYMPTOM     0.5385    0.7778    0.6364        18\n","    I-SYMPTOM     0.4667    0.5250    0.4941        40\n","\n","     accuracy                         0.9159     21960\n","    macro avg     0.7206    0.7502    0.7319     21960\n"," weighted avg     0.9142    0.9159    0.9144     21960\n","\n","Total Validation Accuracy: 0.9159380692167577\n","\n","Train loss: 0.0388124606521376\n","Total Train Accuracy: 0.9881077423743873\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  89%|████████▉ | 8/9 [19:55<02:30, 150.27s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9577    0.9643    0.9610     16334\n","B-RAREDISEASE     0.8345    0.9045    0.8681       513\n","I-RAREDISEASE     0.8755    0.9429    0.9079      1909\n","    B-DISEASE     0.7056    0.6376    0.6699       218\n","    I-DISEASE     0.6876    0.6189    0.6514       530\n","       B-SIGN     0.7153    0.7136    0.7145       405\n","       I-SIGN     0.7552    0.6608    0.7048      1993\n","    B-SYMPTOM     0.4242    0.7778    0.5490        18\n","    I-SYMPTOM     0.4468    0.5250    0.4828        40\n","\n","     accuracy                         0.9163     21960\n","    macro avg     0.7114    0.7495    0.7233     21960\n"," weighted avg     0.9145    0.9163    0.9149     21960\n","\n","Total Validation Accuracy: 0.9163479052823316\n","\n","Train loss: 0.03338139375330567\n","Total Train Accuracy: 0.9898580077235\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch: 100%|██████████| 9/9 [22:26<00:00, 149.62s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9652    0.9608    0.9630     16334\n","B-RAREDISEASE     0.8435    0.8928    0.8674       513\n","I-RAREDISEASE     0.8820    0.9240    0.9025      1909\n","    B-DISEASE     0.6711    0.7018    0.6861       218\n","    I-DISEASE     0.6498    0.6792    0.6642       530\n","       B-SIGN     0.6884    0.7309    0.7090       405\n","       I-SIGN     0.7493    0.7050    0.7265      1993\n","    B-SYMPTOM     0.4667    0.7778    0.5833        18\n","    I-SYMPTOM     0.5122    0.5250    0.5185        40\n","\n","     accuracy                         0.9182     21960\n","    macro avg     0.7142    0.7664    0.7356     21960\n"," weighted avg     0.9187    0.9182    0.9183     21960\n","\n","Total Validation Accuracy: 0.9182149362477231\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"CfY260HEyfWT","colab":{"base_uri":"https://localhost:8080/","height":616},"executionInfo":{"status":"ok","timestamp":1625761506372,"user_tz":-120,"elapsed":595,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"5214f86c-136f-487d-d19b-db7368a25ace"},"source":["# plot training performance\n","results_figure = plt.figure(figsize=(18,9))\n","ax_train = results_figure.add_subplot(1, 2, 1)\n","ax_val = results_figure.add_subplot(1, 2, 2)\n","results_figure.suptitle('BioBERT Results')\n","ax_train.set_title(\"Training loss evolution\")\n","ax_train.set_xlabel(\"Batch\")\n","ax_train.set_ylabel(\"Loss\")\n","ax_train.plot(train_loss_set)\n","ax_val.set_title(\"Validation accuracy evolution\")\n","ax_val.set_xlabel(\"Batch\")\n","ax_val.set_ylabel(\"Accuracy\")\n","ax_val.plot(eval_accuracy_set)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1296x648 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"bL8Yp-Kz_N7b"},"source":["## 6. Testing the model\n","\n","The final step is to test the model. This step is similar to the evaluation one with the difference that the input dataset is changed."]},{"cell_type":"code","metadata":{"id":"orWXD7pk0GgF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625761521236,"user_tz":-120,"elapsed":14868,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"a39dcef1-b4e9-48c6-ba13-ce931c7cb84c"},"source":["## TEST\n","\n","# Put model in evaluation mode\n","model.eval()\n","# Evaluate data for one epoch\n","for batch in test_dataloader:\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","    with torch.no_grad():\n","        # Forward pass, calculate logit predictions\n","        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","        logits = outputs.logits   \n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    test_metrics = compute_nn_metrics(logits, label_ids)\n","    test_metrics_imbalanced = compute_nn_metrics(logits, label_ids, imbalanced=True)\n","    test_metrics_per_entity = compute_nn_metrics(logits, label_ids, entity_level=True)\n","print('Metrics report in Test (with \"O\" class):\\n{}'.format(test_metrics))\n","print('Metrics report in Test (w/o \"O\" class):\\n{}'.format(test_metrics_imbalanced))\n","print('Metrics report in Test per entity:\\n{}'.format(test_metrics_per_entity))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Metrics report in Test (with \"O\" class):\n","               precision    recall  f1-score   support\n","\n","            O     0.9708    0.9523    0.9615     34316\n","B-RAREDISEASE     0.8451    0.9003    0.8718      1073\n","I-RAREDISEASE     0.8704    0.9024    0.8861      3842\n","    B-DISEASE     0.6012    0.6637    0.6309       443\n","    I-DISEASE     0.5186    0.5884    0.5513      1137\n","       B-SIGN     0.6514    0.7073    0.6782       803\n","       I-SIGN     0.6725    0.7099    0.6907      3430\n","    B-SYMPTOM     0.6607    0.7400    0.6981        50\n","    I-SYMPTOM     0.6000    0.4918    0.5405       122\n","\n","     accuracy                         0.9107     45216\n","    macro avg     0.7101    0.7396    0.7232     45216\n"," weighted avg     0.9147    0.9107    0.9124     45216\n","\n","Metrics report in Test (w/o \"O\" class):\n","               precision    recall  f1-score   support\n","\n","B-RAREDISEASE     0.8451    0.9003    0.8718      1073\n","I-RAREDISEASE     0.8704    0.9024    0.8861      3842\n","    B-DISEASE     0.6012    0.6637    0.6309       443\n","    I-DISEASE     0.5186    0.5884    0.5513      1137\n","       B-SIGN     0.6514    0.7073    0.6782       803\n","       I-SIGN     0.6725    0.7099    0.6907      3430\n","    B-SYMPTOM     0.6607    0.7400    0.6981        50\n","    I-SYMPTOM     0.6000    0.4918    0.5405       122\n","\n","    micro avg     0.7353    0.7794    0.7567     10900\n","    macro avg     0.6775    0.7130    0.6935     10900\n"," weighted avg     0.7379    0.7794    0.7579     10900\n","\n","Metrics report in Test per entity:\n","              precision    recall  f1-score   support\n","\n","     DISEASE     0.5197    0.6101    0.5613       454\n"," RAREDISEASE     0.8008    0.8667    0.8325      1095\n","        SIGN     0.5079    0.6033    0.5515       958\n","     SYMPTOM     0.5469    0.6481    0.5932        54\n","\n","   micro avg     0.6298    0.7181    0.6710      2561\n","   macro avg     0.5938    0.6821    0.6346      2561\n","weighted avg     0.6361    0.7181    0.6743      2561\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o2naPUQ2RQeM"},"source":["Scenarios:\n","\n","    - I. Surface string and entity type match\n","    - II. System hypothesized an entity\n","    - III. System misses an entity\n","    - IV. System assigns the wrong entity type\n","    - V. System gets the boundaries of the surface string wrong\n","    - VI. System gets the boundaries and entity type wrong\n","\n","MUC metrics:\n","\n","    - Correct (COR) : both are the same\n","    - Incorrect (INC) : the output of a system and the golden annotation don’t match\n","    - Partial (PAR) : system and the golden annotation are somewhat “similar” but not the same\n","    - Missing (MIS) : a golden annotation is not captured by a system\n","    - Spurius (SPU) : system produces a response which doesn’t exist in the golden annotation\n","\n","Four different ways to measure precision/recall/f1-score:\n","\n","    - Strict: exact boundary surface string match and entity type\n","    - Exact: exact boundary match over the surface string, regardless of the type\n","    - Partial: partial boundary match over the surface string, regardless of the type\n","    - Type: some overlap between the system tagged entity and the gold annotation is required\n"]},{"cell_type":"code","metadata":{"id":"yv6oob40RPgi"},"source":["import logging\n","from collections import namedtuple\n","from copy import deepcopy\n","\n","logging.basicConfig(\n","    format=\"%(asctime)s %(name)s %(levelname)s: %(message)s\",\n","    datefmt=\"%Y-%m-%d %H:%M:%S\",\n","    level=\"DEBUG\",\n",")\n","\n","Entity = namedtuple(\"Entity\", \"e_type start_offset end_offset\")\n","\n","class Evaluator():\n","\n","    def __init__(self, true, pred, tags):\n","        \"\"\"\n","        \"\"\"\n","\n","        if len(true) != len(pred):\n","            raise ValueError(\"Number of predicted documents does not equal true\")\n","\n","        self.true = true\n","        self.pred = pred\n","        self.tags = tags\n","\n","        # Setup dict into which metrics will be stored.\n","\n","        self.metrics_results = {\n","            'correct': 0,\n","            'incorrect': 0,\n","            'partial': 0,\n","            'missed': 0,\n","            'spurious': 0,\n","            'possible': 0,\n","            'actual': 0,\n","            'precision': 0,\n","            'recall': 0,\n","        }\n","\n","        # Copy results dict to cover the four schemes.\n","\n","        self.results = {\n","            'strict': deepcopy(self.metrics_results),\n","            'ent_type': deepcopy(self.metrics_results),\n","            'partial':deepcopy(self.metrics_results),\n","            'exact':deepcopy(self.metrics_results),\n","            }\n","\n","        # Create an accumulator to store results\n","\n","        self.evaluation_agg_entities_type = {e: deepcopy(self.results) for e in tags}\n","\n","\n","    def evaluate(self):\n","\n","        logging.info(\n","            \"Imported %s predictions for %s true examples\",\n","            len(self.pred), len(self.true)\n","        )\n","\n","        for true_ents, pred_ents in zip(self.true, self.pred):\n","\n","            # Check that the length of the true and predicted examples are the\n","            # same. This must be checked here, because another error may not\n","            # be thrown if the lengths do not match.\n","\n","            if len(true_ents) != len(pred_ents):\n","                raise ValueError(\"Prediction length does not match true example length\")\n","\n","            # Compute results for one message\n","\n","            tmp_results, tmp_agg_results = compute_metrics(\n","                collect_named_entities(true_ents),\n","                collect_named_entities(pred_ents),\n","                self.tags\n","            )\n","\n","            # Cycle through each result and accumulate\n","\n","            # TODO: Combine these loops below:\n","\n","            for eval_schema in self.results:\n","\n","                for metric in self.results[eval_schema]:\n","\n","                    self.results[eval_schema][metric] += tmp_results[eval_schema][metric]\n","\n","            # Calculate global precision and recall\n","\n","            self.results = compute_precision_recall_wrapper(self.results)\n","\n","            # Aggregate results by entity type\n","\n","            for e_type in self.tags:\n","\n","                for eval_schema in tmp_agg_results[e_type]:\n","\n","                    for metric in tmp_agg_results[e_type][eval_schema]:\n","\n","                        self.evaluation_agg_entities_type[e_type][eval_schema][metric] += tmp_agg_results[e_type][eval_schema][metric]\n","\n","                # Calculate precision recall at the individual entity level\n","\n","                self.evaluation_agg_entities_type[e_type] = compute_precision_recall_wrapper(self.evaluation_agg_entities_type[e_type])\n","\n","        return self.results, self.evaluation_agg_entities_type\n","\n","\n","def collect_named_entities(tokens):\n","    \"\"\"\n","    Creates a list of Entity named-tuples, storing the entity type and the start and end\n","    offsets of the entity.\n","    :param tokens: a list of tags\n","    :return: a list of Entity named-tuples\n","    \"\"\"\n","\n","    named_entities = []\n","    start_offset = None\n","    end_offset = None\n","    ent_type = None\n","\n","    for offset, token_tag in enumerate(tokens):\n","\n","        if token_tag == 'O':\n","            if ent_type is not None and start_offset is not None:\n","                end_offset = offset - 1\n","                named_entities.append(Entity(ent_type, start_offset, end_offset))\n","                start_offset = None\n","                end_offset = None\n","                ent_type = None\n","\n","        elif ent_type is None:\n","            ent_type = token_tag[2:]\n","            start_offset = offset\n","\n","        elif ent_type != token_tag[2:] or (ent_type == token_tag[2:] and token_tag[:1] == 'B'):\n","\n","            end_offset = offset - 1\n","            named_entities.append(Entity(ent_type, start_offset, end_offset))\n","\n","            # start of a new entity\n","            ent_type = token_tag[2:]\n","            start_offset = offset\n","            end_offset = None\n","\n","    # catches an entity that goes up until the last token\n","\n","    if ent_type is not None and start_offset is not None and end_offset is None:\n","        named_entities.append(Entity(ent_type, start_offset, len(tokens)-1))\n","\n","    return named_entities\n","\n","\n","def compute_metrics(true_named_entities, pred_named_entities, tags):\n","\n","\n","    eval_metrics = {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'precision': 0, 'recall': 0}\n","\n","    # overall results\n","    \n","    evaluation = {\n","        'strict': deepcopy(eval_metrics),\n","        'ent_type': deepcopy(eval_metrics),\n","        'partial': deepcopy(eval_metrics),\n","        'exact': deepcopy(eval_metrics)\n","    }\n","\n","    # results by entity type\n","\n","    evaluation_agg_entities_type = {e: deepcopy(evaluation) for e in tags}\n","\n","    # keep track of entities that overlapped\n","\n","    true_which_overlapped_with_pred = []\n","\n","    # Subset into only the tags that we are interested in.\n","    # NOTE: we remove the tags we don't want from both the predicted and the\n","    # true entities. This covers the two cases where mismatches can occur:\n","    #\n","    # 1) Where the model predicts a tag that is not present in the true data\n","    # 2) Where there is a tag in the true data that the model is not capable of\n","    # predicting.\n","\n","    true_named_entities = [ent for ent in true_named_entities if ent.e_type in tags]\n","    pred_named_entities = [ent for ent in pred_named_entities if ent.e_type in tags]\n","\n","    # go through each predicted named-entity\n","\n","    for pred in pred_named_entities:\n","        found_overlap = False\n","\n","        # Check each of the potential scenarios in turn. See\n","        # http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/\n","        # for scenario explanation.\n","\n","        # Scenario I: Exact match between true and pred\n","\n","        if pred in true_named_entities:\n","            true_which_overlapped_with_pred.append(pred)\n","            evaluation['strict']['correct'] += 1\n","            evaluation['ent_type']['correct'] += 1\n","            evaluation['exact']['correct'] += 1\n","            evaluation['partial']['correct'] += 1\n","\n","            # for the agg. by e_type results\n","            evaluation_agg_entities_type[pred.e_type]['strict']['correct'] += 1\n","            evaluation_agg_entities_type[pred.e_type]['ent_type']['correct'] += 1\n","            evaluation_agg_entities_type[pred.e_type]['exact']['correct'] += 1\n","            evaluation_agg_entities_type[pred.e_type]['partial']['correct'] += 1\n","\n","        else:\n","\n","            # check for overlaps with any of the true entities\n","\n","            for true in true_named_entities:\n","\n","                pred_range = range(pred.start_offset, pred.end_offset)\n","                true_range = range(true.start_offset, true.end_offset)\n","\n","                # Scenario IV: Offsets match, but entity type is wrong\n","\n","                if true.start_offset == pred.start_offset and pred.end_offset == true.end_offset \\\n","                        and true.e_type != pred.e_type:\n","\n","                    # overall results\n","                    evaluation['strict']['incorrect'] += 1\n","                    evaluation['ent_type']['incorrect'] += 1\n","                    evaluation['partial']['correct'] += 1\n","                    evaluation['exact']['correct'] += 1\n","\n","                    # aggregated by entity type results\n","                    evaluation_agg_entities_type[true.e_type]['strict']['incorrect'] += 1\n","                    evaluation_agg_entities_type[true.e_type]['ent_type']['incorrect'] += 1\n","                    evaluation_agg_entities_type[true.e_type]['partial']['correct'] += 1\n","                    evaluation_agg_entities_type[true.e_type]['exact']['correct'] += 1\n","\n","                    true_which_overlapped_with_pred.append(true)\n","                    found_overlap = True\n","\n","                    break\n","\n","                # check for an overlap i.e. not exact boundary match, with true entities\n","\n","                elif find_overlap(true_range, pred_range):\n","\n","                    true_which_overlapped_with_pred.append(true)\n","\n","                    # Scenario V: There is an overlap (but offsets do not match\n","                    # exactly), and the entity type is the same.\n","                    # 2.1 overlaps with the same entity type\n","\n","                    if pred.e_type == true.e_type:\n","\n","                        # overall results\n","                        evaluation['strict']['incorrect'] += 1\n","                        evaluation['ent_type']['correct'] += 1\n","                        evaluation['partial']['partial'] += 1\n","                        evaluation['exact']['incorrect'] += 1\n","\n","                        # aggregated by entity type results\n","                        evaluation_agg_entities_type[true.e_type]['strict']['incorrect'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['ent_type']['correct'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['partial']['partial'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['exact']['incorrect'] += 1\n","\n","                        found_overlap = True\n","\n","                        break\n","\n","                    # Scenario VI: Entities overlap, but the entity type is\n","                    # different.\n","\n","                    else:\n","                        # overall results\n","                        evaluation['strict']['incorrect'] += 1\n","                        evaluation['ent_type']['incorrect'] += 1\n","                        evaluation['partial']['partial'] += 1\n","                        evaluation['exact']['incorrect'] += 1\n","\n","                        # aggregated by entity type results\n","                        # Results against the true entity\n","\n","                        evaluation_agg_entities_type[true.e_type]['strict']['incorrect'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['partial']['partial'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['ent_type']['incorrect'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['exact']['incorrect'] += 1\n","\n","                        # Results against the predicted entity\n","\n","                        # evaluation_agg_entities_type[pred.e_type]['strict']['spurious'] += 1\n","\n","                        found_overlap = True\n","\n","                        break\n","\n","            # Scenario II: Entities are spurious (i.e., over-generated).\n","\n","            if not found_overlap:\n","\n","                # Overall results\n","\n","                evaluation['strict']['spurious'] += 1\n","                evaluation['ent_type']['spurious'] += 1\n","                evaluation['partial']['spurious'] += 1\n","                evaluation['exact']['spurious'] += 1\n","\n","                # Aggregated by entity type results\n","\n","                # NOTE: when pred.e_type is not found in tags\n","                # or when it simply does not appear in the test set, then it is\n","                # spurious, but it is not clear where to assign it at the tag\n","                # level. In this case, it is applied to all target_tags\n","                # found in this example. This will mean that the sum of the\n","                # evaluation_agg_entities will not equal evaluation.\n","\n","                for true in tags:                    \n","\n","                    evaluation_agg_entities_type[true]['strict']['spurious'] += 1\n","                    evaluation_agg_entities_type[true]['ent_type']['spurious'] += 1\n","                    evaluation_agg_entities_type[true]['partial']['spurious'] += 1\n","                    evaluation_agg_entities_type[true]['exact']['spurious'] += 1\n","\n","    # Scenario III: Entity was missed entirely.\n","\n","    for true in true_named_entities:\n","        if true in true_which_overlapped_with_pred:\n","            continue\n","        else:\n","            # overall results\n","            evaluation['strict']['missed'] += 1\n","            evaluation['ent_type']['missed'] += 1\n","            evaluation['partial']['missed'] += 1\n","            evaluation['exact']['missed'] += 1\n","\n","            # for the agg. by e_type\n","            evaluation_agg_entities_type[true.e_type]['strict']['missed'] += 1\n","            evaluation_agg_entities_type[true.e_type]['ent_type']['missed'] += 1\n","            evaluation_agg_entities_type[true.e_type]['partial']['missed'] += 1\n","            evaluation_agg_entities_type[true.e_type]['exact']['missed'] += 1\n","\n","    # Compute 'possible', 'actual' according to SemEval-2013 Task 9.1 on the\n","    # overall results, and use these to calculate precision and recall.\n","\n","    for eval_type in evaluation:\n","        evaluation[eval_type] = compute_actual_possible(evaluation[eval_type])\n","\n","    # Compute 'possible', 'actual', and precision and recall on entity level\n","    # results. Start by cycling through the accumulated results.\n","\n","    for entity_type, entity_level in evaluation_agg_entities_type.items():\n","\n","        # Cycle through the evaluation types for each dict containing entity\n","        # level results.\n","\n","        for eval_type in entity_level:\n","\n","            evaluation_agg_entities_type[entity_type][eval_type] = compute_actual_possible(\n","                entity_level[eval_type]\n","            )\n","\n","    return evaluation, evaluation_agg_entities_type\n","\n","\n","def find_overlap(true_range, pred_range):\n","    \"\"\"Find the overlap between two ranges\n","    Find the overlap between two ranges. Return the overlapping values if\n","    present, else return an empty set().\n","    Examples:\n","    >>> find_overlap((1, 2), (2, 3))\n","    2\n","    >>> find_overlap((1, 2), (3, 4))\n","    set()\n","    \"\"\"\n","\n","    true_set = set(true_range)\n","    pred_set = set(pred_range)\n","\n","    overlaps = true_set.intersection(pred_set)\n","\n","    return overlaps\n","\n","\n","def compute_actual_possible(results):\n","    \"\"\"\n","    Takes a result dict that has been output by compute metrics.\n","    Returns the results dict with actual, possible populated.\n","    When the results dicts is from partial or ent_type metrics, then\n","    partial_or_type=True to ensure the right calculation is used for\n","    calculating precision and recall.\n","    \"\"\"\n","\n","    correct = results['correct']\n","    incorrect = results['incorrect']\n","    partial = results['partial']\n","    missed = results['missed']\n","    spurious = results['spurious']\n","\n","    # Possible: number annotations in the gold-standard which contribute to the\n","    # final score\n","\n","    possible = correct + incorrect + partial + missed\n","\n","    # Actual: number of annotations produced by the NER system\n","\n","    actual = correct + incorrect + partial + spurious\n","\n","    results[\"actual\"] = actual\n","    results[\"possible\"] = possible\n","\n","    return results\n","\n","\n","def compute_precision_recall(results, partial_or_type=False):\n","    \"\"\"\n","    Takes a result dict that has been output by compute metrics.\n","    Returns the results dict with precison and recall populated.\n","    When the results dicts is from partial or ent_type metrics, then\n","    partial_or_type=True to ensure the right calculation is used for\n","    calculating precision and recall.\n","    \"\"\"\n","\n","    actual = results[\"actual\"]\n","    possible = results[\"possible\"]\n","    partial = results['partial']\n","    correct = results['correct']\n","\n","    if partial_or_type:\n","        precision = (correct + 0.5 * partial) / actual if actual > 0 else 0\n","        recall = (correct + 0.5 * partial) / possible if possible > 0 else 0\n","\n","    else:\n","        precision = correct / actual if actual > 0 else 0\n","        recall = correct / possible if possible > 0 else 0\n","\n","    results[\"precision\"] = precision\n","    results[\"recall\"] = recall\n","\n","    return results\n","\n","\n","def compute_precision_recall_wrapper(results):\n","    \"\"\"\n","    Wraps the compute_precision_recall function and runs on a dict of results\n","    \"\"\"\n","\n","    results_a = {key: compute_precision_recall(value, True) for key, value in results.items() if\n","                 key in ['partial', 'ent_type']}\n","    results_b = {key: compute_precision_recall(value) for key, value in results.items() if\n","                 key in ['strict', 'exact']}\n","\n","    results = {**results_a, **results_b}\n","\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z7MzfEKfRpys","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625761523107,"user_tz":-120,"elapsed":798,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"30fe3920-17a1-47a0-be7e-3998c1ed5fc3"},"source":["inputs_idxs = b_input_ids.to('cpu').numpy()\n","inputs_idxs = [[i for i in sentence if i != 0] for sentence in inputs_idxs]\n","inputs_idxs = [tokenizer.convert_ids_to_tokens(sentence) for sentence in inputs_idxs]\n","pred_flat = np.argmax(logits, axis=2)\n","pred_sym = [[tags_metrics[l-1] for l in sentence if l != 0] for sentence in pred_flat]\n","true_flags = [[tags_metrics[l-1] for l in sentence if l != 0] for sentence in label_ids]\n","pred_flags = []\n","\n","for sp, st in zip(pred_sym, true_flags):\n","    limit = len(st)\n","    new = sp[:limit]\n","    pred_flags.append(new)\n","\n","print('Labels and sentences created')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Labels and sentences created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l9qcbi72Ra02","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625761523576,"user_tz":-120,"elapsed":472,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"d9612ddc-56db-40cb-c62a-78c9834de511"},"source":["import random\n","\n","random.seed(3)\n","result_examples_idx = random.sample(range(len(true_flags)), k=30)\n","result_examples_y_gold = list()\n","result_examples_y_pred = list()\n","original_sentences = list()\n","\n","for idx in result_examples_idx:\n","    result_examples_y_gold.append(true_flags[idx])\n","    result_examples_y_pred.append(pred_flags[idx])\n","    original_sentences.append(inputs_idxs[idx])\n","\n","itr = 0\n","for g, p, s in zip(result_examples_y_gold, result_examples_y_pred, original_sentences):\n","    assert len(g) == len(p), 'Results does not seem to be the same'\n","    print('Sentence Nr: ', result_examples_idx[itr])\n","    original_s = pd.Series(s, name='WORD')\n","    df = pd.DataFrame(original_s)\n","    df['GOLD'] = g\n","    df['PRED'] = p\n","    print(df)\n","    itr += 1\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sentence Nr:  487\n","             WORD           GOLD           PRED\n","0             the              O              O\n","1           major              O              O\n","2        physical              O              O\n","3        features              O              O\n","4              of              O              O\n","5           adams  B-RAREDISEASE  B-RAREDISEASE\n","6               -  I-RAREDISEASE  I-RAREDISEASE\n","7          oliver  I-RAREDISEASE  I-RAREDISEASE\n","8        syndrome  I-RAREDISEASE  I-RAREDISEASE\n","9               (              O              O\n","10              i              O              O\n","11              .              O              O\n","12              e              O              O\n","13              .              O              O\n","14              ,              O              O\n","15          scalp         B-SIGN         B-SIGN\n","16        defects         I-SIGN         I-SIGN\n","17            and              O              O\n","18           limb              O         B-SIGN\n","19  abnormalities              O         I-SIGN\n","20              )              O              O\n","21            are              O              O\n","22       apparent              O              O\n","23             at              O              O\n","24          birth              O              O\n","25              (              O              O\n","26     congenital         I-SIGN         I-SIGN\n","27              )              O              O\n","28              .              O              O\n","\n","Sentence Nr:  1213\n","             WORD           GOLD           PRED\n","0           there              O              O\n","1             are              O              O\n","2        numerous              O              O\n","3      conditions              O              O\n","4   characterized              O              O\n","5              by              O              O\n","6           signs              O              O\n","7             and              O              O\n","8        symptoms              O              O\n","9            that              O              O\n","10            are              O              O\n","11        similar              O              O\n","12             to              O              O\n","13          those              O              O\n","14          found              O              O\n","15             in              O              O\n","16            ara  B-RAREDISEASE  B-RAREDISEASE\n","17           ##ch  I-RAREDISEASE  I-RAREDISEASE\n","18           ##no  I-RAREDISEASE  I-RAREDISEASE\n","19          ##idi  I-RAREDISEASE  I-RAREDISEASE\n","20          ##tis  I-RAREDISEASE  I-RAREDISEASE\n","21              ,              O              O\n","22        however              O              O\n","23              ,              O              O\n","24           only              O              O\n","25              a              O              O\n","26            few              O              O\n","27           will              O              O\n","28             be              O              O\n","29         listed              O              O\n","30              .              O              O\n","\n","Sentence Nr:  1114\n","           WORD           GOLD           PRED\n","0           dry         B-SIGN      B-DISEASE\n","1         cough         I-SIGN  I-RAREDISEASE\n","2            is              O              O\n","3           one              O              O\n","4   distinction              O              O\n","5          from              O              O\n","6       typical              O              O\n","7     pneumonia      B-DISEASE      B-DISEASE\n","8       because              O              O\n","9          spit              O         B-SIGN\n","10            (              O              O\n","11           sp         B-SIGN              O\n","12         ##ut         I-SIGN         I-SIGN\n","13         ##um         I-SIGN              O\n","14            )              O              O\n","15           is              O              O\n","16          too              O         I-SIGN\n","17        thick              O         I-SIGN\n","18           to         I-SIGN         I-SIGN\n","19       become         I-SIGN         I-SIGN\n","20   productive         I-SIGN         I-SIGN\n","21            ,              O              O\n","22    therefore              O              O\n","23   productive              O         B-SIGN\n","24        cough         B-SIGN         I-SIGN\n","25           is              O              O\n","26          not              O              O\n","27           as              O              O\n","28       common              O              O\n","29           in              O              O\n","30            p  B-RAREDISEASE  B-RAREDISEASE\n","31          ##j  I-RAREDISEASE  I-RAREDISEASE\n","32          ##p  I-RAREDISEASE  I-RAREDISEASE\n","33            .              O              O\n","\n","Sentence Nr:  267\n","            WORD GOLD PRED\n","0        however    O    O\n","1              ,    O    O\n","2        despite    O    O\n","3          these    O    O\n","4   similarities    O    O\n","5              ,    O    O\n","6            the    O    O\n","7            two    O    O\n","8      disorders    O    O\n","9            are    O    O\n","10      distinct    O    O\n","11             .    O    O\n","\n","Sentence Nr:  757\n","        WORD GOLD PRED\n","0        the    O    O\n","1      exact    O    O\n","2     number    O    O\n","3         of    O    O\n","4     people    O    O\n","5        who    O    O\n","6       have    O    O\n","7       this    O    O\n","8   disorder    O    O\n","9         is    O    O\n","10   unknown    O    O\n","11         .    O    O\n","\n","Sentence Nr:  1236\n","          WORD GOLD PRED\n","0          the    O    O\n","1     disorder    O    O\n","2          was    O    O\n","3    initially    O    O\n","4    described    O    O\n","5           in    O    O\n","6          the    O    O\n","7      medical    O    O\n","8   literature    O    O\n","9           in    O    O\n","10        1973    O    O\n","11           .    O    O\n","\n","Sentence Nr:  970\n","       WORD           GOLD           PRED\n","0   addison  B-RAREDISEASE  B-RAREDISEASE\n","1         ’  I-RAREDISEASE  I-RAREDISEASE\n","2         s  I-RAREDISEASE  I-RAREDISEASE\n","3   disease  I-RAREDISEASE  I-RAREDISEASE\n","4   affects              O              O\n","5     males              O              O\n","6       and              O              O\n","7   females              O              O\n","8        in              O              O\n","9     equal              O              O\n","10  numbers              O              O\n","11        .              O              O\n","\n","Sentence Nr:  1281\n","          WORD GOLD PRED\n","0        there    O    O\n","1           is    O    O\n","2   tremendous    O    O\n","3    diversity    O    O\n","4           in    O    O\n","5          the    O    O\n","6         type    O    O\n","7          and    O    O\n","8     severity    O    O\n","9           of    O    O\n","10    symptoms    O    O\n","11        from    O    O\n","12     patient    O    O\n","13          to    O    O\n","14     patient    O    O\n","15           .    O    O\n","\n","Sentence Nr:  1189\n","           WORD GOLD PRED\n","0          step    O    O\n","1        ##wise    O    O\n","2       testing    O    O\n","3           for    O    O\n","4            ph    O    O\n","5          ##ox    O    O\n","6           ##2    O    O\n","7           ##b    O    O\n","8     mutations    O    O\n","9        should    O    O\n","10           be    O    O\n","11         done    O    O\n","12         with    O    O\n","13        close    O    O\n","14  involvement    O    O\n","15           by    O    O\n","16            a    O    O\n","17    physician    O    O\n","18          and    O    O\n","19      genetic    O    O\n","20    counselor    O    O\n","21            .    O    O\n","\n","Sentence Nr:  134\n","          WORD GOLD PRED\n","0         they    O    O\n","1          may    O    O\n","2           be    O    O\n","3   widespread    O    O\n","4         over    O    O\n","5          the    O    O\n","6        trunk    O    O\n","7            ,    O    O\n","8         back    O    O\n","9            ,    O    O\n","10         and    O    O\n","11           /    O    O\n","12          or    O    O\n","13   shoulders    O    O\n","14           .    O    O\n","\n","Sentence Nr:  1240\n","        WORD GOLD PRED\n","0      early    O    O\n","1  diagnosis    O    O\n","2        and    O    O\n","3     prompt    O    O\n","4  treatment    O    O\n","5         is    O    O\n","6  essential    O    O\n","7          .    O    O\n","\n","Sentence Nr:  26\n","           WORD       GOLD           PRED\n","0     secondary          O  B-RAREDISEASE\n","1             r  B-DISEASE  I-RAREDISEASE\n","2          ##ls  I-DISEASE  I-RAREDISEASE\n","3           may          O              O\n","4         occur          O              O\n","5            in          O              O\n","6   association          O              O\n","7          with          O              O\n","8       certain          O              O\n","9    conditions          O              O\n","10            ,          O              O\n","11         such          O              O\n","12           as          O              O\n","13         iron  B-DISEASE      B-DISEASE\n","14   deficiency  I-DISEASE      I-DISEASE\n","15            ,          O              O\n","16          low          O              O\n","17       levels          O              O\n","18           of          O              O\n","19          the          O              O\n","20       oxygen          O              O\n","21            -          O              O\n","22     carrying          O              O\n","23    component          O              O\n","24           of          O              O\n","25          red          O              O\n","26        blood          O              O\n","27        cells          O              O\n","28            (          O              O\n","29           an  B-DISEASE      B-DISEASE\n","30       ##emia  I-DISEASE      I-DISEASE\n","31            )          O              O\n","32            ,          O              O\n","33       kidney  B-DISEASE      B-DISEASE\n","34      failure  I-DISEASE      I-DISEASE\n","35            ,          O              O\n","36           or          O              O\n","37    pregnancy          O      B-DISEASE\n","38            .          O              O\n","\n","Sentence Nr:  1715\n","       WORD GOLD PRED\n","0    stress    O    O\n","1       and    O    O\n","2     local    O    O\n","3    injury    O    O\n","4       may    O    O\n","5      also    O    O\n","6        be    O    O\n","7  involved    O    O\n","8         .    O    O\n","\n","Sentence Nr:  960\n","         WORD GOLD PRED\n","0         the    O    O\n","1       range    O    O\n","2         and    O    O\n","3    severity    O    O\n","4          of    O    O\n","5    symptoms    O    O\n","6      varies    O    O\n","7           ,    O    O\n","8     greatly    O    O\n","9   depending    O    O\n","10         on    O    O\n","11        the    O    O\n","12      exact    O    O\n","13   location    O    O\n","14        and    O    O\n","15       size    O    O\n","16         of    O    O\n","17        the    O    O\n","18    missing    O    O\n","19    genetic    O    O\n","20   material    O    O\n","21          .    O    O\n","\n","Sentence Nr:  531\n","       WORD GOLD PRED\n","0      some    O    O\n","1       may    O    O\n","2        be    O    O\n","3     large    O    O\n","4    enough    O    O\n","5        to    O    O\n","6        be    O    O\n","7    called    O    O\n","8         “    O    O\n","9    giants    O    O\n","10        ”    O    O\n","11    while    O    O\n","12   others    O    O\n","13      may    O    O\n","14       be    O    O\n","15  limited    O    O\n","16       to    O    O\n","17    small    O    O\n","18    areas    O    O\n","19       of    O    O\n","20      the    O    O\n","21  temples    O    O\n","22       or    O    O\n","23   cheeks    O    O\n","24        .    O    O\n","\n","Sentence Nr:  1128\n","       WORD           GOLD           PRED\n","0        gs  B-RAREDISEASE  B-RAREDISEASE\n","1       ##d  I-RAREDISEASE  I-RAREDISEASE\n","2      type  I-RAREDISEASE  I-RAREDISEASE\n","3       vii  I-RAREDISEASE  I-RAREDISEASE\n","4   affects              O              O\n","5     males              O              O\n","6       and              O              O\n","7   females              O              O\n","8        in              O              O\n","9     equal              O              O\n","10  numbers              O              O\n","11        .              O              O\n","\n","Sentence Nr:  479\n","         WORD GOLD PRED\n","0           a    O    O\n","1      family    O    O\n","2     history    O    O\n","3         and    O    O\n","4    physical    O    O\n","5        exam    O    O\n","6         can    O    O\n","7     confirm    O    O\n","8         the    O    O\n","9   diagnosis    O    O\n","10          .    O    O\n","\n","Sentence Nr:  392\n","           WORD           GOLD           PRED\n","0         hairy  B-RAREDISEASE  B-RAREDISEASE\n","1        tongue  I-RAREDISEASE  I-RAREDISEASE\n","2          most              O              O\n","3      commonly              O              O\n","4       affects              O              O\n","5        adults              O              O\n","6             ;              O              O\n","7       however              O              O\n","8             ,              O              O\n","9            it              O              O\n","10          may              O              O\n","11    sometimes              O              O\n","12        occur              O              O\n","13       during              O              O\n","14    childhood              O              O\n","15           or              O              O\n","16  adolescence              O              O\n","17            .              O              O\n","\n","Sentence Nr:  1468\n","           WORD       GOLD       PRED\n","0            in          O          O\n","1      contrast          O          O\n","2            to          O          O\n","3        purely          O          O\n","4    peripheral  B-DISEASE  I-DISEASE\n","5            ne  I-DISEASE  I-DISEASE\n","6         ##uro  I-DISEASE  I-DISEASE\n","7        ##path  I-DISEASE  I-DISEASE\n","8         ##ies  I-DISEASE  I-DISEASE\n","9             ,          O          O\n","10          the          O          O\n","11       reflex          O          O\n","12           of          O          O\n","13          the          O          O\n","14         toes          O          O\n","15        known          O          O\n","16           as          O          O\n","17           ba     B-SIGN  B-DISEASE\n","18        ##bin     I-SIGN  I-DISEASE\n","19        ##ski     I-SIGN  I-DISEASE\n","20            ’     I-SIGN  I-DISEASE\n","21            s     I-SIGN  I-DISEASE\n","22         sign     I-SIGN  I-DISEASE\n","23           is     I-SIGN          O\n","24        often     I-SIGN          O\n","25     positive     I-SIGN          O\n","26            ,          O          O\n","27   indicating          O          O\n","28  involvement          O          O\n","29           of          O          O\n","30      central          O          O\n","31        motor          O          O\n","32     pathways          O          O\n","33            .          O          O\n","\n","Sentence Nr:  963\n","           WORD GOLD    PRED\n","0         these    O       O\n","1        tumors    O  B-SIGN\n","2           are    O       O\n","3    frequently    O       O\n","4   microscopic    O       O\n","5           and    O       O\n","6     extremely    O       O\n","7     difficult    O       O\n","8            to    O       O\n","9        detect    O       O\n","10            .    O       O\n","\n","Sentence Nr:  1107\n","       WORD           GOLD           PRED\n","0        am  B-RAREDISEASE  B-RAREDISEASE\n","1     ##elo  I-RAREDISEASE  I-RAREDISEASE\n","2     ##bla  I-RAREDISEASE  I-RAREDISEASE\n","3     ##sto  I-RAREDISEASE  I-RAREDISEASE\n","4      ##ma  I-RAREDISEASE  I-RAREDISEASE\n","5       can              O              O\n","6      show              O              O\n","7        up              O              O\n","8    either              O              O\n","9        in              O              O\n","10        a              O              O\n","11  regular              O              O\n","12        x              O              O\n","13        -              O              O\n","14      ray              O              O\n","15       or              O              O\n","16       in              O              O\n","17       an              O              O\n","18      mri              O              O\n","19  imaging              O              O\n","20    study              O              O\n","21        .              O              O\n","\n","Sentence Nr:  1713\n","         WORD       GOLD       PRED\n","0          in          O          O\n","1    patients          O          O\n","2        with          O          O\n","3   pulmonary  B-DISEASE  B-DISEASE\n","4          fi  I-DISEASE  I-DISEASE\n","5       ##bro  I-DISEASE  I-DISEASE\n","6       ##sis  I-DISEASE  I-DISEASE\n","7   similarly          O          O\n","8           2          O          O\n","9           -          O          O\n","10          5          O          O\n","11          %          O          O\n","12        are          O          O\n","13    thought          O          O\n","14         to          O          O\n","15         be          O          O\n","16        due          O          O\n","17         to          O          O\n","18  mutations          O          O\n","19         in          O          O\n","20        ter          O          O\n","21        ##c          O          O\n","22         or          O          O\n","23        ter          O          O\n","24        ##t          O          O\n","25          .          O          O\n","\n","Sentence Nr:  1125\n","           WORD           GOLD           PRED\n","0           the              O              O\n","1      severity              O              O\n","2           and              O              O\n","3   progression              O              O\n","4            of              O              O\n","5            sp  B-RAREDISEASE  B-RAREDISEASE\n","6           ##s  I-RAREDISEASE  I-RAREDISEASE\n","7        varies              O              O\n","8          from              O              O\n","9           one              O              O\n","10       person              O              O\n","11           to              O              O\n","12      another              O              O\n","13            .              O              O\n","\n","Sentence Nr:  975\n","       WORD    GOLD    PRED\n","0    people       O       O\n","1      with       O       O\n","2      this       O       O\n","3   disease       O       O\n","4      also       O       O\n","5    bruise  B-SIGN       O\n","6    easily       O       O\n","7       and       O       O\n","8       the       O       O\n","9   bruises  B-SIGN  B-SIGN\n","10     tend       O       O\n","11       to       O       O\n","12   linger       O       O\n","13        .       O       O\n","\n","Sentence Nr:  813\n","          WORD           GOLD           PRED\n","0            i  I-RAREDISEASE  B-RAREDISEASE\n","1   associated  I-RAREDISEASE  I-RAREDISEASE\n","2           my  I-RAREDISEASE  I-RAREDISEASE\n","3        ##elo  I-RAREDISEASE  I-RAREDISEASE\n","4      ##pathy  I-RAREDISEASE  I-RAREDISEASE\n","5            /  I-RAREDISEASE  I-RAREDISEASE\n","6     tropical  I-RAREDISEASE  I-RAREDISEASE\n","7          spa  I-RAREDISEASE  I-RAREDISEASE\n","8       ##stic  I-RAREDISEASE  I-RAREDISEASE\n","9         para  I-RAREDISEASE  I-RAREDISEASE\n","10       ##par  I-RAREDISEASE  I-RAREDISEASE\n","11      ##esis  I-RAREDISEASE  I-RAREDISEASE\n","12           (              O              O\n","13         ham  B-RAREDISEASE  B-RAREDISEASE\n","14           /  I-RAREDISEASE  I-RAREDISEASE\n","15          ts  I-RAREDISEASE  I-RAREDISEASE\n","16         ##p  I-RAREDISEASE  I-RAREDISEASE\n","17           )              O              O\n","18           .              O              O\n","\n","Sentence Nr:  1308\n","          WORD           GOLD           PRED\n","0    treatment              O              O\n","1           of              O              O\n","2            k  B-RAREDISEASE  B-RAREDISEASE\n","3         ##lu  I-RAREDISEASE  I-RAREDISEASE\n","4        ##ver  I-RAREDISEASE  I-RAREDISEASE\n","5            -  I-RAREDISEASE  I-RAREDISEASE\n","6           bu  I-RAREDISEASE  I-RAREDISEASE\n","7         ##cy  I-RAREDISEASE  I-RAREDISEASE\n","8     syndrome  I-RAREDISEASE  I-RAREDISEASE\n","9           is              O              O\n","10  supportive              O              O\n","11         and              O              O\n","12      psycho              O              O\n","13       ##tro              O              O\n","14       ##pic              O              O\n","15         ##s              O              O\n","16        that              O              O\n","17         may              O              O\n","18          be              O              O\n","19   effective              O              O\n","20         for              O              O\n","21        some              O              O\n","22          of              O              O\n","23         the              O              O\n","24  associated              O              O\n","25    symptoms              O              O\n","26           .              O              O\n","\n","Sentence Nr:  1763\n","        WORD           GOLD           PRED\n","0         in              O              O\n","1   addition              O              O\n","2          ,              O              O\n","3          o  B-RAREDISEASE  B-RAREDISEASE\n","4       ##cc  I-RAREDISEASE  I-RAREDISEASE\n","..       ...            ...            ...\n","69        or              O              O\n","70      near              O         I-SIGN\n","71       the              O         I-SIGN\n","72      ears              O         I-SIGN\n","73         .              O              O\n","\n","[74 rows x 3 columns]\n","\n","Sentence Nr:  308\n","         WORD           GOLD           PRED\n","0      lennox  B-RAREDISEASE  B-RAREDISEASE\n","1           -  I-RAREDISEASE  I-RAREDISEASE\n","2         gas  I-RAREDISEASE  I-RAREDISEASE\n","3        ##ta  I-RAREDISEASE  I-RAREDISEASE\n","4        ##ut  I-RAREDISEASE  I-RAREDISEASE\n","5    syndrome  I-RAREDISEASE  I-RAREDISEASE\n","6           (              O              O\n","7           l  B-RAREDISEASE  B-RAREDISEASE\n","8        ##gs  I-RAREDISEASE  I-RAREDISEASE\n","9           )              O              O\n","10         is              O              O\n","11          a              O              O\n","12     severe              O              O\n","13       form              O              O\n","14         of              O              O\n","15         ep      B-DISEASE      B-DISEASE\n","16      ##ile      I-DISEASE      I-DISEASE\n","17      ##psy      I-DISEASE      I-DISEASE\n","18       that              O              O\n","19  typically              O              O\n","20    becomes              O              O\n","21   apparent              O              O\n","22     during         I-SIGN              O\n","23    infancy         I-SIGN              O\n","24         or         I-SIGN              O\n","25      early         I-SIGN              O\n","26  childhood         I-SIGN              O\n","27          .              O              O\n","\n","Sentence Nr:  474\n","        WORD           GOLD           PRED\n","0        the              O              O\n","1      exact              O              O\n","2      cause              O              O\n","3         of              O              O\n","4        med  B-RAREDISEASE  B-RAREDISEASE\n","5     ##ulla  I-RAREDISEASE  I-RAREDISEASE\n","6       ##ry  I-RAREDISEASE  I-RAREDISEASE\n","7     sponge  I-RAREDISEASE  I-RAREDISEASE\n","8     kidney  I-RAREDISEASE  I-RAREDISEASE\n","9         is              O              O\n","10       not              O              O\n","11     known              O              O\n","12       and              O              O\n","13      most              O              O\n","14     cases              O              O\n","15     occur              O              O\n","16  sporadic              O              O\n","17    ##ally              O              O\n","18       for              O              O\n","19        no              O              O\n","20  apparent              O              O\n","21    reason              O              O\n","22         .              O              O\n","\n","Sentence Nr:  1300\n","        WORD GOLD PRED\n","0     during    O    O\n","1          a    O    O\n","2         sc    O    O\n","3     ##hill    O    O\n","4      ##ing    O    O\n","5       test    O    O\n","6          ,    O    O\n","7        the    O    O\n","8        int    O    O\n","9      ##est    O    O\n","10    ##ines    O    O\n","11         '    O    O\n","12   ability    O    O\n","13        to    O    O\n","14    absorb    O    O\n","15   vitamin    O    O\n","16        b1    O    O\n","17       ##2    O    O\n","18        is    O    O\n","19  measured    O    O\n","20         .    O    O\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lV_GbDavXyRC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625761523576,"user_tz":-120,"elapsed":11,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"d0acb0d2-2fae-423b-9852-30f2dca32183"},"source":["if allTypes:\n","    test_labels = ['DISEASE', 'RAREDISEASE', 'SYMPTOM', 'SIGN']\n","else:\n","    test_labels = ['RAREDISEASE', 'SIGN-SYM']\n","\n","test_to_use_gold = result_examples_y_gold\n","test_to_use_pred = result_examples_y_pred\n","\n","evaluator_examples = Evaluator(test_to_use_gold, test_to_use_pred, test_labels)\n","results_examples, results_agg_examples = evaluator_examples.evaluate()\n","\n","print('## OVERALL RESULTS')\n","for item in results_examples.keys():\n","    print('\\tEvaluation Metric: ', item)\n","    print('\\t', results_examples[item])\n","print('## RESULTS AT ENTITY LEVEL')\n","for entity in results_agg_examples.keys():\n","    print('Entity: ', entity)\n","    for item in results_agg_examples[entity].keys():\n","        print('\\tEvaluation Metric: ', item)\n","        print('\\t', results_agg_examples[entity][item])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-07-08 16:25:23 root INFO: Imported 30 predictions for 30 true examples\n"],"name":"stderr"},{"output_type":"stream","text":["## OVERALL RESULTS\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 30, 'incorrect': 2, 'partial': 0, 'missed': 5, 'spurious': 11, 'possible': 37, 'actual': 43, 'precision': 0.6976744186046512, 'recall': 0.8108108108108109}\n","\tEvaluation Metric:  partial\n","\t {'correct': 28, 'incorrect': 0, 'partial': 4, 'missed': 5, 'spurious': 11, 'possible': 37, 'actual': 43, 'precision': 0.6976744186046512, 'recall': 0.8108108108108109}\n","\tEvaluation Metric:  strict\n","\t {'correct': 28, 'incorrect': 4, 'partial': 0, 'missed': 5, 'spurious': 11, 'possible': 37, 'actual': 43, 'precision': 0.6511627906976745, 'recall': 0.7567567567567568}\n","\tEvaluation Metric:  exact\n","\t {'correct': 28, 'incorrect': 4, 'partial': 0, 'missed': 5, 'spurious': 11, 'possible': 37, 'actual': 43, 'precision': 0.6511627906976745, 'recall': 0.7567567567567568}\n","## RESULTS AT ENTITY LEVEL\n","Entity:  DISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 7, 'incorrect': 1, 'partial': 0, 'missed': 0, 'spurious': 11, 'possible': 8, 'actual': 19, 'precision': 0.3684210526315789, 'recall': 0.875}\n","\tEvaluation Metric:  partial\n","\t {'correct': 7, 'incorrect': 0, 'partial': 1, 'missed': 0, 'spurious': 11, 'possible': 8, 'actual': 19, 'precision': 0.39473684210526316, 'recall': 0.9375}\n","\tEvaluation Metric:  strict\n","\t {'correct': 7, 'incorrect': 1, 'partial': 0, 'missed': 0, 'spurious': 11, 'possible': 8, 'actual': 19, 'precision': 0.3684210526315789, 'recall': 0.875}\n","\tEvaluation Metric:  exact\n","\t {'correct': 7, 'incorrect': 1, 'partial': 0, 'missed': 0, 'spurious': 11, 'possible': 8, 'actual': 19, 'precision': 0.3684210526315789, 'recall': 0.875}\n","Entity:  RAREDISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 15, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 11, 'possible': 15, 'actual': 26, 'precision': 0.5769230769230769, 'recall': 1.0}\n","\tEvaluation Metric:  partial\n","\t {'correct': 15, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 11, 'possible': 15, 'actual': 26, 'precision': 0.5769230769230769, 'recall': 1.0}\n","\tEvaluation Metric:  strict\n","\t {'correct': 15, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 11, 'possible': 15, 'actual': 26, 'precision': 0.5769230769230769, 'recall': 1.0}\n","\tEvaluation Metric:  exact\n","\t {'correct': 15, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 11, 'possible': 15, 'actual': 26, 'precision': 0.5769230769230769, 'recall': 1.0}\n","Entity:  SYMPTOM\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 11, 'possible': 0, 'actual': 11, 'precision': 0.0, 'recall': 0}\n","\tEvaluation Metric:  partial\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 11, 'possible': 0, 'actual': 11, 'precision': 0.0, 'recall': 0}\n","\tEvaluation Metric:  strict\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 11, 'possible': 0, 'actual': 11, 'precision': 0.0, 'recall': 0}\n","\tEvaluation Metric:  exact\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 11, 'possible': 0, 'actual': 11, 'precision': 0.0, 'recall': 0}\n","Entity:  SIGN\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 8, 'incorrect': 1, 'partial': 0, 'missed': 5, 'spurious': 11, 'possible': 14, 'actual': 20, 'precision': 0.4, 'recall': 0.5714285714285714}\n","\tEvaluation Metric:  partial\n","\t {'correct': 6, 'incorrect': 0, 'partial': 3, 'missed': 5, 'spurious': 11, 'possible': 14, 'actual': 20, 'precision': 0.375, 'recall': 0.5357142857142857}\n","\tEvaluation Metric:  strict\n","\t {'correct': 6, 'incorrect': 3, 'partial': 0, 'missed': 5, 'spurious': 11, 'possible': 14, 'actual': 20, 'precision': 0.3, 'recall': 0.42857142857142855}\n","\tEvaluation Metric:  exact\n","\t {'correct': 6, 'incorrect': 3, 'partial': 0, 'missed': 5, 'spurious': 11, 'possible': 14, 'actual': 20, 'precision': 0.3, 'recall': 0.42857142857142855}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"39ZEiDXiX2xl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625761523904,"user_tz":-120,"elapsed":332,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"1b5e9194-a337-41b4-a63e-eb1dd8409525"},"source":["evaluator_all = Evaluator(true_flags, pred_flags, test_labels)\n","results_all, results_agg_all = evaluator_all.evaluate()\n","\n","print('## OVERALL RESULTS')\n","for item in results_all.keys():\n","    print('\\tEvaluation Metric: ', item)\n","    print('\\t', results_all[item])\n","print('## RESULTS AT ENTITY LEVEL')\n","for entity in results_agg_all.keys():\n","    print('Entity: ', entity)\n","    for item in results_agg_all[entity].keys():\n","        print('\\tEvaluation Metric: ', item)\n","        print('\\t', results_agg_all[entity][item])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-07-08 16:25:24 root INFO: Imported 1772 predictions for 1772 true examples\n"],"name":"stderr"},{"output_type":"stream","text":["## OVERALL RESULTS\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 2059, 'incorrect': 304, 'partial': 0, 'missed': 240, 'spurious': 557, 'possible': 2603, 'actual': 2920, 'precision': 0.7051369863013699, 'recall': 0.7910103726469458}\n","\tEvaluation Metric:  partial\n","\t {'correct': 2094, 'incorrect': 0, 'partial': 269, 'missed': 240, 'spurious': 557, 'possible': 2603, 'actual': 2920, 'precision': 0.7631849315068493, 'recall': 0.8561275451402228}\n","\tEvaluation Metric:  strict\n","\t {'correct': 1839, 'incorrect': 524, 'partial': 0, 'missed': 240, 'spurious': 557, 'possible': 2603, 'actual': 2920, 'precision': 0.6297945205479452, 'recall': 0.7064925086438725}\n","\tEvaluation Metric:  exact\n","\t {'correct': 2094, 'incorrect': 269, 'partial': 0, 'missed': 240, 'spurious': 557, 'possible': 2603, 'actual': 2920, 'precision': 0.7171232876712329, 'recall': 0.8044563964656166}\n","## RESULTS AT ENTITY LEVEL\n","Entity:  DISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 295, 'incorrect': 131, 'partial': 0, 'missed': 31, 'spurious': 557, 'possible': 457, 'actual': 983, 'precision': 0.30010172939979657, 'recall': 0.6455142231947484}\n","\tEvaluation Metric:  partial\n","\t {'correct': 393, 'incorrect': 0, 'partial': 33, 'missed': 31, 'spurious': 557, 'possible': 457, 'actual': 983, 'precision': 0.4165818921668362, 'recall': 0.8960612691466083}\n","\tEvaluation Metric:  strict\n","\t {'correct': 277, 'incorrect': 149, 'partial': 0, 'missed': 31, 'spurious': 557, 'possible': 457, 'actual': 983, 'precision': 0.28179043743641913, 'recall': 0.6061269146608315}\n","\tEvaluation Metric:  exact\n","\t {'correct': 393, 'incorrect': 33, 'partial': 0, 'missed': 31, 'spurious': 557, 'possible': 457, 'actual': 983, 'precision': 0.3997965412004069, 'recall': 0.8599562363238512}\n","Entity:  RAREDISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 1000, 'incorrect': 80, 'partial': 0, 'missed': 24, 'spurious': 557, 'possible': 1104, 'actual': 1637, 'precision': 0.6108735491753207, 'recall': 0.9057971014492754}\n","\tEvaluation Metric:  partial\n","\t {'correct': 1016, 'incorrect': 0, 'partial': 64, 'missed': 24, 'spurious': 557, 'possible': 1104, 'actual': 1637, 'precision': 0.6401954795357361, 'recall': 0.9492753623188406}\n","\tEvaluation Metric:  strict\n","\t {'correct': 949, 'incorrect': 131, 'partial': 0, 'missed': 24, 'spurious': 557, 'possible': 1104, 'actual': 1637, 'precision': 0.5797189981673794, 'recall': 0.8596014492753623}\n","\tEvaluation Metric:  exact\n","\t {'correct': 1016, 'incorrect': 64, 'partial': 0, 'missed': 24, 'spurious': 557, 'possible': 1104, 'actual': 1637, 'precision': 0.6206475259621258, 'recall': 0.9202898550724637}\n","Entity:  SYMPTOM\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 41, 'incorrect': 8, 'partial': 0, 'missed': 8, 'spurious': 557, 'possible': 57, 'actual': 606, 'precision': 0.06765676567656766, 'recall': 0.7192982456140351}\n","\tEvaluation Metric:  partial\n","\t {'correct': 38, 'incorrect': 0, 'partial': 11, 'missed': 8, 'spurious': 557, 'possible': 57, 'actual': 606, 'precision': 0.07178217821782178, 'recall': 0.7631578947368421}\n","\tEvaluation Metric:  strict\n","\t {'correct': 35, 'incorrect': 14, 'partial': 0, 'missed': 8, 'spurious': 557, 'possible': 57, 'actual': 606, 'precision': 0.057755775577557754, 'recall': 0.6140350877192983}\n","\tEvaluation Metric:  exact\n","\t {'correct': 38, 'incorrect': 11, 'partial': 0, 'missed': 8, 'spurious': 557, 'possible': 57, 'actual': 606, 'precision': 0.0627062706270627, 'recall': 0.6666666666666666}\n","Entity:  SIGN\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 723, 'incorrect': 85, 'partial': 0, 'missed': 177, 'spurious': 557, 'possible': 985, 'actual': 1365, 'precision': 0.5296703296703297, 'recall': 0.7340101522842639}\n","\tEvaluation Metric:  partial\n","\t {'correct': 647, 'incorrect': 0, 'partial': 161, 'missed': 177, 'spurious': 557, 'possible': 985, 'actual': 1365, 'precision': 0.532967032967033, 'recall': 0.7385786802030457}\n","\tEvaluation Metric:  strict\n","\t {'correct': 578, 'incorrect': 230, 'partial': 0, 'missed': 177, 'spurious': 557, 'possible': 985, 'actual': 1365, 'precision': 0.42344322344322344, 'recall': 0.5868020304568528}\n","\tEvaluation Metric:  exact\n","\t {'correct': 647, 'incorrect': 161, 'partial': 0, 'missed': 177, 'spurious': 557, 'possible': 985, 'actual': 1365, 'precision': 0.473992673992674, 'recall': 0.6568527918781726}\n"],"name":"stdout"}]}]}