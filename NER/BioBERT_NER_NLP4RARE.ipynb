{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"BioBERT_NER_NLP4RARE.ipynb","provenance":[{"file_id":"1ley57tuXXLuPfr2v6nntDKL0ggJ09cwx","timestamp":1612919533273},{"file_id":"1LCJt3fu3pW0hFe7L19Uu4MMRrW9Z9p5N","timestamp":1612543820837}],"collapsed_sections":[]},"environment":{"name":"pytorch-gpu.1-4.m55","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m55"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AcQ7f6ku4TCy"},"source":["# BioBERT approach for detecting rare diseases\n","\n","This notebook contains the code to develop a BioBERT model to detect rare diseases from texts, which is BERT model pre trained on a huge corpus of medical data (from there, the prefix 'Bio').\n","\n","To accomplish this, we will use some tools developed in the [transformers](https://huggingface.co/transformers/index.html) library, which is a library that recopiles some of the State-of-the-art Natural Language Processing for Pytorch and TensorFlow.\n","\n","To make use of the pre-trained BioBert model with the hugging face `transformers` library, we need the model's weights to be in a form which pyTorch understands. The original model was trained using tensorflow so we need to convert the weights into pyTorch weights. We can then import and use it."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E-awiIaFW2Nc","executionInfo":{"status":"ok","timestamp":1625747488637,"user_tz":-120,"elapsed":13850,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"f8f7b5fa-7001-4958-a58d-e1fe01e2a17d"},"source":["if 'google.colab' in str(get_ipython()):\n","    print('Running on CoLab')\n","    from google.colab import drive\n","    #drive.flush_and_unmount()\n","    drive.mount('/content/drive')\n","    root = '/content/drive/My Drive/Colab Notebooks'\n","else:\n","    print('Not running on CoLab')\n","    root = './'\n","\n","print(\"Current directory: {}\".format(root))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running on CoLab\n","Mounted at /content/drive\n","Current directory: /content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XLKP1xZe17qh"},"source":["## 1. Getting the resources\n","\n","First of all, we will download the model from github repo of [BioBert](https://github.com/dmis-lab/biobert).\n","We will download the proper files directly through the command `wget`. An introduction to this command can be found [here](https://medium.com/@acpanjan/download-google-drive-files-using-wget-3c2c025a8b99).\n","\n","After that, we will install the needed packages."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4nnlQo8ZYKT","executionInfo":{"status":"ok","timestamp":1625747494553,"user_tz":-120,"elapsed":4615,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"2a7b6338-4fd7-4276-9113-031df28257b4"},"source":["!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1R84voFKHfWV9xjzeLzWBbmY1uOMYpnyD' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1R84voFKHfWV9xjzeLzWBbmY1uOMYpnyD\" -O biobert_weights && rm -rf /tmp/cookies.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-07-08 12:31:30--  https://docs.google.com/uc?export=download&confirm=BflF&id=1R84voFKHfWV9xjzeLzWBbmY1uOMYpnyD\n","Resolving docs.google.com (docs.google.com)... 74.125.142.139, 74.125.142.138, 74.125.142.101, ...\n","Connecting to docs.google.com (docs.google.com)|74.125.142.139|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-0s-68-docs.googleusercontent.com/docs/securesc/ld3kcvbhn6jam3uiatsqn6aannblgtus/g154vcc9mpcbj06l79j6mtl60fb6u1te/1625747475000/13799006341648886493/07617052645893874160Z/1R84voFKHfWV9xjzeLzWBbmY1uOMYpnyD?e=download [following]\n","--2021-07-08 12:31:30--  https://doc-0s-68-docs.googleusercontent.com/docs/securesc/ld3kcvbhn6jam3uiatsqn6aannblgtus/g154vcc9mpcbj06l79j6mtl60fb6u1te/1625747475000/13799006341648886493/07617052645893874160Z/1R84voFKHfWV9xjzeLzWBbmY1uOMYpnyD?e=download\n","Resolving doc-0s-68-docs.googleusercontent.com (doc-0s-68-docs.googleusercontent.com)... 74.125.20.132, 2607:f8b0:400e:c07::84\n","Connecting to doc-0s-68-docs.googleusercontent.com (doc-0s-68-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://docs.google.com/nonceSigner?nonce=os9sthj761dk6&continue=https://doc-0s-68-docs.googleusercontent.com/docs/securesc/ld3kcvbhn6jam3uiatsqn6aannblgtus/g154vcc9mpcbj06l79j6mtl60fb6u1te/1625747475000/13799006341648886493/07617052645893874160Z/1R84voFKHfWV9xjzeLzWBbmY1uOMYpnyD?e%3Ddownload&hash=hf5iu7lg6gehmqgppsc63srqr6tb4mei [following]\n","--2021-07-08 12:31:30--  https://docs.google.com/nonceSigner?nonce=os9sthj761dk6&continue=https://doc-0s-68-docs.googleusercontent.com/docs/securesc/ld3kcvbhn6jam3uiatsqn6aannblgtus/g154vcc9mpcbj06l79j6mtl60fb6u1te/1625747475000/13799006341648886493/07617052645893874160Z/1R84voFKHfWV9xjzeLzWBbmY1uOMYpnyD?e%3Ddownload&hash=hf5iu7lg6gehmqgppsc63srqr6tb4mei\n","Connecting to docs.google.com (docs.google.com)|74.125.142.139|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://doc-0s-68-docs.googleusercontent.com/docs/securesc/ld3kcvbhn6jam3uiatsqn6aannblgtus/g154vcc9mpcbj06l79j6mtl60fb6u1te/1625747475000/13799006341648886493/07617052645893874160Z/1R84voFKHfWV9xjzeLzWBbmY1uOMYpnyD?e=download&nonce=os9sthj761dk6&user=07617052645893874160Z&hash=pbtssdc9b17lvgv878knrordfiehsmsf [following]\n","--2021-07-08 12:31:30--  https://doc-0s-68-docs.googleusercontent.com/docs/securesc/ld3kcvbhn6jam3uiatsqn6aannblgtus/g154vcc9mpcbj06l79j6mtl60fb6u1te/1625747475000/13799006341648886493/07617052645893874160Z/1R84voFKHfWV9xjzeLzWBbmY1uOMYpnyD?e=download&nonce=os9sthj761dk6&user=07617052645893874160Z&hash=pbtssdc9b17lvgv878knrordfiehsmsf\n","Connecting to doc-0s-68-docs.googleusercontent.com (doc-0s-68-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/x-gzip]\n","Saving to: ‘biobert_weights’\n","\n","biobert_weights         [            <=>     ] 382.81M   155MB/s    in 2.5s    \n","\n","2021-07-08 12:31:34 (155 MB/s) - ‘biobert_weights’ saved [401403346]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eiDJciIUZ1fg","executionInfo":{"status":"ok","timestamp":1625747507155,"user_tz":-120,"elapsed":12605,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"efae0cf2-3d2f-49f8-d571-5b5123a43575"},"source":["!pip install pytorch_transformers\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pytorch_transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n","\u001b[K     |████████████████████████████████| 184kB 8.1MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 43.0MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.9.0+cu102)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/8a/bfe42e25206da14a311a76798248def9d0f5815bb5651fa4090af7fc4683/boto3-1.17.107-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 43.2MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 42.5MB/s \n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n","Collecting s3transfer<0.5.0,>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n","\u001b[K     |████████████████████████████████| 81kB 12.2MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Collecting botocore<1.21.0,>=1.20.107\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/85/b2e0366a63f4f0aedd4cca8b7bf8b2d6e6adc0f3d72435aa5174d0ec80e2/botocore-1.20.107-py2.py3-none-any.whl (7.7MB)\n","\u001b[K     |████████████████████████████████| 7.7MB 42.1MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.107->boto3->pytorch_transformers) (2.8.1)\n","\u001b[31mERROR: botocore 1.20.107 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: sacremoses, jmespath, botocore, s3transfer, boto3, sentencepiece, pytorch-transformers\n","Successfully installed boto3-1.17.107 botocore-1.20.107 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.4.2 sacremoses-0.0.45 sentencepiece-0.1.96\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 8.9MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Collecting huggingface-hub==0.0.12\n","  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 51.0MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Installing collected packages: huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.0.12 tokenizers-0.10.3 transformers-4.8.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vWZMOW1yaMXt","executionInfo":{"status":"ok","timestamp":1625747512229,"user_tz":-120,"elapsed":5078,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"7f779084-0ebe-4b1d-91a1-b54216be8e08"},"source":["!tar -xzf biobert_weights\n","!ls biobert_v1.1_pubmed/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["bert_config.json\t\t\tmodel.ckpt-1000000.index  vocab.txt\n","model.ckpt-1000000.data-00000-of-00001\tmodel.ckpt-1000000.meta\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5yG1qBvaSGO","executionInfo":{"status":"ok","timestamp":1625747524569,"user_tz":-120,"elapsed":12342,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"c6d05829-68bb-4a6f-ac9e-a38eba2237b7"},"source":["!transformers-cli convert --model_type bert --tf_checkpoint biobert_v1.1_pubmed/model.ckpt-1000000 --config biobert_v1.1_pubmed/bert_config.json --pytorch_dump_output biobert_v1.1_pubmed/pytorch_model.bin"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-07-08 12:31:56.959910: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","Building PyTorch model from configuration: BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.8.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","Converting TensorFlow checkpoint from /content/biobert_v1.1_pubmed/model.ckpt-1000000\n","Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n","Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n","Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n","Loading TF weight bert/embeddings/word_embeddings with shape [28996, 768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/pooler/dense/bias with shape [768]\n","Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n","Save PyTorch model to biobert_v1.1_pubmed/pytorch_model.bin\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EplmbFMDac-_","executionInfo":{"status":"ok","timestamp":1625747524925,"user_tz":-120,"elapsed":361,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"b47fb1f9-d735-4925-ad39-3f13d74b0f75"},"source":["!ls biobert_v1.1_pubmed/\n","!mv biobert_v1.1_pubmed/bert_config.json biobert_v1.1_pubmed/config.json\n","!ls biobert_v1.1_pubmed/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["bert_config.json\t\t\tmodel.ckpt-1000000.meta\n","model.ckpt-1000000.data-00000-of-00001\tpytorch_model.bin\n","model.ckpt-1000000.index\t\tvocab.txt\n","config.json\t\t\t\tmodel.ckpt-1000000.meta\n","model.ckpt-1000000.data-00000-of-00001\tpytorch_model.bin\n","model.ckpt-1000000.index\t\tvocab.txt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ULc2U_O924aK"},"source":["Here, finally we will declare the model we want to execute. In this case, a `BertModel` pretrained with biobert weights."]},{"cell_type":"code","metadata":{"id":"D3v-Ml4Pahx-"},"source":["from pytorch_transformers import BertModel\n","model = BertModel.from_pretrained('biobert_v1.1_pubmed')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3SWmvzdm3D7a"},"source":["## 2. Data loading and first insights\n","\n","In this step we will download the data and define all of the main paths that our model includes.\n","\n","It is also possible to select the desired language (`en` for english and `es` for spanish) and whether to consider all the entities from the model or not (`allTypes` variable)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ytuVTGvFameo","executionInfo":{"status":"ok","timestamp":1625747527607,"user_tz":-120,"elapsed":3,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"4c7791c9-d32a-4cd6-e8d1-ba1d309fc749"},"source":["LANG = 'en'  #This system will also process texts written in Spanish, LANG='es'\n","allTypes = True\n","sTypes = ''\n","if allTypes:\n","    sTypes = '_all'\n","\n","#path_data=root+'data/{}/'.format(LANG) #folder where you can find the datasets\n","path_data = root + '/ner/data/gold_nlp4rare_corpus/' #folder where you can find the datasets\n","path_models = root + '/ner/models/{}/'.format(LANG) #folder to save the models\n","checkpoints = root + '/ner/checkpoints/'\n","path_scores = root + '/ner/scores/{}/'.format(LANG) #folder to save the scores\n","path_outputs = root + '/ner/outputs/{}/'.format(LANG) #folder to save the scores\n","\n","print('Datasets:',path_data)\n","print('Path to save this model:',path_models)\n","print('Path for checkpoints:',checkpoints)\n","print('Path to save the scores:',path_scores)\n","print('Path to save the outputs:',path_outputs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Datasets: /content/drive/My Drive/Colab Notebooks/ner/data/gold_nlp4rare_corpus/\n","Path to save this model: /content/drive/My Drive/Colab Notebooks/ner/models/en/\n","Path for checkpoints: /content/drive/My Drive/Colab Notebooks/ner/checkpoints/\n","Path to save the scores: /content/drive/My Drive/Colab Notebooks/ner/scores/en/\n","Path to save the outputs: /content/drive/My Drive/Colab Notebooks/ner/outputs/en/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBUx_tlSbcGu","executionInfo":{"status":"ok","timestamp":1625747530621,"user_tz":-120,"elapsed":2336,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"03feb994-8fe0-4236-be21-3d7245812c37"},"source":["import pandas as pd\n","\n","df_train = pd.read_csv(path_data+'train{}.csv'.format(sTypes),index_col=0)\n","print('size of the training dataset: {}'.format(len(df_train)))\n","df_dev = pd.read_csv(path_data+'dev{}.csv'.format(sTypes),index_col=0)\n","print('size of the development dataset: {}'.format(len(df_dev)))\n","df_test = pd.read_csv(path_data+'test{}.csv'.format(sTypes),index_col=0)\n","print('size of the test dataset: {}'.format(len(df_test)))\n","print('datasets loaded!\\n')\n","\n","#number of labels (IOB tags)\n","tags = df_train['Tag'].unique()\n","num_tags = df_train['Tag'].nunique()\n","print('Labels: {}'.format(tags))\n","print('Nr of labels: {}'.format(num_tags))\n","\n","# Overall statistics for the number of words in each text\n","count_df_train = df_train.groupby('Sentence #').count()\n","statistics_train = count_df_train['Word'].describe()\n","print('\\nSome statistics of the sentences in the training dataset:')\n","print(statistics_train)\n","\n","count_df_dev = df_dev.groupby('Sentence #').count()\n","statistics_dev = count_df_dev['Word'].describe()\n","print('\\nSome statistics of the sentences in the development dataset:')\n","print(statistics_dev)\n","\n","#The lenth of the longest sentence. Lenght is the number of words.\n","MAX_LEN_TRAIN = int(statistics_train['max'])\n","MAX_LEN_DEV = int(statistics_dev['max'])\n","MAX_LEN = max(MAX_LEN_TRAIN, MAX_LEN_DEV)\n","print('\\n')\n","print('The maximum length of sentences in TRAIN is: ', MAX_LEN_TRAIN)\n","print('The maximum length of sentences in DEV is: ', MAX_LEN_DEV)\n","print('The maximum length of sentences in TOTAL is:', MAX_LEN)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["size of the training dataset: 135656\n","size of the development dataset: 18492\n","size of the test dataset: 37837\n","datasets loaded!\n","\n","Labels: ['O' 'B-RAREDISEASE' 'I-RAREDISEASE' 'B-DISEASE' 'I-DISEASE' 'B-SIGN'\n"," 'I-SIGN' 'B-SYMPTOM' 'I-SYMPTOM']\n","Nr of labels: 9\n","\n","Some statistics of the sentences in the training dataset:\n","count    6451.000000\n","mean       21.028678\n","std        10.653876\n","min         1.000000\n","25%        13.000000\n","50%        19.000000\n","75%        26.000000\n","max        90.000000\n","Name: Word, dtype: float64\n","\n","Some statistics of the sentences in the development dataset:\n","count    903.000000\n","mean      20.478405\n","std       10.105284\n","min        1.000000\n","25%       13.000000\n","50%       18.000000\n","75%       25.000000\n","max       71.000000\n","Name: Word, dtype: float64\n","\n","\n","The maximum length of sentences in TRAIN is:  90\n","The maximum length of sentences in DEV is:  71\n","The maximum length of sentences in TOTAL is: 90\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ltOsBqAv4N_r"},"source":["We visualize next the distribution of each of the datasets according to its entities."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLdpET-UblbE","executionInfo":{"status":"ok","timestamp":1625747530622,"user_tz":-120,"elapsed":4,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"6f148d61-0562-44c8-8f40-e5e92cb3b738"},"source":["separator = '*'*60\n","# Tag statistics train df\n","print('TRAIN:\\n', df_train['Tag'].value_counts(), sep='\\n', end='\\n')\n","print()\n","print('Percentages:', df_train['Tag'].value_counts(normalize=True)*100, sep='\\n', end='\\n')\n","\n","# Tag statistics dev df\n","print('', separator, '', sep='\\n')\n","print('DEV:\\n', df_dev['Tag'].value_counts(), sep='\\n', end='\\n')\n","print()\n","print('Percentages:', df_dev['Tag'].value_counts(normalize=True)*100, sep='\\n', end='\\n')\n","\n","# Tag statistics test df\n","print('', separator, '', sep='\\n')\n","print('TEST:\\n', df_test['Tag'].value_counts(), sep='\\n', end='\\n')\n","print()\n","print('Percentages:', df_test['Tag'].value_counts(normalize=True)*100, sep='\\n', end='\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TRAIN:\n","\n","O                113555\n","I-SIGN             7584\n","I-RAREDISEASE      4116\n","B-RAREDISEASE      3555\n","B-SIGN             2914\n","I-DISEASE          1735\n","B-DISEASE          1596\n","I-SYMPTOM           304\n","B-SYMPTOM           297\n","Name: Tag, dtype: int64\n","\n","Percentages:\n","O                83.708056\n","I-SIGN            5.590612\n","I-RAREDISEASE     3.034145\n","B-RAREDISEASE     2.620599\n","B-SIGN            2.148080\n","I-DISEASE         1.278970\n","B-DISEASE         1.176505\n","I-SYMPTOM         0.224096\n","B-SYMPTOM         0.218936\n","Name: Tag, dtype: float64\n","\n","************************************************************\n","\n","DEV:\n","\n","O                15131\n","I-SIGN            1337\n","I-RAREDISEASE      626\n","B-RAREDISEASE      513\n","B-SIGN             405\n","I-DISEASE          224\n","B-DISEASE          218\n","I-SYMPTOM           20\n","B-SYMPTOM           18\n","Name: Tag, dtype: int64\n","\n","Percentages:\n","O                81.824573\n","I-SIGN            7.230154\n","I-RAREDISEASE     3.385248\n","B-RAREDISEASE     2.774173\n","B-SIGN            2.190136\n","I-DISEASE         1.211335\n","B-DISEASE         1.178888\n","I-SYMPTOM         0.108155\n","B-SYMPTOM         0.097339\n","Name: Tag, dtype: float64\n","\n","************************************************************\n","\n","TEST:\n","\n","O                31594\n","I-SIGN            2215\n","I-RAREDISEASE     1179\n","B-RAREDISEASE     1073\n","B-SIGN             803\n","B-DISEASE          443\n","I-DISEASE          400\n","I-SYMPTOM           80\n","B-SYMPTOM           50\n","Name: Tag, dtype: int64\n","\n","Percentages:\n","O                83.500278\n","I-SIGN            5.854058\n","I-RAREDISEASE     3.115998\n","B-RAREDISEASE     2.835849\n","B-SIGN            2.122261\n","B-DISEASE         1.170812\n","I-DISEASE         1.057166\n","I-SYMPTOM         0.211433\n","B-SYMPTOM         0.132146\n","Name: Tag, dtype: float64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D30_dqal47wo"},"source":["## 3. Imports and pre-processing of the data\n","\n","First, all the steps to import the necessary packages to use the model are defined. After that, the pre processing of the data is necessary as the `Bert` model need to meet some special requirements."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"id":"wNJcYiT0eXbV","executionInfo":{"status":"ok","timestamp":1625747535843,"user_tz":-120,"elapsed":5223,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"61ef122f-23b4-4b4b-928a-f16e71474af6"},"source":["#importing a few necessary packages and setting the DATA directory\n","DATA_DIR=\".\"\n","import os\n","import numpy as np\n","import pickle\n","import tensorflow as tf\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","# install BERT\n","!pip install pytorch_pretrained_bert pytorch-nlp\n","\n","# BERT imports\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from pytorch_pretrained_bert import BertTokenizer, BertConfig\n","from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","# specify GPU device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pytorch_pretrained_bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 7.5MB/s \n","\u001b[?25hCollecting pytorch-nlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n","\u001b[K     |████████████████████████████████| 92kB 7.1MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.9.0+cu102)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.17.107)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n","Requirement already satisfied: botocore<1.21.0,>=1.20.107 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.20.107)\n","Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.4.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.107->boto3->pytorch_pretrained_bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.107->boto3->pytorch_pretrained_bert) (1.15.0)\n","Installing collected packages: pytorch-pretrained-bert, pytorch-nlp\n","Successfully installed pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla T4'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"epO0H4UI5awo"},"source":["The model does not process text, so we need to transform all the pre-defined entities (labels) to a language that can be interpreted by the model, i.e., numbers.\n","\n","To do that, we create a dictionary with the desired labels following the IOB scheme."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AD4URCopex4w","executionInfo":{"status":"ok","timestamp":1625747535844,"user_tz":-120,"elapsed":4,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"eaacae13-fe1b-4501-808f-59ec5343d30b"},"source":["# We have to create a dictionary for the labels (IOB labels):\n","# label is key and value is index.\n","tag_index = {t : i + 1 for i, t in enumerate(tags)}\n","#we have to add a new label for pad tokens\n","tag_index[\"PAD\"] = 0\n","\n","print('Dictionary for labels:', tag_index)\n","print('Number of tags added the tag for pad tokens:', len(tag_index))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dictionary for labels: {'O': 1, 'B-RAREDISEASE': 2, 'I-RAREDISEASE': 3, 'B-DISEASE': 4, 'I-DISEASE': 5, 'B-SIGN': 6, 'I-SIGN': 7, 'B-SYMPTOM': 8, 'I-SYMPTOM': 9, 'PAD': 0}\n","Number of tags added the tag for pad tokens: 10\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DL-1sfr-58qn"},"source":["Next, we perform the first step of preprocessing of the data. Here, a class `SentenceGetter` in combination to a function `vectorization` are defined to extract the desired features from the input data."]},{"cell_type":"code","metadata":{"id":"YIUm7FCEgfFK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625747536524,"user_tz":-120,"elapsed":683,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"3bff0333-1a77-41a5-fd8e-aeab1052089e"},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","class SentenceGetter(object):\n","    \"\"\"This is a class to get sentence. Each sentence will be a list of tuples with its words, tag and pos.\"\"\"\n","    def __init__(self, df):\n","        self.n_sent = 1\n","        self.df = df\n","        self.empty = False\n","        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n","                                                       s['POS'].values.tolist(),\n","                                                       s['Tag'].values.tolist())]\n","        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n","        self.sentences = [s for s in self.grouped]\n","        \n","    def get_text(self):\n","        try:\n","            #s = self.grouped['Sentence: {}'.format(self.n_sent)]\n","            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n","            self.n_sent +=1\n","            return s\n","        except:\n","            return None\n","\n","def vectorization(df, tag_index):\n","    \"\"\"This functions gets the dataframe with the dataset and transform it to vectors. \n","    First, its sentences are retrieved. Then, for each sentence, the function creates a list\n","    with its corresponding indexes. In addition to X (which are the sentences transformed to vectors),\n","    the functions also returns the corresponding labels for each token\"\"\"\n","    \n","    df = df[['Sentence #','Word','POS','Tag']]\n","    \n","    # Getting full sentences\n","    getter = SentenceGetter(df)\n","    sentences = getter.sentences\n","\n","    X = [[w[0] for w in s] for s in sentences]\n","\n","    # Convert label to index\n","    y = [[tag_index[w[2]] for w in s] for s in sentences]\n","    \n","    return (X, y)\n","\n","# vectorization of datasets\n","sentences_train, labels_train = vectorization(df_train, tag_index)\n","sentences_dev, labels_dev = vectorization(df_dev, tag_index)\n","sentences_test, labels_test = vectorization(df_test, tag_index)\n","print('Datasets loaded!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Datasets loaded!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NK85yt-p64ft"},"source":["Same as for the labels, all of the retrieved words for each sentence is necessary to be converted to numbers to use them in the model. For that, we use the tokenization of the Bert model."]},{"cell_type":"code","metadata":{"id":"XVFBcuyehFFD"},"source":["# Tokenize with BERT tokenizer\n","from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('biobert_v1.1_pubmed', do_lower_case=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-1977pMY7N60"},"source":["Here, an example of tokenization is provided to check how this process works.\n","\n","Through this example, we can see how the original sentence is transformed to new subwords or 'tokens', and after that the tokenizer assign them a number according to its internal vocabulary. \n","\n","As new subwords are created, the original lenght of the sentence is modified. Then, the original labels are no longer valid, and a new processing of the labels is necessary to correct this disalignment between words and labels."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GHEDBh2dvR5u","executionInfo":{"status":"ok","timestamp":1625747536766,"user_tz":-120,"elapsed":5,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"cfd56abe-076a-4f78-d685-b82d1469ae56"},"source":["# Example of BERT tokenization\n","selected_index = np.random.randint(1, 6461)\n","# selected_index = 344\n","# selected_index = 4\n","selected_sentence = sentences_train[selected_index]\n","tokenized_input = tokenizer(selected_sentence, is_split_into_words=True, add_special_tokens=False)\n","tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n","print(\"Sentence used: {}\\nOriginal sentence:\\n\\t{}\".format(selected_index, selected_sentence))\n","print(\"Tokenization of the sentence:\\n\\t{}\".format(tokens))\n","print('Tokenized ids for the sentence:\\n\\t{}'.format(tokenized_input[\"input_ids\"]))\n","print(\"Length:\\n\\tOriginal sentence: {}\\n\\tTokenized sentence: {}\\n\\tTokenized ids: {}\".format(len(selected_sentence), len(tokens), len(tokenized_input[\"input_ids\"])))\n","\n","# Example label alignment after BERT tokenization\n","selected_original_labels = labels_train[selected_index]\n","\n","print('')\n","print('Original labels:\\n\\t{}'.format(selected_original_labels))\n","\n","word_ids = []\n","index = 0\n","current_word = ''\n","for token in tokens:\n","    if token.startswith(\"##\"):\n","        word_ids.append(index-1)\n","    elif token in current_word:\n","        if len(tokenizer.tokenize(current_word)) != 1:\n","            subtokens_qty = len(tokenizer.tokenize(current_word))\n","            for subtoken in tokenizer.tokenize(current_word):\n","                if token == subtoken:\n","                    word_ids.append(index-1)\n","                    break\n","                subtokens_qty -= 1\n","                if subtokens_qty == 0:\n","                    word_ids.append(index)\n","                    current_word = selected_sentence[index].lower()\n","                    index += 1\n","        else:\n","            word_ids.append(index)\n","            current_word = selected_sentence[index].lower()\n","            index += 1\n","    else:\n","        word_ids.append(index)\n","        current_word = selected_sentence[index].lower()\n","        index += 1\n","\n","print('New assigned word_ids:\\n\\t{}'.format(word_ids))\n","\n","aligned_labels = []\n","old_index = -1\n","\n","if allTypes:\n","    for i in word_ids:\n","        if (i == old_index) and ( (selected_original_labels[i] == 2) or (selected_original_labels[i] == 4) or (selected_original_labels[i] == 6) or (selected_original_labels[i] == 8) ):\n","            aligned_labels.append(selected_original_labels[i]+1)\n","        else:\n","            aligned_labels.append(selected_original_labels[i])\n","        old_index = i\n","else:\n","    for i in word_ids:\n","        if (i == old_index) and ( (selected_original_labels[i] == 2) or (selected_original_labels[i] == 4) ):\n","            aligned_labels.append(selected_original_labels[i]+1)\n","        else:\n","            aligned_labels.append(selected_original_labels[i])\n","        old_index = i\n","\n","# print('')\n","# print('Original labels:\\n\\t{}'.format(selected_original_labels))\n","# print('New assigned word_ids:\\n\\t{}'.format(word_ids))\n","print('New label alignment:\\n\\t{}'.format(aligned_labels))\n","print(\"Length:\\n\\tOriginal labels: {}\\n\\tNew assigned word_ids: {}\\n\\tNew label alignment: {}\".format(len(selected_original_labels), len(word_ids), len(aligned_labels)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sentence used: 3109\n","Original sentence:\n","\t['Cockayne', 'Syndrome', 'is', 'very', 'rare', 'and', 'affects', 'males', 'and', 'females', 'in', 'equal', 'numbers', '.']\n","Tokenization of the sentence:\n","\t['cock', '##ayne', 'syndrome', 'is', 'very', 'rare', 'and', 'affects', 'males', 'and', 'females', 'in', 'equal', 'numbers', '.']\n","Tokenized ids for the sentence:\n","\t[11012, 24562, 9318, 1110, 1304, 4054, 1105, 13974, 3508, 1105, 3032, 1107, 4463, 2849, 119]\n","Length:\n","\tOriginal sentence: 14\n","\tTokenized sentence: 15\n","\tTokenized ids: 15\n","\n","Original labels:\n","\t[2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","New assigned word_ids:\n","\t[0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n","New label alignment:\n","\t[2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","Length:\n","\tOriginal labels: 14\n","\tNew assigned word_ids: 15\n","\tNew label alignment: 15\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y3P5E_Gz8H2o"},"source":["After the example, we proceed with the same operation to the full datasets."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueA3oqQ-VoLL","executionInfo":{"status":"ok","timestamp":1625747536767,"user_tz":-120,"elapsed":4,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"103feb47-6cc9-4978-ed45-904142ff5b90"},"source":["# print(tokenizer.tokenize('1%-2'))\n","# print(tokenizer.tokenize('and'))\n","# print(tokenizer.tokenize('NMOSD'))\n","subtoken_to_analyze = '2'\n","strings = ['1%-2', 'and', 'with', 'NMOSD', '2,000', ',', '2-2', '222', '24-hour']\n","\n","for string in strings: \n","    print('[', string, ']')\n","    if len(tokenizer.tokenize(string)) != 1:\n","        print('\\t({})'.format(tokenizer.tokenize(string)))\n","        print('\\tnot unique word')\n","        subtokens_qty = len(tokenizer.tokenize(string))\n","        for subtoken in tokenizer.tokenize(string):\n","            if subtoken_to_analyze.lower() == subtoken:\n","                print('------> <{}> belongs to last word'.format(subtoken_to_analyze))\n","                break\n","            subtokens_qty -= 1\n","            if subtokens_qty == 0:\n","                print('------> <{}> does NOT belong to last word'.format(subtoken_to_analyze))\n","    else:\n","        print('\\tunique word')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ 1%-2 ]\n","\t(['1', '%', '-', '2'])\n","\tnot unique word\n","------> <2> belongs to last word\n","[ and ]\n","\tunique word\n","[ with ]\n","\tunique word\n","[ NMOSD ]\n","\t(['nm', '##os', '##d'])\n","\tnot unique word\n","------> <2> does NOT belong to last word\n","[ 2,000 ]\n","\t(['2', ',', '000'])\n","\tnot unique word\n","------> <2> belongs to last word\n","[ , ]\n","\tunique word\n","[ 2-2 ]\n","\t(['2', '-', '2'])\n","\tnot unique word\n","------> <2> belongs to last word\n","[ 222 ]\n","\tunique word\n","[ 24-hour ]\n","\t(['24', '-', 'hour'])\n","\tnot unique word\n","------> <2> does NOT belong to last word\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_MoZWkQ1mGmE","executionInfo":{"status":"ok","timestamp":1625747551492,"user_tz":-120,"elapsed":14727,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"43c595ed-0785-4206-9ff3-c5e1c8384c14"},"source":["def align_labels(original_sentences, original_labels, MAX_LEN):\n","    \"\"\"\n","    This function assign the new labels following the original input and according to\n","    the results from the Tokenization to create a good alignment between words/subwords\n","    and labels.\n","    Besides this, it provides the new maximum lenght of the sentences after the Tokenization\n","    for future padding purposes.\n","    \"\"\"\n","    tokenized_input = tokenizer(original_sentences, is_split_into_words=True, add_special_tokens=False)\n","    tokens = [tokenizer.convert_ids_to_tokens(t) for t in tokenized_input[\"input_ids\"]]\n","    list_len = [len(i) for i in tokens]\n","    MAX_LEN = max(max(list_len), MAX_LEN) \n","\n","    word_ids_global = []\n","    for nr_sentence, list_tokens in enumerate(tokens):\n","        word_ids = []\n","        index = 0\n","        current_word = ''\n","        for token in list_tokens:\n","            if token.startswith(\"##\"):\n","                word_ids.append(index-1)\n","            elif token in current_word:\n","                if len(tokenizer.tokenize(current_word)) != 1:\n","                    subtokens_qty = len(tokenizer.tokenize(current_word))\n","                    for subtoken in tokenizer.tokenize(current_word):\n","                        if token == subtoken:\n","                            word_ids.append(index-1)\n","                            break\n","                        subtokens_qty -= 1\n","                        if subtokens_qty == 0:\n","                            word_ids.append(index)\n","                            current_word = original_sentences[nr_sentence][index].lower()\n","                            index += 1\n","                else:\n","                    word_ids.append(index)\n","                    current_word = original_sentences[nr_sentence][index].lower()\n","                    index += 1\n","            else:\n","                word_ids.append(index)\n","                current_word = original_sentences[nr_sentence][index].lower()\n","                index += 1\n","        word_ids_global.append(word_ids)\n","\n","    aligned_global = []\n","    for nr_sentence, list_word_ids in enumerate(word_ids_global):\n","        aligned_labels = []\n","        old_index = -1\n","        if allTypes:\n","            for i in list_word_ids:\n","                if (i == old_index) and ( (original_labels[nr_sentence][i] == 2) or (original_labels[nr_sentence][i] == 4) or (original_labels[nr_sentence][i] == 6) or (original_labels[nr_sentence][i] == 8) ):\n","                    aligned_labels.append(original_labels[nr_sentence][i]+1)\n","                else:\n","                    aligned_labels.append(original_labels[nr_sentence][i])\n","                old_index = i\n","        else:\n","            for i in list_word_ids:\n","                if (i == old_index) and ( (original_labels[nr_sentence][i] == 2) or (original_labels[nr_sentence][i] == 4) ):\n","                    aligned_labels.append(original_labels[nr_sentence][i]+1)\n","                else:\n","                    aligned_labels.append(original_labels[nr_sentence][i])\n","                old_index = i\n","        aligned_global.append(aligned_labels)\n","\n","    return MAX_LEN, aligned_global\n","\n","print('Aligning labels...')\n","train_max_len, aligned_labels_train = align_labels(sentences_train, labels_train, MAX_LEN)\n","dev_max_len, aligned_labels_dev = align_labels(sentences_dev, labels_dev, MAX_LEN)\n","test_max_len, aligned_labels_test = align_labels(sentences_test, labels_test, MAX_LEN)\n","print('Labels aligned!')\n","CORRECTED_MAX_LEN = max(train_max_len, dev_max_len)\n","print('New defined MAX_LEN after tokenization is: ', CORRECTED_MAX_LEN)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Aligning labels...\n","Labels aligned!\n","New defined MAX_LEN after tokenization is:  120\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NZrwapYI85Bt"},"source":["The pre-processing of the data is finished with the padding of the new labels to the maximum lenght and the tokenization of the words."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7BvTz40BSMeJ","executionInfo":{"status":"ok","timestamp":1625747564870,"user_tz":-120,"elapsed":13380,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"97503398-add6-4961-bc08-1c1ba00a7517"},"source":["# Padding labels according to corrected MAX_LEN\n","final_train_labels = pad_sequences(maxlen=CORRECTED_MAX_LEN, sequences=aligned_labels_train, padding=\"post\", value=tag_index[\"PAD\"]).tolist()\n","final_dev_labels = pad_sequences(maxlen=CORRECTED_MAX_LEN, sequences=aligned_labels_dev, padding=\"post\", value=tag_index[\"PAD\"]).tolist()\n","final_test_labels = pad_sequences(maxlen=CORRECTED_MAX_LEN, sequences=aligned_labels_test, padding=\"post\", value=tag_index[\"PAD\"]).tolist()\n","print('Labels padded')\n","\n","# Tokenize inputs according to corrected MAX_LEN\n","# train dataset\n","tokenized_input_train = tokenizer(sentences_train, truncation=True, max_length=CORRECTED_MAX_LEN, padding='max_length', is_split_into_words=True, add_special_tokens=False)\n","print('\\nTrain dataset:\\n\\tsentences lenght: {}.\\n\\tlabels lenght: {}.\\n\\tinput_ids length: {}.'.format(len(sentences_train), len(labels_train), len(tokenized_input_train['input_ids'])))\n","\n","# dev dataset\n","tokenized_input_dev = tokenizer(sentences_dev, truncation=True, max_length=CORRECTED_MAX_LEN, padding='max_length', is_split_into_words=True, add_special_tokens=False)\n","print('\\nDev dataset:\\n\\tsentences lenght: {}.\\n\\tlabels lenght: {}.\\n\\tinput_ids length: {}.'.format(len(sentences_dev), len(labels_dev), len(tokenized_input_dev['input_ids'])))\n","\n","# test dataset\n","tokenized_input_test = tokenizer(sentences_test, truncation=True, max_length=CORRECTED_MAX_LEN, padding='max_length', is_split_into_words=True, add_special_tokens=False)\n","print('\\nTest dataset:\\n\\tsentences lenght: {}.\\n\\tlabels lenght: {}.\\n\\tinput_ids length: {}.'.format(len(sentences_test), len(labels_test), len(tokenized_input_test['input_ids'])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Labels padded\n","\n","Train dataset:\n","\tsentences lenght: 6451.\n","\tlabels lenght: 6451.\n","\tinput_ids length: 6451.\n","\n","Dev dataset:\n","\tsentences lenght: 903.\n","\tlabels lenght: 903.\n","\tinput_ids length: 903.\n","\n","Test dataset:\n","\tsentences lenght: 1772.\n","\tlabels lenght: 1772.\n","\tinput_ids length: 1772.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GWN1XXZa9Fuj"},"source":["We now extract one example from the processed data to check the dimensions and alignment among all of the inputs."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9WxrBL85iDjQ","executionInfo":{"status":"ok","timestamp":1625747564870,"user_tz":-120,"elapsed":8,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"f6888fd4-10d3-4bb1-8e89-cb7e5ebbb289"},"source":["# Checking all is right\n","print(tokenized_input_dev.keys())\n","print(tokenized_input_dev['input_ids'][0])\n","print(tokenized_input_dev['attention_mask'][0])\n","print(final_dev_labels[0])\n","print('Length inputs: {}.\\nLength masks: {}.\\nLength labels: {}.'.format(len(tokenized_input_dev['input_ids'][0]), len(tokenized_input_dev['attention_mask'][0]), len(final_dev_labels[0])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n","[5855, 2552, 9318, 113, 172, 1279, 114, 1110, 170, 4054, 22572, 16071, 22354, 7435, 8936, 1115, 1336, 1129, 10238, 1120, 3485, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[2, 3, 3, 1, 2, 3, 1, 1, 1, 1, 4, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Length inputs: 120.\n","Length masks: 120.\n","Length labels: 120.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u2bbyah39e_t"},"source":["## 4. Definition of the model\n","\n","For reproducibility reasons, we fix a seed for PyTorch and convert all the data into tensors as the model requires."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XwA5hL_tj7zj","executionInfo":{"status":"ok","timestamp":1625747564870,"user_tz":-120,"elapsed":6,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"78989d91-fd57-492f-f16a-5cc30019b504"},"source":["import torch\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","np.random.seed(42)\n","torch.backends.cudnn.deterministic=True\n","batch_size = 32 # 64\n","\n","# Convert all of our data into torch tensors, the required datatype for our model\n","train_inputs = torch.tensor(tokenized_input_train[\"input_ids\"])\n","train_masks = torch.tensor(tokenized_input_train[\"attention_mask\"])\n","train_labels = torch.tensor(final_train_labels)\n","\n","validation_inputs = torch.tensor(tokenized_input_dev[\"input_ids\"])\n","validation_masks = torch.tensor(tokenized_input_dev[\"attention_mask\"])\n","validation_labels = torch.tensor(final_dev_labels)\n","\n","test_inputs = torch.tensor(tokenized_input_test[\"input_ids\"])\n","test_masks = torch.tensor(tokenized_input_test[\"attention_mask\"])\n","test_labels = torch.tensor(final_test_labels)\n","\n","# Checking outputs\n","print('Train tensor shapes:')\n","print('Inputs: ', train_inputs.shape)\n","print('Masks: ', train_masks.shape)\n","print('Labels: ', train_labels.shape)\n","print('\\nValidation tensor shapes:')\n","print('Inputs: ', validation_inputs.shape)\n","print('Masks: ', validation_masks.shape)\n","print('Labels: ', validation_labels.shape)\n","print('\\nTest tensor shapes:')\n","print('Inputs: ', test_inputs.shape)\n","print('Masks: ', test_masks.shape)\n","print('Labels: ', test_labels.shape)\n","\n","# Create an iterator of our data with torch DataLoader \n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","shuffled_train_data = torch.utils.data.Subset(train_data, torch.randperm(len(train_data)).tolist())\n","train_dataloader = DataLoader(shuffled_train_data, batch_size=batch_size, shuffle=False)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","shuffled_validation_data = torch.utils.data.Subset(validation_data, torch.randperm(len(validation_data)).tolist())\n","validation_dataloader = DataLoader(shuffled_validation_data, batch_size=len(labels_dev), shuffle=False)\n","\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","shuffled_test_data = torch.utils.data.Subset(test_data, torch.randperm(len(test_data)).tolist())\n","test_dataloader = DataLoader(shuffled_test_data, batch_size=len(labels_test), shuffle=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train tensor shapes:\n","Inputs:  torch.Size([6451, 120])\n","Masks:  torch.Size([6451, 120])\n","Labels:  torch.Size([6451, 120])\n","\n","Validation tensor shapes:\n","Inputs:  torch.Size([903, 120])\n","Masks:  torch.Size([903, 120])\n","Labels:  torch.Size([903, 120])\n","\n","Test tensor shapes:\n","Inputs:  torch.Size([1772, 120])\n","Masks:  torch.Size([1772, 120])\n","Labels:  torch.Size([1772, 120])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0KWfz6HVpsN9","executionInfo":{"status":"ok","timestamp":1625747578120,"user_tz":-120,"elapsed":13253,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"b87752ba-ee34-43b4-eda5-e2b23a2d0658"},"source":["# Loading pre trained BERT\n","from transformers import BertForTokenClassification\n","model = BertForTokenClassification.from_pretrained(\"biobert_v1.1_pubmed\", num_labels=num_tags+1) # binary classification\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at biobert_v1.1_pubmed were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at biobert_v1.1_pubmed and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"4yZ1CKM3-BlT"},"source":["In order to evaluate the results after the model training, we will need some packages to incorpore to our model."]},{"cell_type":"code","metadata":{"id":"3D7HOVBz7Y07","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625747585722,"user_tz":-120,"elapsed":7605,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"3255260d-8c49-4702-8393-384efcb1acc9"},"source":["!pip install seqeval\n","!pip install sklearn-crfsuite"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\r\u001b[K     |███████▌                        | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 13.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16184 sha256=d6e1a1bc6a3c7dad87d06fd46d947e469ec7f2ed8e843207afab01e60dc59200\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Collecting sklearn-crfsuite\n","  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (1.15.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.8.9)\n","Collecting python-crfsuite>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n","\u001b[K     |████████████████████████████████| 747kB 10.3MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (4.41.1)\n","Installing collected packages: python-crfsuite, sklearn-crfsuite\n","Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Pipz0b42-N_w"},"source":["Here, an example of the evaluation report is provided. For this, we use the `seqeval` library along with the labels or tags we desire to compute."]},{"cell_type":"code","metadata":{"id":"L9sQnkf_7fxU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625747585723,"user_tz":-120,"elapsed":10,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"dc16e941-0ec1-4c5e-d4d0-ea58d69223c4"},"source":["from sklearn_crfsuite.metrics import flat_classification_report\n","from seqeval.metrics.sequence_labeling import get_entities\n","from seqeval.metrics import classification_report, accuracy_score\n","from seqeval.scheme import IOB2\n","\n","\n","if allTypes:\n","    tags_metrics = ['O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'B-DISEASE', 'I-DISEASE', 'B-SIGN', 'I-SIGN', 'B-SYMPTOM', 'I-SYMPTOM']\n","else:\n","    tags_metrics = ['O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'B-SIGN-SYM', 'I-SIGN-SYM']\n","\n","\n","# Example of metrics\n","_labels = final_dev_labels[-10:]\n","_labels_output = [\n","        [l for l in sentence if l != 0]\n","        for sentence in _labels\n","    ]\n","_converted = [\n","        [tags_metrics[l-1] for l in sentence if l != 0]\n","        for sentence in _labels\n","    ]\n","_report = flat_classification_report(y_true=_converted, y_pred=_converted, labels=tags_metrics, digits=4)\n","\n","print('Tags: {}\\nEntities in tag: {}'.format(tags_metrics, get_entities(tags_metrics)))\n","print()\n","print('Nr of sentences with labels: {}\\nExample of labels: {}\\nConverted labels: {}'.format(len(_labels), _labels_output, _converted))\n","print()\n","print(_report)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tags: ['O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'B-DISEASE', 'I-DISEASE', 'B-SIGN', 'I-SIGN', 'B-SYMPTOM', 'I-SYMPTOM']\n","Entities in tag: [('RAREDISEASE', 1, 2), ('DISEASE', 3, 4), ('SIGN', 5, 6), ('SYMPTOM', 7, 8)]\n","\n","Nr of sentences with labels: 10\n","Example of labels: [[2, 3, 3, 3, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1], [1, 1, 1, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1], [2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n","Converted labels: [['B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'O'], ['O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'B-DISEASE', 'I-DISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n","\n","               precision    recall  f1-score   support\n","\n","            O     1.0000    1.0000    1.0000       168\n","B-RAREDISEASE     1.0000    1.0000    1.0000         8\n","I-RAREDISEASE     1.0000    1.0000    1.0000        29\n","    B-DISEASE     1.0000    1.0000    1.0000         3\n","    I-DISEASE     1.0000    1.0000    1.0000        10\n","       B-SIGN     0.0000    0.0000    0.0000         0\n","       I-SIGN     0.0000    0.0000    0.0000         0\n","    B-SYMPTOM     0.0000    0.0000    0.0000         0\n","    I-SYMPTOM     0.0000    0.0000    0.0000         0\n","\n","    micro avg     1.0000    1.0000    1.0000       218\n","    macro avg     0.5556    0.5556    0.5556       218\n"," weighted avg     1.0000    1.0000    1.0000       218\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"zZ2zHZOn-gRL"},"source":["## 5. Fine tuning the model and training\n","\n","Finally, we define the model parameters and hyper parameters and its training."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jy6n8WG3rAQp","executionInfo":{"status":"ok","timestamp":1625747585724,"user_tz":-120,"elapsed":7,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"355b1cb9-c63c-4544-f76d-454124402bb8"},"source":["# BERT fine-tuning parameters\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n","\n","optimizer = BertAdam(optimizer_grouped_parameters,\n","                     lr=2e-5,\n","                     warmup=.1)\n","\n","# Function to compute the metrics of our predictions vs labels\n","def flat_accuracy(predictions, labels):\n","    \"\"\"\n","    This function computes the accuracy of the network as a float number.\n","    \"\"\"\n","    pred_flat = np.argmax(predictions, axis=2).flatten()\n","    labels_flat = labels.flatten()\n","    valid_predictions = [tags_metrics[p-1] for (p, l) in zip(pred_flat, labels_flat) if l != 0]\n","    valid_flags = [tags_metrics[l-1] for (p, l) in zip(pred_flat, labels_flat) if l != 0]\n","    return accuracy_score(y_true=valid_flags, y_pred=valid_predictions)\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def compute_nn_metrics(predictions, labels, tags=tags_metrics, entity_level=False, imbalanced=False):\n","    \"\"\"\n","    This function computes the metrics of the network through the seqeval model.\n","    \"\"\"\n","    pred_flat = np.argmax(predictions, axis=2).flatten()\n","    labels_flat = labels.flatten()\n","    imbalanced_tags = [t for t in tags]\n","    imbalanced_tags.remove('O')\n","    valid_predictions = [[tags_metrics[p-1] for (p, l) in zip(pred_flat, labels_flat) if l != 0]]\n","    valid_flags = [[tags_metrics[l-1] for (p, l) in zip(pred_flat, labels_flat) if l != 0]]\n","    if entity_level:\n","        return classification_report(y_true=valid_flags, y_pred=valid_predictions, scheme=IOB2, zero_division=0, digits=4)\n","    else:\n","        if imbalanced:\n","            return flat_classification_report(y_true=valid_flags, y_pred=valid_predictions, labels=imbalanced_tags, zero_division=0, digits=4)\n","        else:\n","            return flat_classification_report(y_true=valid_flags, y_pred=valid_predictions, labels=tags, zero_division=0, digits=4)\n","        \n","\n","torch.cuda.empty_cache() \n","# Store our loss and accuracy for plotting\n","train_loss_set = []\n","eval_accuracy_set = []\n","# Number of training epochs \n","epochs = 9"],"execution_count":null,"outputs":[{"output_type":"stream","text":["t_total value of -1 results in schedule not being applied\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1HlVLO_rgJP","executionInfo":{"status":"ok","timestamp":1625748980649,"user_tz":-120,"elapsed":1394571,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"e5196ece-38dd-4b7f-ee61-996c7263c11d"},"source":["# BERT training loop\n","for _ in trange(epochs, desc=\"Epoch\"):  \n","  \n","    ## TRAINING\n","\n","    # Set our model to training mode\n","    model.train()  \n","    # Tracking variables\n","    tr_loss, train_accuracy = 0, 0\n","    nb_train_steps = 0\n","    # Train the data for one epoch\n","    for step, batch in enumerate(train_dataloader):\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Clear out the gradients (by default they accumulate)\n","        optimizer.zero_grad()\n","        # Forward pass\n","        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","        train_loss_set.append(loss.item())   \n","        # Backward pass\n","        loss.backward()\n","        # Update parameters and take a step using the computed gradient\n","        optimizer.step()\n","        # Update tracking variables\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        tmp_train_accuracy = flat_accuracy(logits, label_ids)\n","        train_accuracy += tmp_train_accuracy\n","        tr_loss += loss.item()\n","        nb_train_steps += 1\n","    print(\"\\nTrain loss: {}\".format(tr_loss/nb_train_steps))\n","    print(\"Total Train Accuracy: {}\".format(train_accuracy/nb_train_steps))\n","\n","    ## VALIDATION\n","\n","    # Put model in evaluation mode\n","    model.eval()\n","    # Tracking variables \n","    eval_accuracy = 0\n","    nb_eval_steps = 0\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","        with torch.no_grad():\n","            # Forward pass, calculate logit predictions\n","            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","            logits = outputs.logits\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        eval_metrics = compute_nn_metrics(logits, label_ids)\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy   \n","        eval_accuracy_set.append(tmp_eval_accuracy)    \n","        nb_eval_steps += 1\n","    print('\\nMetrics report in Validation:\\n{}'.format(eval_metrics))\n","    print(\"Total Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\rEpoch:   0%|          | 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Train loss: 0.36115297800538565\n","Total Train Accuracy: 0.8816634662272177\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  11%|█         | 1/9 [02:33<20:24, 153.10s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9668    0.9411    0.9538     16744\n","B-RAREDISEASE     0.8327    0.9123    0.8707       513\n","I-RAREDISEASE     0.8688    0.9462    0.9059      2156\n","    B-DISEASE     0.7169    0.5459    0.6198       218\n","    I-DISEASE     0.6510    0.6045    0.6269       617\n","       B-SIGN     0.6483    0.7556    0.6978       405\n","       I-SIGN     0.6554    0.7423    0.6961      2165\n","    B-SYMPTOM     0.0000    0.0000    0.0000        18\n","    I-SYMPTOM     0.5000    0.0500    0.0909        40\n","\n","     accuracy                         0.9037     22876\n","    macro avg     0.6489    0.6109    0.6069     22876\n"," weighted avg     0.9070    0.9037    0.9042     22876\n","\n","Total Validation Accuracy: 0.9036544850498339\n","\n","Train loss: 0.17234639449063505\n","Total Train Accuracy: 0.940497813646308\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  22%|██▏       | 2/9 [05:08<17:56, 153.73s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9616    0.9591    0.9603     16744\n","B-RAREDISEASE     0.8579    0.9181    0.8870       513\n","I-RAREDISEASE     0.8899    0.9559    0.9217      2156\n","    B-DISEASE     0.7569    0.6284    0.6867       218\n","    I-DISEASE     0.7217    0.6305    0.6730       617\n","       B-SIGN     0.7033    0.7259    0.7145       405\n","       I-SIGN     0.7219    0.7039    0.7128      2165\n","    B-SYMPTOM     0.4762    0.5556    0.5128        18\n","    I-SYMPTOM     0.3750    0.3750    0.3750        40\n","\n","     accuracy                         0.9162     22876\n","    macro avg     0.7183    0.7169    0.7160     22876\n"," weighted avg     0.9154    0.9162    0.9155     22876\n","\n","Total Validation Accuracy: 0.9162440986186396\n","\n","Train loss: 0.11189680338127188\n","Total Train Accuracy: 0.9631389788481257\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  33%|███▎      | 3/9 [07:43<15:25, 154.20s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9567    0.9624    0.9595     16744\n","B-RAREDISEASE     0.8598    0.9084    0.8834       513\n","I-RAREDISEASE     0.8747    0.9457    0.9088      2156\n","    B-DISEASE     0.7233    0.6835    0.7028       218\n","    I-DISEASE     0.6868    0.6256    0.6548       617\n","       B-SIGN     0.7135    0.6395    0.6745       405\n","       I-SIGN     0.7307    0.6517    0.6890      2165\n","    B-SYMPTOM     0.3077    0.6667    0.4211        18\n","    I-SYMPTOM     0.3158    0.4500    0.3711        40\n","\n","     accuracy                         0.9117     22876\n","    macro avg     0.6854    0.7259    0.6961     22876\n"," weighted avg     0.9099    0.9117    0.9103     22876\n","\n","Total Validation Accuracy: 0.9116541353383458\n","\n","Train loss: 0.08565807307489437\n","Total Train Accuracy: 0.9724266108738947\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  44%|████▍     | 4/9 [10:18<12:52, 154.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9522    0.9642    0.9582     16744\n","B-RAREDISEASE     0.8963    0.8596    0.8776       513\n","I-RAREDISEASE     0.9189    0.9202    0.9196      2156\n","    B-DISEASE     0.6490    0.7294    0.6868       218\n","    I-DISEASE     0.6522    0.6840    0.6677       617\n","       B-SIGN     0.7117    0.6765    0.6937       405\n","       I-SIGN     0.7302    0.6462    0.6856      2165\n","    B-SYMPTOM     0.4583    0.6111    0.5238        18\n","    I-SYMPTOM     0.3333    0.4500    0.3830        40\n","\n","     accuracy                         0.9115     22876\n","    macro avg     0.7003    0.7268    0.7107     22876\n"," weighted avg     0.9101    0.9115    0.9105     22876\n","\n","Total Validation Accuracy: 0.9115229935303375\n","\n","Train loss: 0.06139635409477471\n","Total Train Accuracy: 0.9806880572513823\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  56%|█████▌    | 5/9 [12:53<10:18, 154.68s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9538    0.9626    0.9581     16744\n","B-RAREDISEASE     0.8655    0.8908    0.8780       513\n","I-RAREDISEASE     0.8963    0.9420    0.9186      2156\n","    B-DISEASE     0.6844    0.7064    0.6953       218\n","    I-DISEASE     0.6783    0.6937    0.6859       617\n","       B-SIGN     0.7151    0.6568    0.6847       405\n","       I-SIGN     0.7367    0.6333    0.6811      2165\n","    B-SYMPTOM     0.4375    0.7778    0.5600        18\n","    I-SYMPTOM     0.3333    0.5250    0.4078        40\n","\n","     accuracy                         0.9118     22876\n","    macro avg     0.7001    0.7543    0.7188     22876\n"," weighted avg     0.9101    0.9118    0.9104     22876\n","\n","Total Validation Accuracy: 0.911828991082357\n","\n","Train loss: 0.05020635881193793\n","Total Train Accuracy: 0.984503551560655\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  67%|██████▋   | 6/9 [15:28<07:44, 154.81s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9592    0.9623    0.9607     16744\n","B-RAREDISEASE     0.8487    0.8967    0.8720       513\n","I-RAREDISEASE     0.8808    0.9388    0.9088      2156\n","    B-DISEASE     0.6417    0.7477    0.6907       218\n","    I-DISEASE     0.6113    0.7342    0.6672       617\n","       B-SIGN     0.7228    0.6568    0.6882       405\n","       I-SIGN     0.7714    0.6374    0.6980      2165\n","    B-SYMPTOM     0.3889    0.7778    0.5185        18\n","    I-SYMPTOM     0.4200    0.5250    0.4667        40\n","\n","     accuracy                         0.9133     22876\n","    macro avg     0.6939    0.7641    0.7190     22876\n"," weighted avg     0.9135    0.9133    0.9124     22876\n","\n","Total Validation Accuracy: 0.9133152649064522\n","\n","Train loss: 0.039171865232989635\n","Total Train Accuracy: 0.9878136626914769\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  78%|███████▊  | 7/9 [18:04<05:09, 154.95s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9637    0.9541    0.9589     16744\n","B-RAREDISEASE     0.8579    0.8947    0.8760       513\n","I-RAREDISEASE     0.8718    0.9434    0.9062      2156\n","    B-DISEASE     0.6784    0.7064    0.6921       218\n","    I-DISEASE     0.6918    0.6402    0.6650       617\n","       B-SIGN     0.6974    0.7284    0.7126       405\n","       I-SIGN     0.7184    0.7072    0.7128      2165\n","    B-SYMPTOM     0.4667    0.7778    0.5833        18\n","    I-SYMPTOM     0.4375    0.5250    0.4773        40\n","\n","     accuracy                         0.9127     22876\n","    macro avg     0.7093    0.7641    0.7316     22876\n"," weighted avg     0.9134    0.9127    0.9128     22876\n","\n","Total Validation Accuracy: 0.912703269802413\n","\n","Train loss: 0.03330434628849904\n","Total Train Accuracy: 0.9899955401454589\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  89%|████████▉ | 8/9 [20:39<02:35, 155.01s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9538    0.9684    0.9611     16744\n","B-RAREDISEASE     0.8563    0.8713    0.8638       513\n","I-RAREDISEASE     0.8961    0.9165    0.9062      2156\n","    B-DISEASE     0.6667    0.7156    0.6903       218\n","    I-DISEASE     0.6333    0.6969    0.6636       617\n","       B-SIGN     0.7189    0.7136    0.7162       405\n","       I-SIGN     0.7811    0.6379    0.7023      2165\n","    B-SYMPTOM     0.5000    0.6667    0.5714        18\n","    I-SYMPTOM     0.5000    0.5250    0.5122        40\n","\n","     accuracy                         0.9148     22876\n","    macro avg     0.7229    0.7458    0.7319     22876\n"," weighted avg     0.9132    0.9148    0.9132     22876\n","\n","Total Validation Accuracy: 0.9148015387305473\n","\n","Train loss: 0.025763676219993262\n","Total Train Accuracy: 0.9923109128214872\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch: 100%|██████████| 9/9 [23:14<00:00, 154.96s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9555    0.9663    0.9608     16744\n","B-RAREDISEASE     0.8789    0.8772    0.8780       513\n","I-RAREDISEASE     0.9157    0.9170    0.9163      2156\n","    B-DISEASE     0.6740    0.7018    0.6876       218\n","    I-DISEASE     0.6553    0.7180    0.6852       617\n","       B-SIGN     0.7247    0.6889    0.7063       405\n","       I-SIGN     0.7537    0.6642    0.7061      2165\n","    B-SYMPTOM     0.4483    0.7222    0.5532        18\n","    I-SYMPTOM     0.4468    0.5250    0.4828        40\n","\n","     accuracy                         0.9159     22876\n","    macro avg     0.7170    0.7534    0.7307     22876\n"," weighted avg     0.9148    0.9159    0.9150     22876\n","\n","Total Validation Accuracy: 0.91593810106662\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"CfY260HEyfWT","colab":{"base_uri":"https://localhost:8080/","height":616},"executionInfo":{"status":"ok","timestamp":1625748981303,"user_tz":-120,"elapsed":662,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"27508a9c-bf4a-4d23-9ce9-e642078794fb"},"source":["# plot training performance\n","results_figure = plt.figure(figsize=(18,9))\n","ax_train = results_figure.add_subplot(1, 2, 1)\n","ax_val = results_figure.add_subplot(1, 2, 2)\n","results_figure.suptitle('BioBERT Results')\n","ax_train.set_title(\"Training loss evolution\")\n","ax_train.set_xlabel(\"Batch\")\n","ax_train.set_ylabel(\"Loss\")\n","ax_train.plot(train_loss_set)\n","ax_val.set_title(\"Validation accuracy evolution\")\n","ax_val.set_xlabel(\"Batch\")\n","ax_val.set_ylabel(\"Accuracy\")\n","ax_val.plot(eval_accuracy_set)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1296x648 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"bL8Yp-Kz_N7b"},"source":["## 6. Testing the model\n","\n","The final step is to test the model. This step is similar to the evaluation one with the difference that the input dataset is changed."]},{"cell_type":"code","metadata":{"id":"orWXD7pk0GgF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625748996404,"user_tz":-120,"elapsed":15104,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"c2eb90d2-2b0e-4eb5-8cee-08547d10999c"},"source":["## TEST\n","\n","# Put model in evaluation mode\n","model.eval()\n","# Evaluate data for one epoch\n","for batch in test_dataloader:\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","    with torch.no_grad():\n","        # Forward pass, calculate logit predictions\n","        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","        logits = outputs.logits   \n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    test_metrics = compute_nn_metrics(logits, label_ids)\n","    test_metrics_imbalanced = compute_nn_metrics(logits, label_ids, imbalanced=True)\n","    test_metrics_per_entity = compute_nn_metrics(logits, label_ids, entity_level=True)\n","print('Metrics report in Test (with \"O\" class):\\n{}'.format(test_metrics))\n","print('Metrics report in Test (w/o \"O\" class):\\n{}'.format(test_metrics_imbalanced))\n","print('Metrics report in Test per entity:\\n{}'.format(test_metrics_per_entity))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Metrics report in Test (with \"O\" class):\n","               precision    recall  f1-score   support\n","\n","            O     0.9663    0.9653    0.9658     35108\n","B-RAREDISEASE     0.8825    0.8816    0.8821      1073\n","I-RAREDISEASE     0.9142    0.8927    0.9033      4370\n","    B-DISEASE     0.6356    0.7088    0.6702       443\n","    I-DISEASE     0.5716    0.6964    0.6279      1278\n","       B-SIGN     0.7238    0.7049    0.7142       803\n","       I-SIGN     0.7330    0.6978    0.7150      3762\n","    B-SYMPTOM     0.6349    0.8000    0.7080        50\n","    I-SYMPTOM     0.5538    0.5538    0.5538       130\n","\n","     accuracy                         0.9197     47017\n","    macro avg     0.7351    0.7668    0.7489     47017\n"," weighted avg     0.9214    0.9197    0.9203     47017\n","\n","Metrics report in Test (w/o \"O\" class):\n","               precision    recall  f1-score   support\n","\n","B-RAREDISEASE     0.8825    0.8816    0.8821      1073\n","I-RAREDISEASE     0.9142    0.8927    0.9033      4370\n","    B-DISEASE     0.6356    0.7088    0.6702       443\n","    I-DISEASE     0.5716    0.6964    0.6279      1278\n","       B-SIGN     0.7238    0.7049    0.7142       803\n","       I-SIGN     0.7330    0.6978    0.7150      3762\n","    B-SYMPTOM     0.6349    0.8000    0.7080        50\n","    I-SYMPTOM     0.5538    0.5538    0.5538       130\n","\n","    micro avg     0.7830    0.7855    0.7842     11909\n","    macro avg     0.7062    0.7420    0.7218     11909\n"," weighted avg     0.7890    0.7855    0.7863     11909\n","\n","Metrics report in Test per entity:\n","              precision    recall  f1-score   support\n","\n","     DISEASE     0.5607    0.6608    0.6067       454\n"," RAREDISEASE     0.8522    0.8530    0.8526      1095\n","        SIGN     0.5574    0.5877    0.5722       958\n","     SYMPTOM     0.5143    0.6667    0.5806        54\n","\n","   micro avg     0.6761    0.7157    0.6954      2561\n","   macro avg     0.6212    0.6920    0.6530      2561\n","weighted avg     0.6831    0.7157    0.6984      2561\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o2naPUQ2RQeM"},"source":["Scenarios:\n","\n","    - I. Surface string and entity type match\n","    - II. System hypothesized an entity\n","    - III. System misses an entity\n","    - IV. System assigns the wrong entity type\n","    - V. System gets the boundaries of the surface string wrong\n","    - VI. System gets the boundaries and entity type wrong\n","\n","MUC metrics:\n","\n","    - Correct (COR) : both are the same\n","    - Incorrect (INC) : the output of a system and the golden annotation don’t match\n","    - Partial (PAR) : system and the golden annotation are somewhat “similar” but not the same\n","    - Missing (MIS) : a golden annotation is not captured by a system\n","    - Spurius (SPU) : system produces a response which doesn’t exist in the golden annotation\n","\n","Four different ways to measure precision/recall/f1-score:\n","\n","    - Strict: exact boundary surface string match and entity type\n","    - Exact: exact boundary match over the surface string, regardless of the type\n","    - Partial: partial boundary match over the surface string, regardless of the type\n","    - Type: some overlap between the system tagged entity and the gold annotation is required\n"]},{"cell_type":"code","metadata":{"id":"yv6oob40RPgi"},"source":["import logging\n","from collections import namedtuple\n","from copy import deepcopy\n","\n","logging.basicConfig(\n","    format=\"%(asctime)s %(name)s %(levelname)s: %(message)s\",\n","    datefmt=\"%Y-%m-%d %H:%M:%S\",\n","    level=\"DEBUG\",\n",")\n","\n","Entity = namedtuple(\"Entity\", \"e_type start_offset end_offset\")\n","\n","class Evaluator():\n","\n","    def __init__(self, true, pred, tags):\n","        \"\"\"\n","        \"\"\"\n","\n","        if len(true) != len(pred):\n","            raise ValueError(\"Number of predicted documents does not equal true\")\n","\n","        self.true = true\n","        self.pred = pred\n","        self.tags = tags\n","\n","        # Setup dict into which metrics will be stored.\n","\n","        self.metrics_results = {\n","            'correct': 0,\n","            'incorrect': 0,\n","            'partial': 0,\n","            'missed': 0,\n","            'spurious': 0,\n","            'possible': 0,\n","            'actual': 0,\n","            'precision': 0,\n","            'recall': 0,\n","        }\n","\n","        # Copy results dict to cover the four schemes.\n","\n","        self.results = {\n","            'strict': deepcopy(self.metrics_results),\n","            'ent_type': deepcopy(self.metrics_results),\n","            'partial':deepcopy(self.metrics_results),\n","            'exact':deepcopy(self.metrics_results),\n","            }\n","\n","        # Create an accumulator to store results\n","\n","        self.evaluation_agg_entities_type = {e: deepcopy(self.results) for e in tags}\n","\n","\n","    def evaluate(self):\n","\n","        logging.info(\n","            \"Imported %s predictions for %s true examples\",\n","            len(self.pred), len(self.true)\n","        )\n","\n","        for true_ents, pred_ents in zip(self.true, self.pred):\n","\n","            # Check that the length of the true and predicted examples are the\n","            # same. This must be checked here, because another error may not\n","            # be thrown if the lengths do not match.\n","\n","            if len(true_ents) != len(pred_ents):\n","                raise ValueError(\"Prediction length does not match true example length\")\n","\n","            # Compute results for one message\n","\n","            tmp_results, tmp_agg_results = compute_metrics(\n","                collect_named_entities(true_ents),\n","                collect_named_entities(pred_ents),\n","                self.tags\n","            )\n","\n","            # Cycle through each result and accumulate\n","\n","            # TODO: Combine these loops below:\n","\n","            for eval_schema in self.results:\n","\n","                for metric in self.results[eval_schema]:\n","\n","                    self.results[eval_schema][metric] += tmp_results[eval_schema][metric]\n","\n","            # Calculate global precision and recall\n","\n","            self.results = compute_precision_recall_wrapper(self.results)\n","\n","            # Aggregate results by entity type\n","\n","            for e_type in self.tags:\n","\n","                for eval_schema in tmp_agg_results[e_type]:\n","\n","                    for metric in tmp_agg_results[e_type][eval_schema]:\n","\n","                        self.evaluation_agg_entities_type[e_type][eval_schema][metric] += tmp_agg_results[e_type][eval_schema][metric]\n","\n","                # Calculate precision recall at the individual entity level\n","\n","                self.evaluation_agg_entities_type[e_type] = compute_precision_recall_wrapper(self.evaluation_agg_entities_type[e_type])\n","\n","        return self.results, self.evaluation_agg_entities_type\n","\n","\n","def collect_named_entities(tokens):\n","    \"\"\"\n","    Creates a list of Entity named-tuples, storing the entity type and the start and end\n","    offsets of the entity.\n","    :param tokens: a list of tags\n","    :return: a list of Entity named-tuples\n","    \"\"\"\n","\n","    named_entities = []\n","    start_offset = None\n","    end_offset = None\n","    ent_type = None\n","\n","    for offset, token_tag in enumerate(tokens):\n","\n","        if token_tag == 'O':\n","            if ent_type is not None and start_offset is not None:\n","                end_offset = offset - 1\n","                named_entities.append(Entity(ent_type, start_offset, end_offset))\n","                start_offset = None\n","                end_offset = None\n","                ent_type = None\n","\n","        elif ent_type is None:\n","            ent_type = token_tag[2:]\n","            start_offset = offset\n","\n","        elif ent_type != token_tag[2:] or (ent_type == token_tag[2:] and token_tag[:1] == 'B'):\n","\n","            end_offset = offset - 1\n","            named_entities.append(Entity(ent_type, start_offset, end_offset))\n","\n","            # start of a new entity\n","            ent_type = token_tag[2:]\n","            start_offset = offset\n","            end_offset = None\n","\n","    # catches an entity that goes up until the last token\n","\n","    if ent_type is not None and start_offset is not None and end_offset is None:\n","        named_entities.append(Entity(ent_type, start_offset, len(tokens)-1))\n","\n","    return named_entities\n","\n","\n","def compute_metrics(true_named_entities, pred_named_entities, tags):\n","\n","\n","    eval_metrics = {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'precision': 0, 'recall': 0}\n","\n","    # overall results\n","    \n","    evaluation = {\n","        'strict': deepcopy(eval_metrics),\n","        'ent_type': deepcopy(eval_metrics),\n","        'partial': deepcopy(eval_metrics),\n","        'exact': deepcopy(eval_metrics)\n","    }\n","\n","    # results by entity type\n","\n","    evaluation_agg_entities_type = {e: deepcopy(evaluation) for e in tags}\n","\n","    # keep track of entities that overlapped\n","\n","    true_which_overlapped_with_pred = []\n","\n","    # Subset into only the tags that we are interested in.\n","    # NOTE: we remove the tags we don't want from both the predicted and the\n","    # true entities. This covers the two cases where mismatches can occur:\n","    #\n","    # 1) Where the model predicts a tag that is not present in the true data\n","    # 2) Where there is a tag in the true data that the model is not capable of\n","    # predicting.\n","\n","    true_named_entities = [ent for ent in true_named_entities if ent.e_type in tags]\n","    pred_named_entities = [ent for ent in pred_named_entities if ent.e_type in tags]\n","\n","    # go through each predicted named-entity\n","\n","    for pred in pred_named_entities:\n","        found_overlap = False\n","\n","        # Check each of the potential scenarios in turn. See\n","        # http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/\n","        # for scenario explanation.\n","\n","        # Scenario I: Exact match between true and pred\n","\n","        if pred in true_named_entities:\n","            true_which_overlapped_with_pred.append(pred)\n","            evaluation['strict']['correct'] += 1\n","            evaluation['ent_type']['correct'] += 1\n","            evaluation['exact']['correct'] += 1\n","            evaluation['partial']['correct'] += 1\n","\n","            # for the agg. by e_type results\n","            evaluation_agg_entities_type[pred.e_type]['strict']['correct'] += 1\n","            evaluation_agg_entities_type[pred.e_type]['ent_type']['correct'] += 1\n","            evaluation_agg_entities_type[pred.e_type]['exact']['correct'] += 1\n","            evaluation_agg_entities_type[pred.e_type]['partial']['correct'] += 1\n","\n","        else:\n","\n","            # check for overlaps with any of the true entities\n","\n","            for true in true_named_entities:\n","\n","                pred_range = range(pred.start_offset, pred.end_offset)\n","                true_range = range(true.start_offset, true.end_offset)\n","\n","                # Scenario IV: Offsets match, but entity type is wrong\n","\n","                if true.start_offset == pred.start_offset and pred.end_offset == true.end_offset \\\n","                        and true.e_type != pred.e_type:\n","\n","                    # overall results\n","                    evaluation['strict']['incorrect'] += 1\n","                    evaluation['ent_type']['incorrect'] += 1\n","                    evaluation['partial']['correct'] += 1\n","                    evaluation['exact']['correct'] += 1\n","\n","                    # aggregated by entity type results\n","                    evaluation_agg_entities_type[true.e_type]['strict']['incorrect'] += 1\n","                    evaluation_agg_entities_type[true.e_type]['ent_type']['incorrect'] += 1\n","                    evaluation_agg_entities_type[true.e_type]['partial']['correct'] += 1\n","                    evaluation_agg_entities_type[true.e_type]['exact']['correct'] += 1\n","\n","                    true_which_overlapped_with_pred.append(true)\n","                    found_overlap = True\n","\n","                    break\n","\n","                # check for an overlap i.e. not exact boundary match, with true entities\n","\n","                elif find_overlap(true_range, pred_range):\n","\n","                    true_which_overlapped_with_pred.append(true)\n","\n","                    # Scenario V: There is an overlap (but offsets do not match\n","                    # exactly), and the entity type is the same.\n","                    # 2.1 overlaps with the same entity type\n","\n","                    if pred.e_type == true.e_type:\n","\n","                        # overall results\n","                        evaluation['strict']['incorrect'] += 1\n","                        evaluation['ent_type']['correct'] += 1\n","                        evaluation['partial']['partial'] += 1\n","                        evaluation['exact']['incorrect'] += 1\n","\n","                        # aggregated by entity type results\n","                        evaluation_agg_entities_type[true.e_type]['strict']['incorrect'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['ent_type']['correct'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['partial']['partial'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['exact']['incorrect'] += 1\n","\n","                        found_overlap = True\n","\n","                        break\n","\n","                    # Scenario VI: Entities overlap, but the entity type is\n","                    # different.\n","\n","                    else:\n","                        # overall results\n","                        evaluation['strict']['incorrect'] += 1\n","                        evaluation['ent_type']['incorrect'] += 1\n","                        evaluation['partial']['partial'] += 1\n","                        evaluation['exact']['incorrect'] += 1\n","\n","                        # aggregated by entity type results\n","                        # Results against the true entity\n","\n","                        evaluation_agg_entities_type[true.e_type]['strict']['incorrect'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['partial']['partial'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['ent_type']['incorrect'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['exact']['incorrect'] += 1\n","\n","                        # Results against the predicted entity\n","\n","                        # evaluation_agg_entities_type[pred.e_type]['strict']['spurious'] += 1\n","\n","                        found_overlap = True\n","\n","                        break\n","\n","            # Scenario II: Entities are spurious (i.e., over-generated).\n","\n","            if not found_overlap:\n","\n","                # Overall results\n","\n","                evaluation['strict']['spurious'] += 1\n","                evaluation['ent_type']['spurious'] += 1\n","                evaluation['partial']['spurious'] += 1\n","                evaluation['exact']['spurious'] += 1\n","\n","                # Aggregated by entity type results\n","\n","                # NOTE: when pred.e_type is not found in tags\n","                # or when it simply does not appear in the test set, then it is\n","                # spurious, but it is not clear where to assign it at the tag\n","                # level. In this case, it is applied to all target_tags\n","                # found in this example. This will mean that the sum of the\n","                # evaluation_agg_entities will not equal evaluation.\n","\n","                for true in tags:                    \n","\n","                    evaluation_agg_entities_type[true]['strict']['spurious'] += 1\n","                    evaluation_agg_entities_type[true]['ent_type']['spurious'] += 1\n","                    evaluation_agg_entities_type[true]['partial']['spurious'] += 1\n","                    evaluation_agg_entities_type[true]['exact']['spurious'] += 1\n","\n","    # Scenario III: Entity was missed entirely.\n","\n","    for true in true_named_entities:\n","        if true in true_which_overlapped_with_pred:\n","            continue\n","        else:\n","            # overall results\n","            evaluation['strict']['missed'] += 1\n","            evaluation['ent_type']['missed'] += 1\n","            evaluation['partial']['missed'] += 1\n","            evaluation['exact']['missed'] += 1\n","\n","            # for the agg. by e_type\n","            evaluation_agg_entities_type[true.e_type]['strict']['missed'] += 1\n","            evaluation_agg_entities_type[true.e_type]['ent_type']['missed'] += 1\n","            evaluation_agg_entities_type[true.e_type]['partial']['missed'] += 1\n","            evaluation_agg_entities_type[true.e_type]['exact']['missed'] += 1\n","\n","    # Compute 'possible', 'actual' according to SemEval-2013 Task 9.1 on the\n","    # overall results, and use these to calculate precision and recall.\n","\n","    for eval_type in evaluation:\n","        evaluation[eval_type] = compute_actual_possible(evaluation[eval_type])\n","\n","    # Compute 'possible', 'actual', and precision and recall on entity level\n","    # results. Start by cycling through the accumulated results.\n","\n","    for entity_type, entity_level in evaluation_agg_entities_type.items():\n","\n","        # Cycle through the evaluation types for each dict containing entity\n","        # level results.\n","\n","        for eval_type in entity_level:\n","\n","            evaluation_agg_entities_type[entity_type][eval_type] = compute_actual_possible(\n","                entity_level[eval_type]\n","            )\n","\n","    return evaluation, evaluation_agg_entities_type\n","\n","\n","def find_overlap(true_range, pred_range):\n","    \"\"\"Find the overlap between two ranges\n","    Find the overlap between two ranges. Return the overlapping values if\n","    present, else return an empty set().\n","    Examples:\n","    >>> find_overlap((1, 2), (2, 3))\n","    2\n","    >>> find_overlap((1, 2), (3, 4))\n","    set()\n","    \"\"\"\n","\n","    true_set = set(true_range)\n","    pred_set = set(pred_range)\n","\n","    overlaps = true_set.intersection(pred_set)\n","\n","    return overlaps\n","\n","\n","def compute_actual_possible(results):\n","    \"\"\"\n","    Takes a result dict that has been output by compute metrics.\n","    Returns the results dict with actual, possible populated.\n","    When the results dicts is from partial or ent_type metrics, then\n","    partial_or_type=True to ensure the right calculation is used for\n","    calculating precision and recall.\n","    \"\"\"\n","\n","    correct = results['correct']\n","    incorrect = results['incorrect']\n","    partial = results['partial']\n","    missed = results['missed']\n","    spurious = results['spurious']\n","\n","    # Possible: number annotations in the gold-standard which contribute to the\n","    # final score\n","\n","    possible = correct + incorrect + partial + missed\n","\n","    # Actual: number of annotations produced by the NER system\n","\n","    actual = correct + incorrect + partial + spurious\n","\n","    results[\"actual\"] = actual\n","    results[\"possible\"] = possible\n","\n","    return results\n","\n","\n","def compute_precision_recall(results, partial_or_type=False):\n","    \"\"\"\n","    Takes a result dict that has been output by compute metrics.\n","    Returns the results dict with precison and recall populated.\n","    When the results dicts is from partial or ent_type metrics, then\n","    partial_or_type=True to ensure the right calculation is used for\n","    calculating precision and recall.\n","    \"\"\"\n","\n","    actual = results[\"actual\"]\n","    possible = results[\"possible\"]\n","    partial = results['partial']\n","    correct = results['correct']\n","\n","    if partial_or_type:\n","        precision = (correct + 0.5 * partial) / actual if actual > 0 else 0\n","        recall = (correct + 0.5 * partial) / possible if possible > 0 else 0\n","\n","    else:\n","        precision = correct / actual if actual > 0 else 0\n","        recall = correct / possible if possible > 0 else 0\n","\n","    results[\"precision\"] = precision\n","    results[\"recall\"] = recall\n","\n","    return results\n","\n","\n","def compute_precision_recall_wrapper(results):\n","    \"\"\"\n","    Wraps the compute_precision_recall function and runs on a dict of results\n","    \"\"\"\n","\n","    results_a = {key: compute_precision_recall(value, True) for key, value in results.items() if\n","                 key in ['partial', 'ent_type']}\n","    results_b = {key: compute_precision_recall(value) for key, value in results.items() if\n","                 key in ['strict', 'exact']}\n","\n","    results = {**results_a, **results_b}\n","\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z7MzfEKfRpys","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625748997762,"user_tz":-120,"elapsed":361,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"b3eabd8a-2d8d-47f0-fff9-7d6b6f78d81a"},"source":["inputs_idxs = b_input_ids.to('cpu').numpy()\n","inputs_idxs = [[i for i in sentence if i != 0] for sentence in inputs_idxs]\n","inputs_idxs = [tokenizer.convert_ids_to_tokens(sentence) for sentence in inputs_idxs]\n","pred_flat = np.argmax(logits, axis=2)\n","pred_sym = [[tags_metrics[l-1] for l in sentence if l != 0] for sentence in pred_flat]\n","true_flags = [[tags_metrics[l-1] for l in sentence if l != 0] for sentence in label_ids]\n","pred_flags = []\n","\n","for sp, st in zip(pred_sym, true_flags):\n","    limit = len(st)\n","    new = sp[:limit]\n","    pred_flags.append(new)\n","\n","print('Labels and sentences created')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Labels and sentences created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l9qcbi72Ra02","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625748998117,"user_tz":-120,"elapsed":357,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"34d3fa7a-d9bd-4d79-fa15-3b66dd0cd289"},"source":["import random\n","\n","random.seed(3)\n","result_examples_idx = random.sample(range(len(true_flags)), k=30)\n","result_examples_y_gold = list()\n","result_examples_y_pred = list()\n","original_sentences = list()\n","\n","for idx in result_examples_idx:\n","    result_examples_y_gold.append(true_flags[idx])\n","    result_examples_y_pred.append(pred_flags[idx])\n","    original_sentences.append(inputs_idxs[idx])\n","\n","itr = 0\n","for g, p, s in zip(result_examples_y_gold, result_examples_y_pred, original_sentences):\n","    assert len(g) == len(p), 'Results does not seem to be the same'\n","    print('Sentence Nr: ', result_examples_idx[itr])\n","    original_s = pd.Series(s, name='WORD')\n","    df = pd.DataFrame(original_s)\n","    df['GOLD'] = g\n","    df['PRED'] = p\n","    print(df)\n","    itr += 1\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sentence Nr:  487\n","        WORD           GOLD           PRED\n","0        the              O              O\n","1      major              O              O\n","2   physical              O              O\n","3   features              O              O\n","4         of              O              O\n","5         ad  B-RAREDISEASE  B-RAREDISEASE\n","6      ##ams  I-RAREDISEASE  I-RAREDISEASE\n","7          -  I-RAREDISEASE  I-RAREDISEASE\n","8      olive  I-RAREDISEASE  I-RAREDISEASE\n","9        ##r  I-RAREDISEASE  I-RAREDISEASE\n","10  syndrome  I-RAREDISEASE  I-RAREDISEASE\n","11         (              O              O\n","12         i              O              O\n","13         .              O              O\n","14         e              O              O\n","15         .              O              O\n","16         ,              O              O\n","17     scalp         B-SIGN         B-SIGN\n","18   defects         I-SIGN         I-SIGN\n","19       and              O              O\n","20      limb              O         B-SIGN\n","21  abnormal              O         I-SIGN\n","22   ##ities              O         I-SIGN\n","23         )              O              O\n","24       are              O              O\n","25  apparent              O              O\n","26        at              O              O\n","27     birth              O              O\n","28         (              O              O\n","29       con         I-SIGN         I-SIGN\n","30     ##gen         I-SIGN         I-SIGN\n","31    ##ital         I-SIGN         I-SIGN\n","32         )              O              O\n","33         .              O              O\n","\n","Sentence Nr:  1213\n","             WORD           GOLD           PRED\n","0           there              O              O\n","1             are              O              O\n","2        numerous              O              O\n","3      conditions              O              O\n","4   characterized              O              O\n","5              by              O              O\n","6           signs              O              O\n","7             and              O              O\n","8        symptoms              O              O\n","9            that              O              O\n","10            are              O              O\n","11        similar              O              O\n","12             to              O              O\n","13          those              O              O\n","14          found              O              O\n","15             in              O              O\n","16              a  B-RAREDISEASE  B-RAREDISEASE\n","17          ##rac  I-RAREDISEASE  I-RAREDISEASE\n","18           ##hn  I-RAREDISEASE  I-RAREDISEASE\n","19          ##oid  I-RAREDISEASE  I-RAREDISEASE\n","20         ##itis  I-RAREDISEASE  I-RAREDISEASE\n","21              ,              O              O\n","22        however              O              O\n","23              ,              O              O\n","24           only              O              O\n","25              a              O              O\n","26            few              O              O\n","27           will              O              O\n","28             be              O              O\n","29         listed              O              O\n","30              .              O              O\n","\n","Sentence Nr:  1114\n","           WORD           GOLD           PRED\n","0           dry         B-SIGN         B-SIGN\n","1         cough         I-SIGN         I-SIGN\n","2            is              O              O\n","3           one              O              O\n","4   distinction              O              O\n","5          from              O              O\n","6       typical              O      B-DISEASE\n","7     pneumonia      B-DISEASE      I-DISEASE\n","8       because              O              O\n","9          spit              O              O\n","10            (              O              O\n","11            s         B-SIGN         B-SIGN\n","12        ##put         I-SIGN         I-SIGN\n","13         ##um         I-SIGN         I-SIGN\n","14            )              O              O\n","15           is              O              O\n","16          too              O              O\n","17        thick              O         I-SIGN\n","18           to         I-SIGN              O\n","19       become         I-SIGN              O\n","20   productive         I-SIGN         I-SIGN\n","21            ,              O              O\n","22    therefore              O              O\n","23   productive              O         B-SIGN\n","24        cough         B-SIGN         I-SIGN\n","25           is              O              O\n","26          not              O              O\n","27           as              O              O\n","28       common              O              O\n","29           in              O              O\n","30            p  B-RAREDISEASE  B-RAREDISEASE\n","31          ##j  I-RAREDISEASE  I-RAREDISEASE\n","32          ##p  I-RAREDISEASE  I-RAREDISEASE\n","33            .              O              O\n","\n","Sentence Nr:  267\n","            WORD GOLD PRED\n","0        however    O    O\n","1              ,    O    O\n","2        despite    O    O\n","3          these    O    O\n","4   similarities    O    O\n","5              ,    O    O\n","6            the    O    O\n","7            two    O    O\n","8      disorders    O    O\n","9            are    O    O\n","10      distinct    O    O\n","11             .    O    O\n","\n","Sentence Nr:  757\n","        WORD GOLD PRED\n","0        the    O    O\n","1      exact    O    O\n","2     number    O    O\n","3         of    O    O\n","4     people    O    O\n","5        who    O    O\n","6       have    O    O\n","7       this    O    O\n","8   disorder    O    O\n","9         is    O    O\n","10   unknown    O    O\n","11         .    O    O\n","\n","Sentence Nr:  1236\n","          WORD GOLD PRED\n","0          the    O    O\n","1     disorder    O    O\n","2          was    O    O\n","3    initially    O    O\n","4    described    O    O\n","5           in    O    O\n","6          the    O    O\n","7      medical    O    O\n","8   literature    O    O\n","9           in    O    O\n","10        1973    O    O\n","11           .    O    O\n","\n","Sentence Nr:  970\n","       WORD           GOLD           PRED\n","0       add  B-RAREDISEASE  B-RAREDISEASE\n","1    ##ison  I-RAREDISEASE  I-RAREDISEASE\n","2         ’  I-RAREDISEASE  I-RAREDISEASE\n","3         s  I-RAREDISEASE  I-RAREDISEASE\n","4   disease  I-RAREDISEASE  I-RAREDISEASE\n","5   affects              O              O\n","6     males              O              O\n","7       and              O              O\n","8   females              O              O\n","9        in              O              O\n","10    equal              O              O\n","11  numbers              O              O\n","12        .              O              O\n","\n","Sentence Nr:  1281\n","          WORD GOLD PRED\n","0        there    O    O\n","1           is    O    O\n","2   tremendous    O    O\n","3    diversity    O    O\n","4           in    O    O\n","5          the    O    O\n","6         type    O    O\n","7          and    O    O\n","8     severity    O    O\n","9           of    O    O\n","10    symptoms    O    O\n","11        from    O    O\n","12     patient    O    O\n","13          to    O    O\n","14     patient    O    O\n","15           .    O    O\n","\n","Sentence Nr:  1189\n","           WORD GOLD PRED\n","0          step    O    O\n","1        ##wise    O    O\n","2       testing    O    O\n","3           for    O    O\n","4             p    O    O\n","5          ##ho    O    O\n","6           ##x    O    O\n","7           ##2    O    O\n","8           ##b    O    O\n","9     mutations    O    O\n","10       should    O    O\n","11           be    O    O\n","12         done    O    O\n","13         with    O    O\n","14        close    O    O\n","15  involvement    O    O\n","16           by    O    O\n","17            a    O    O\n","18    physician    O    O\n","19          and    O    O\n","20      genetic    O    O\n","21    counselor    O    O\n","22            .    O    O\n","\n","Sentence Nr:  134\n","          WORD GOLD PRED\n","0         they    O    O\n","1          may    O    O\n","2           be    O    O\n","3   widespread    O    O\n","4         over    O    O\n","5          the    O    O\n","6        trunk    O    O\n","7            ,    O    O\n","8         back    O    O\n","9            ,    O    O\n","10         and    O    O\n","11           /    O    O\n","12          or    O    O\n","13   shoulders    O    O\n","14           .    O    O\n","\n","Sentence Nr:  1240\n","        WORD GOLD PRED\n","0      early    O    O\n","1  diagnosis    O    O\n","2        and    O    O\n","3        pro    O    O\n","4      ##mpt    O    O\n","5  treatment    O    O\n","6         is    O    O\n","7  essential    O    O\n","8          .    O    O\n","\n","Sentence Nr:  26\n","           WORD       GOLD           PRED\n","0     secondary          O  B-RAREDISEASE\n","1             r  B-DISEASE  I-RAREDISEASE\n","2          ##ls  I-DISEASE  I-RAREDISEASE\n","3           may          O              O\n","4         occur          O              O\n","5            in          O              O\n","6   association          O              O\n","7          with          O              O\n","8       certain          O              O\n","9    conditions          O              O\n","10            ,          O              O\n","11         such          O              O\n","12           as          O              O\n","13         iron  B-DISEASE      B-DISEASE\n","14   deficiency  I-DISEASE      I-DISEASE\n","15            ,          O              O\n","16          low          O              O\n","17       levels          O              O\n","18           of          O              O\n","19          the          O              O\n","20       oxygen          O              O\n","21            -          O              O\n","22     carrying          O              O\n","23    component          O              O\n","24           of          O              O\n","25          red          O              O\n","26        blood          O              O\n","27        cells          O              O\n","28            (          O              O\n","29           an  B-DISEASE      B-DISEASE\n","30       ##emia  I-DISEASE      I-DISEASE\n","31            )          O              O\n","32            ,          O              O\n","33       kidney  B-DISEASE      B-DISEASE\n","34      failure  I-DISEASE      I-DISEASE\n","35            ,          O              O\n","36           or          O              O\n","37    pregnancy          O      B-DISEASE\n","38            .          O              O\n","\n","Sentence Nr:  1715\n","       WORD GOLD PRED\n","0    stress    O    O\n","1       and    O    O\n","2     local    O    O\n","3    injury    O    O\n","4       may    O    O\n","5      also    O    O\n","6        be    O    O\n","7  involved    O    O\n","8         .    O    O\n","\n","Sentence Nr:  960\n","         WORD GOLD PRED\n","0         the    O    O\n","1       range    O    O\n","2         and    O    O\n","3    severity    O    O\n","4          of    O    O\n","5    symptoms    O    O\n","6      varies    O    O\n","7           ,    O    O\n","8     greatly    O    O\n","9   depending    O    O\n","10         on    O    O\n","11        the    O    O\n","12      exact    O    O\n","13   location    O    O\n","14        and    O    O\n","15       size    O    O\n","16         of    O    O\n","17        the    O    O\n","18    missing    O    O\n","19    genetic    O    O\n","20   material    O    O\n","21          .    O    O\n","\n","Sentence Nr:  531\n","       WORD GOLD PRED\n","0      some    O    O\n","1       may    O    O\n","2        be    O    O\n","3     large    O    O\n","4    enough    O    O\n","5        to    O    O\n","6        be    O    O\n","7    called    O    O\n","8         “    O    O\n","9    giants    O    O\n","10        ”    O    O\n","11    while    O    O\n","12   others    O    O\n","13      may    O    O\n","14       be    O    O\n","15  limited    O    O\n","16       to    O    O\n","17    small    O    O\n","18    areas    O    O\n","19       of    O    O\n","20      the    O    O\n","21  temples    O    O\n","22       or    O    O\n","23   cheeks    O    O\n","24        .    O    O\n","\n","Sentence Nr:  1128\n","       WORD           GOLD           PRED\n","0         g  B-RAREDISEASE  B-RAREDISEASE\n","1       ##s  I-RAREDISEASE  I-RAREDISEASE\n","2       ##d  I-RAREDISEASE  I-RAREDISEASE\n","3      type  I-RAREDISEASE  I-RAREDISEASE\n","4         v  I-RAREDISEASE  I-RAREDISEASE\n","5      ##ii  I-RAREDISEASE  I-RAREDISEASE\n","6   affects              O              O\n","7     males              O              O\n","8       and              O              O\n","9   females              O              O\n","10       in              O              O\n","11    equal              O              O\n","12  numbers              O              O\n","13        .              O              O\n","\n","Sentence Nr:  479\n","         WORD GOLD PRED\n","0           a    O    O\n","1      family    O    O\n","2     history    O    O\n","3         and    O    O\n","4    physical    O    O\n","5        exam    O    O\n","6         can    O    O\n","7     confirm    O    O\n","8         the    O    O\n","9   diagnosis    O    O\n","10          .    O    O\n","\n","Sentence Nr:  392\n","         WORD           GOLD           PRED\n","0       hairy  B-RAREDISEASE  B-RAREDISEASE\n","1      tongue  I-RAREDISEASE  I-RAREDISEASE\n","2        most              O              O\n","3    commonly              O              O\n","4     affects              O              O\n","5      adults              O              O\n","6           ;              O              O\n","7     however              O              O\n","8           ,              O              O\n","9          it              O              O\n","10        may              O              O\n","11  sometimes              O              O\n","12      occur              O              O\n","13     during              O              O\n","14  childhood              O              O\n","15         or              O              O\n","16         ad              O              O\n","17      ##ole              O              O\n","18   ##scence              O              O\n","19          .              O              O\n","\n","Sentence Nr:  1468\n","           WORD       GOLD           PRED\n","0            in          O              O\n","1      contrast          O              O\n","2            to          O              O\n","3        purely          O              O\n","4    peripheral  B-DISEASE      B-DISEASE\n","5            ne  I-DISEASE      I-DISEASE\n","6         ##uro  I-DISEASE      I-DISEASE\n","7        ##path  I-DISEASE      I-DISEASE\n","8         ##ies  I-DISEASE      I-DISEASE\n","9             ,          O              O\n","10          the          O              O\n","11       reflex          O              O\n","12           of          O              O\n","13          the          O              O\n","14         toes          O              O\n","15        known          O              O\n","16           as          O              O\n","17            b     B-SIGN  B-RAREDISEASE\n","18        ##abi     I-SIGN  I-RAREDISEASE\n","19         ##ns     I-SIGN  I-RAREDISEASE\n","20         ##ki     I-SIGN  I-RAREDISEASE\n","21            ’     I-SIGN         I-SIGN\n","22            s     I-SIGN         I-SIGN\n","23         sign     I-SIGN         I-SIGN\n","24           is     I-SIGN              O\n","25        often     I-SIGN              O\n","26     positive     I-SIGN              O\n","27            ,          O              O\n","28   indicating          O              O\n","29  involvement          O              O\n","30           of          O              O\n","31      central          O              O\n","32        motor          O              O\n","33     pathways          O              O\n","34            .          O              O\n","\n","Sentence Nr:  963\n","          WORD GOLD    PRED\n","0        these    O       O\n","1       tumors    O  B-SIGN\n","2          are    O       O\n","3   frequently    O       O\n","4        micro    O       O\n","5     ##scopic    O       O\n","6          and    O       O\n","7    extremely    O       O\n","8    difficult    O       O\n","9           to    O       O\n","10      detect    O       O\n","11           .    O       O\n","\n","Sentence Nr:  1107\n","       WORD           GOLD           PRED\n","0        am  B-RAREDISEASE  B-RAREDISEASE\n","1     ##elo  I-RAREDISEASE  I-RAREDISEASE\n","2   ##blast  I-RAREDISEASE  I-RAREDISEASE\n","3     ##oma  I-RAREDISEASE  I-RAREDISEASE\n","4       can              O              O\n","5      show              O              O\n","6        up              O              O\n","7    either              O              O\n","8        in              O              O\n","9         a              O              O\n","10  regular              O              O\n","11        x              O              O\n","12        -              O              O\n","13      ray              O              O\n","14       or              O              O\n","15       in              O              O\n","16       an              O              O\n","17        m              O              O\n","18     ##ri              O              O\n","19  imaging              O              O\n","20    study              O              O\n","21        .              O              O\n","\n","Sentence Nr:  1713\n","         WORD       GOLD       PRED\n","0          in          O          O\n","1    patients          O          O\n","2        with          O          O\n","3   pulmonary  B-DISEASE  B-DISEASE\n","4          fi  I-DISEASE  I-DISEASE\n","5       ##bro  I-DISEASE  I-DISEASE\n","6       ##sis  I-DISEASE  I-DISEASE\n","7   similarly          O          O\n","8           2          O          O\n","9           -          O          O\n","10          5          O          O\n","11          %          O          O\n","12        are          O          O\n","13    thought          O          O\n","14         to          O          O\n","15         be          O          O\n","16        due          O          O\n","17         to          O          O\n","18  mutations          O          O\n","19         in          O          O\n","20         te          O          O\n","21       ##rc          O          O\n","22         or          O          O\n","23         te          O          O\n","24       ##rt          O          O\n","25          .          O          O\n","\n","Sentence Nr:  1125\n","           WORD           GOLD           PRED\n","0           the              O              O\n","1      severity              O              O\n","2           and              O              O\n","3   progression              O              O\n","4            of              O              O\n","5             s  B-RAREDISEASE  B-RAREDISEASE\n","6          ##ps  I-RAREDISEASE  I-RAREDISEASE\n","7        varies              O              O\n","8          from              O              O\n","9           one              O              O\n","10       person              O              O\n","11           to              O              O\n","12      another              O              O\n","13            .              O              O\n","\n","Sentence Nr:  975\n","       WORD    GOLD    PRED\n","0    people       O       O\n","1      with       O       O\n","2      this       O       O\n","3   disease       O       O\n","4      also       O       O\n","5        br  B-SIGN  I-SIGN\n","6    ##uise  I-SIGN  I-SIGN\n","7    easily       O  I-SIGN\n","8       and       O       O\n","9       the       O       O\n","10  bruises  B-SIGN  B-SIGN\n","11     tend       O       O\n","12       to       O  I-SIGN\n","13        l       O  I-SIGN\n","14  ##inger       O  I-SIGN\n","15        .       O       O\n","\n","Sentence Nr:  813\n","          WORD           GOLD           PRED\n","0            i  I-RAREDISEASE  B-RAREDISEASE\n","1   associated  I-RAREDISEASE  I-RAREDISEASE\n","2           my  I-RAREDISEASE  I-RAREDISEASE\n","3        ##elo  I-RAREDISEASE  I-RAREDISEASE\n","4      ##pathy  I-RAREDISEASE  I-RAREDISEASE\n","5            /  I-RAREDISEASE  I-RAREDISEASE\n","6     tropical  I-RAREDISEASE  I-RAREDISEASE\n","7          spa  I-RAREDISEASE  I-RAREDISEASE\n","8       ##stic  I-RAREDISEASE  I-RAREDISEASE\n","9         para  I-RAREDISEASE  I-RAREDISEASE\n","10       ##par  I-RAREDISEASE  I-RAREDISEASE\n","11      ##esis  I-RAREDISEASE  I-RAREDISEASE\n","12           (              O              O\n","13          ha  B-RAREDISEASE  B-RAREDISEASE\n","14         ##m  I-RAREDISEASE  I-RAREDISEASE\n","15           /  I-RAREDISEASE  I-RAREDISEASE\n","16           t  I-RAREDISEASE  I-RAREDISEASE\n","17        ##sp  I-RAREDISEASE  I-RAREDISEASE\n","18           )              O              O\n","19           .              O              O\n","\n","Sentence Nr:  1308\n","          WORD           GOLD           PRED\n","0    treatment              O              O\n","1           of              O              O\n","2            k  B-RAREDISEASE  B-RAREDISEASE\n","3         ##lu  I-RAREDISEASE  I-RAREDISEASE\n","4        ##ver  I-RAREDISEASE  I-RAREDISEASE\n","5            -  I-RAREDISEASE  I-RAREDISEASE\n","6            b  I-RAREDISEASE  I-RAREDISEASE\n","7         ##uc  I-RAREDISEASE  I-RAREDISEASE\n","8          ##y  I-RAREDISEASE  I-RAREDISEASE\n","9     syndrome  I-RAREDISEASE  I-RAREDISEASE\n","10          is              O              O\n","11  supportive              O              O\n","12         and              O              O\n","13          ps              O              O\n","14       ##ych              O              O\n","15        ##ot              O              O\n","16     ##ropic              O              O\n","17         ##s              O              O\n","18        that              O              O\n","19         may              O              O\n","20          be              O              O\n","21   effective              O              O\n","22         for              O              O\n","23        some              O              O\n","24          of              O              O\n","25         the              O              O\n","26  associated              O              O\n","27    symptoms              O              O\n","28           .              O              O\n","\n","Sentence Nr:  1763\n","        WORD           GOLD           PRED\n","0         in              O              O\n","1   addition              O              O\n","2          ,              O              O\n","3          o  B-RAREDISEASE  B-RAREDISEASE\n","4       ##cc  I-RAREDISEASE  I-RAREDISEASE\n","..       ...            ...            ...\n","70        or              O              O\n","71      near              O              O\n","72       the              O              O\n","73      ears              O              O\n","74         .              O              O\n","\n","[75 rows x 3 columns]\n","\n","Sentence Nr:  308\n","         WORD           GOLD           PRED\n","0          le  B-RAREDISEASE  B-RAREDISEASE\n","1        ##nn  I-RAREDISEASE  I-RAREDISEASE\n","2        ##ox  I-RAREDISEASE  I-RAREDISEASE\n","3           -  I-RAREDISEASE  I-RAREDISEASE\n","4         gas  I-RAREDISEASE  I-RAREDISEASE\n","5        ##ta  I-RAREDISEASE  I-RAREDISEASE\n","6        ##ut  I-RAREDISEASE  I-RAREDISEASE\n","7    syndrome  I-RAREDISEASE  I-RAREDISEASE\n","8           (              O              O\n","9           l  B-RAREDISEASE  B-RAREDISEASE\n","10       ##gs  I-RAREDISEASE  I-RAREDISEASE\n","11          )              O              O\n","12         is              O              O\n","13          a              O              O\n","14     severe              O              O\n","15       form              O              O\n","16         of              O              O\n","17          e      B-DISEASE      B-DISEASE\n","18     ##pile      I-DISEASE      I-DISEASE\n","19      ##psy      I-DISEASE      I-DISEASE\n","20       that              O              O\n","21  typically              O              O\n","22    becomes              O              O\n","23   apparent              O              O\n","24     during         I-SIGN              O\n","25    infancy         I-SIGN              O\n","26         or         I-SIGN              O\n","27      early         I-SIGN              O\n","28  childhood         I-SIGN              O\n","29          .              O              O\n","\n","Sentence Nr:  474\n","         WORD           GOLD           PRED\n","0         the              O              O\n","1       exact              O              O\n","2       cause              O              O\n","3          of              O              O\n","4          me  B-RAREDISEASE  B-RAREDISEASE\n","5        ##du  I-RAREDISEASE  I-RAREDISEASE\n","6      ##llar  I-RAREDISEASE  I-RAREDISEASE\n","7         ##y  I-RAREDISEASE  I-RAREDISEASE\n","8           s  I-RAREDISEASE  I-RAREDISEASE\n","9        ##po  I-RAREDISEASE  I-RAREDISEASE\n","10      ##nge  I-RAREDISEASE  I-RAREDISEASE\n","11     kidney  I-RAREDISEASE  I-RAREDISEASE\n","12         is              O              O\n","13        not              O              O\n","14      known              O              O\n","15        and              O              O\n","16       most              O              O\n","17      cases              O              O\n","18      occur              O              O\n","19          s              O              O\n","20  ##poradic              O              O\n","21     ##ally              O              O\n","22        for              O              O\n","23         no              O              O\n","24   apparent              O              O\n","25     reason              O              O\n","26          .              O              O\n","\n","Sentence Nr:  1300\n","        WORD GOLD PRED\n","0     during    O    O\n","1          a    O    O\n","2          s    O    O\n","3      ##chi    O    O\n","4    ##lling    O    O\n","5       test    O    O\n","6          ,    O    O\n","7        the    O    O\n","8         in    O    O\n","9     ##test    O    O\n","10    ##ines    O    O\n","11         '    O    O\n","12   ability    O    O\n","13        to    O    O\n","14    absorb    O    O\n","15   vitamin    O    O\n","16         b    O    O\n","17      ##12    O    O\n","18        is    O    O\n","19  measured    O    O\n","20         .    O    O\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lV_GbDavXyRC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625748998117,"user_tz":-120,"elapsed":11,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"6db05df1-bb1f-4e91-cc35-f6210a286b58"},"source":["if allTypes:\n","    test_labels = ['DISEASE', 'RAREDISEASE', 'SYMPTOM', 'SIGN']\n","else:\n","    test_labels = ['RAREDISEASE', 'SIGN-SYM']\n","\n","test_to_use_gold = result_examples_y_gold\n","test_to_use_pred = result_examples_y_pred\n","\n","evaluator_examples = Evaluator(test_to_use_gold, test_to_use_pred, test_labels)\n","results_examples, results_agg_examples = evaluator_examples.evaluate()\n","\n","print('## OVERALL RESULTS')\n","for item in results_examples.keys():\n","    print('\\tEvaluation Metric: ', item)\n","    print('\\t', results_examples[item])\n","print('## RESULTS AT ENTITY LEVEL')\n","for entity in results_agg_examples.keys():\n","    print('Entity: ', entity)\n","    for item in results_agg_examples[entity].keys():\n","        print('\\tEvaluation Metric: ', item)\n","        print('\\t', results_agg_examples[entity][item])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-07-08 12:56:37 root INFO: Imported 30 predictions for 30 true examples\n"],"name":"stderr"},{"output_type":"stream","text":["## OVERALL RESULTS\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 31, 'incorrect': 2, 'partial': 0, 'missed': 5, 'spurious': 9, 'possible': 38, 'actual': 42, 'precision': 0.7380952380952381, 'recall': 0.8157894736842105}\n","\tEvaluation Metric:  partial\n","\t {'correct': 29, 'incorrect': 0, 'partial': 4, 'missed': 5, 'spurious': 9, 'possible': 38, 'actual': 42, 'precision': 0.7380952380952381, 'recall': 0.8157894736842105}\n","\tEvaluation Metric:  strict\n","\t {'correct': 29, 'incorrect': 4, 'partial': 0, 'missed': 5, 'spurious': 9, 'possible': 38, 'actual': 42, 'precision': 0.6904761904761905, 'recall': 0.7631578947368421}\n","\tEvaluation Metric:  exact\n","\t {'correct': 29, 'incorrect': 4, 'partial': 0, 'missed': 5, 'spurious': 9, 'possible': 38, 'actual': 42, 'precision': 0.6904761904761905, 'recall': 0.7631578947368421}\n","## RESULTS AT ENTITY LEVEL\n","Entity:  DISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 6, 'incorrect': 1, 'partial': 0, 'missed': 1, 'spurious': 9, 'possible': 8, 'actual': 16, 'precision': 0.375, 'recall': 0.75}\n","\tEvaluation Metric:  partial\n","\t {'correct': 6, 'incorrect': 0, 'partial': 1, 'missed': 1, 'spurious': 9, 'possible': 8, 'actual': 16, 'precision': 0.40625, 'recall': 0.8125}\n","\tEvaluation Metric:  strict\n","\t {'correct': 6, 'incorrect': 1, 'partial': 0, 'missed': 1, 'spurious': 9, 'possible': 8, 'actual': 16, 'precision': 0.375, 'recall': 0.75}\n","\tEvaluation Metric:  exact\n","\t {'correct': 6, 'incorrect': 1, 'partial': 0, 'missed': 1, 'spurious': 9, 'possible': 8, 'actual': 16, 'precision': 0.375, 'recall': 0.75}\n","Entity:  RAREDISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 15, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 9, 'possible': 15, 'actual': 24, 'precision': 0.625, 'recall': 1.0}\n","\tEvaluation Metric:  partial\n","\t {'correct': 15, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 9, 'possible': 15, 'actual': 24, 'precision': 0.625, 'recall': 1.0}\n","\tEvaluation Metric:  strict\n","\t {'correct': 15, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 9, 'possible': 15, 'actual': 24, 'precision': 0.625, 'recall': 1.0}\n","\tEvaluation Metric:  exact\n","\t {'correct': 15, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 9, 'possible': 15, 'actual': 24, 'precision': 0.625, 'recall': 1.0}\n","Entity:  SYMPTOM\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 9, 'possible': 0, 'actual': 9, 'precision': 0.0, 'recall': 0}\n","\tEvaluation Metric:  partial\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 9, 'possible': 0, 'actual': 9, 'precision': 0.0, 'recall': 0}\n","\tEvaluation Metric:  strict\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 9, 'possible': 0, 'actual': 9, 'precision': 0.0, 'recall': 0}\n","\tEvaluation Metric:  exact\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 9, 'possible': 0, 'actual': 9, 'precision': 0.0, 'recall': 0}\n","Entity:  SIGN\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 10, 'incorrect': 1, 'partial': 0, 'missed': 4, 'spurious': 9, 'possible': 15, 'actual': 20, 'precision': 0.5, 'recall': 0.6666666666666666}\n","\tEvaluation Metric:  partial\n","\t {'correct': 8, 'incorrect': 0, 'partial': 3, 'missed': 4, 'spurious': 9, 'possible': 15, 'actual': 20, 'precision': 0.475, 'recall': 0.6333333333333333}\n","\tEvaluation Metric:  strict\n","\t {'correct': 8, 'incorrect': 3, 'partial': 0, 'missed': 4, 'spurious': 9, 'possible': 15, 'actual': 20, 'precision': 0.4, 'recall': 0.5333333333333333}\n","\tEvaluation Metric:  exact\n","\t {'correct': 8, 'incorrect': 3, 'partial': 0, 'missed': 4, 'spurious': 9, 'possible': 15, 'actual': 20, 'precision': 0.4, 'recall': 0.5333333333333333}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"39ZEiDXiX2xl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625748998812,"user_tz":-120,"elapsed":699,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"bec1d608-4797-4eeb-a747-529e77e0ee9f"},"source":["evaluator_all = Evaluator(true_flags, pred_flags, test_labels)\n","results_all, results_agg_all = evaluator_all.evaluate()\n","\n","print('## OVERALL RESULTS')\n","for item in results_all.keys():\n","    print('\\tEvaluation Metric: ', item)\n","    print('\\t', results_all[item])\n","print('## RESULTS AT ENTITY LEVEL')\n","for entity in results_agg_all.keys():\n","    print('Entity: ', entity)\n","    for item in results_agg_all[entity].keys():\n","        print('\\tEvaluation Metric: ', item)\n","        print('\\t', results_agg_all[entity][item])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-07-08 12:56:37 root INFO: Imported 1772 predictions for 1772 true examples\n"],"name":"stderr"},{"output_type":"stream","text":["## OVERALL RESULTS\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 2046, 'incorrect': 282, 'partial': 0, 'missed': 272, 'spurious': 383, 'possible': 2600, 'actual': 2711, 'precision': 0.7547030616008853, 'recall': 0.786923076923077}\n","\tEvaluation Metric:  partial\n","\t {'correct': 2075, 'incorrect': 0, 'partial': 253, 'missed': 272, 'spurious': 383, 'possible': 2600, 'actual': 2711, 'precision': 0.8120619697528587, 'recall': 0.8467307692307692}\n","\tEvaluation Metric:  strict\n","\t {'correct': 1833, 'incorrect': 495, 'partial': 0, 'missed': 272, 'spurious': 383, 'possible': 2600, 'actual': 2711, 'precision': 0.6761342677978606, 'recall': 0.705}\n","\tEvaluation Metric:  exact\n","\t {'correct': 2075, 'incorrect': 253, 'partial': 0, 'missed': 272, 'spurious': 383, 'possible': 2600, 'actual': 2711, 'precision': 0.765400221320546, 'recall': 0.7980769230769231}\n","## RESULTS AT ENTITY LEVEL\n","Entity:  DISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 321, 'incorrect': 105, 'partial': 0, 'missed': 33, 'spurious': 383, 'possible': 459, 'actual': 809, 'precision': 0.3967861557478368, 'recall': 0.6993464052287581}\n","\tEvaluation Metric:  partial\n","\t {'correct': 394, 'incorrect': 0, 'partial': 32, 'missed': 33, 'spurious': 383, 'possible': 459, 'actual': 809, 'precision': 0.5067985166872683, 'recall': 0.8932461873638344}\n","\tEvaluation Metric:  strict\n","\t {'correct': 300, 'incorrect': 126, 'partial': 0, 'missed': 33, 'spurious': 383, 'possible': 459, 'actual': 809, 'precision': 0.37082818294190356, 'recall': 0.6535947712418301}\n","\tEvaluation Metric:  exact\n","\t {'correct': 394, 'incorrect': 32, 'partial': 0, 'missed': 33, 'spurious': 383, 'possible': 459, 'actual': 809, 'precision': 0.48702101359703337, 'recall': 0.8583877995642701}\n","Entity:  RAREDISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 978, 'incorrect': 92, 'partial': 0, 'missed': 31, 'spurious': 383, 'possible': 1101, 'actual': 1453, 'precision': 0.6730901582931865, 'recall': 0.888283378746594}\n","\tEvaluation Metric:  partial\n","\t {'correct': 1012, 'incorrect': 0, 'partial': 58, 'missed': 31, 'spurious': 383, 'possible': 1101, 'actual': 1453, 'precision': 0.7164487267721955, 'recall': 0.9455040871934605}\n","\tEvaluation Metric:  strict\n","\t {'correct': 934, 'incorrect': 136, 'partial': 0, 'missed': 31, 'spurious': 383, 'possible': 1101, 'actual': 1453, 'precision': 0.64280798348245, 'recall': 0.8483197093551317}\n","\tEvaluation Metric:  exact\n","\t {'correct': 1012, 'incorrect': 58, 'partial': 0, 'missed': 31, 'spurious': 383, 'possible': 1101, 'actual': 1453, 'precision': 0.6964900206469373, 'recall': 0.9191643960036331}\n","Entity:  SYMPTOM\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 41, 'incorrect': 8, 'partial': 0, 'missed': 8, 'spurious': 383, 'possible': 57, 'actual': 432, 'precision': 0.09490740740740741, 'recall': 0.7192982456140351}\n","\tEvaluation Metric:  partial\n","\t {'correct': 42, 'incorrect': 0, 'partial': 7, 'missed': 8, 'spurious': 383, 'possible': 57, 'actual': 432, 'precision': 0.10532407407407407, 'recall': 0.7982456140350878}\n","\tEvaluation Metric:  strict\n","\t {'correct': 36, 'incorrect': 13, 'partial': 0, 'missed': 8, 'spurious': 383, 'possible': 57, 'actual': 432, 'precision': 0.08333333333333333, 'recall': 0.631578947368421}\n","\tEvaluation Metric:  exact\n","\t {'correct': 42, 'incorrect': 7, 'partial': 0, 'missed': 8, 'spurious': 383, 'possible': 57, 'actual': 432, 'precision': 0.09722222222222222, 'recall': 0.7368421052631579}\n","Entity:  SIGN\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 706, 'incorrect': 77, 'partial': 0, 'missed': 200, 'spurious': 383, 'possible': 983, 'actual': 1166, 'precision': 0.6054888507718696, 'recall': 0.7182095625635809}\n","\tEvaluation Metric:  partial\n","\t {'correct': 627, 'incorrect': 0, 'partial': 156, 'missed': 200, 'spurious': 383, 'possible': 983, 'actual': 1166, 'precision': 0.6046312178387651, 'recall': 0.7171922685656155}\n","\tEvaluation Metric:  strict\n","\t {'correct': 563, 'incorrect': 220, 'partial': 0, 'missed': 200, 'spurious': 383, 'possible': 983, 'actual': 1166, 'precision': 0.48284734133790735, 'recall': 0.572736520854527}\n","\tEvaluation Metric:  exact\n","\t {'correct': 627, 'incorrect': 156, 'partial': 0, 'missed': 200, 'spurious': 383, 'possible': 983, 'actual': 1166, 'precision': 0.5377358490566038, 'recall': 0.6378433367243134}\n"],"name":"stdout"}]}]}