{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Bio_ClinicalBERT_NER_NLP4RARE.ipynb","provenance":[{"file_id":"1c-fOOTd8KeU8QGKdKVyCwdfKlZjQgCF3","timestamp":1625314379253},{"file_id":"1ley57tuXXLuPfr2v6nntDKL0ggJ09cwx","timestamp":1612919533273},{"file_id":"1LCJt3fu3pW0hFe7L19Uu4MMRrW9Z9p5N","timestamp":1612543820837}],"collapsed_sections":[]},"environment":{"name":"pytorch-gpu.1-4.m55","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m55"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4f2749ac3d4843c581359bbf4ec2b0b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1fc6efda6448435aab4229c1bd6ccc83","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_914be3fc6b1744bd80848aa682055d66","IPY_MODEL_89bdd1ccbe92461c86d4298c5c0533e3"]}},"1fc6efda6448435aab4229c1bd6ccc83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"914be3fc6b1744bd80848aa682055d66":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_33b953fd3f5c4782bc280a96ca0c48ee","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":385,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":385,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8bde44031cfa4dc8a1690dbd02ba1e3c"}},"89bdd1ccbe92461c86d4298c5c0533e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d6aedeeb3d4946b68c669767e0dd7b1e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 385/385 [00:00&lt;00:00, 616B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0bfaeb922c6b4997a07d1bf54295050a"}},"33b953fd3f5c4782bc280a96ca0c48ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8bde44031cfa4dc8a1690dbd02ba1e3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d6aedeeb3d4946b68c669767e0dd7b1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0bfaeb922c6b4997a07d1bf54295050a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"12d8face70d7488b8d877a112b7d32e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_da4ab5c4bd8d401b81657af9b9b3d4f7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_de02fbb4e17c485598f2a5925aa7ad09","IPY_MODEL_9731f40dae134ed1ba85790398b9fc75"]}},"da4ab5c4bd8d401b81657af9b9b3d4f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"de02fbb4e17c485598f2a5925aa7ad09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_25da2b2eb9ac4061a74c689544a13e1f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d3a1e9752689406fa7f2399903b4b9e2"}},"9731f40dae134ed1ba85790398b9fc75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fe28f62025794688aa7a06f3e3c0646b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 213k/213k [00:01&lt;00:00, 148kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_262b4e19bdbe45fcba9d00e9547791d9"}},"25da2b2eb9ac4061a74c689544a13e1f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d3a1e9752689406fa7f2399903b4b9e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe28f62025794688aa7a06f3e3c0646b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"262b4e19bdbe45fcba9d00e9547791d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"79af1ddccb914b6c9fce79c9ecff43aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d6dfb7522a394965a209c8e4e97f585e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_728a5881ddc249d7a2a8bb304db810ff","IPY_MODEL_15569efb11a04b64acd48a74e546f2f6"]}},"d6dfb7522a394965a209c8e4e97f585e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"728a5881ddc249d7a2a8bb304db810ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fbe9860371c346f8862f652dfbe7e041","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":435778770,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435778770,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ebde14eb068d4ff89ac51bb05806d9b1"}},"15569efb11a04b64acd48a74e546f2f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b247e87744cc4feda057f39afd29230f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 436M/436M [00:09&lt;00:00, 47.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2923bd9e1c6f411bb61c94061b0efba6"}},"fbe9860371c346f8862f652dfbe7e041":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ebde14eb068d4ff89ac51bb05806d9b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b247e87744cc4feda057f39afd29230f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2923bd9e1c6f411bb61c94061b0efba6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"AcQ7f6ku4TCy"},"source":["# Bio_ClinicalBERT approach for detecting rare diseases\n","\n","This notebook contains the code to develop a Bio_ClinicalBERT model to detect rare diseases from texts, which is BERT model pre trained on a huge corpus of medical data (from there, the prefix 'Bio_Clinical').\n","\n","The Bio_ClinicalBERT model was trained on all notes from [MIMIC III](https://www.nature.com/articles/sdata201635), a database containing electronic health records from ICU patients at the Beth Israel Hospital in Boston, MA. For more details on MIMIC, see [here](https://mimic.physionet.org/). All notes from the NOTEEVENTS table were included (~880M words).\n","\n","The Bio_ClinicalBERT model was trained using code from [Google's BERT repository](https://github.com/google-research/bert) on a GeForce GTX TITAN X 12 GB GPU. Model parameters were initialized with BioBERT (BioBERT-Base v1.0 + PubMed 200K + PMC 270K).\n","\n","To accomplish this, we will use some tools developed in the [transformers](https://huggingface.co/transformers/index.html) library, which is a library that recopiles some of the State-of-the-art Natural Language Processing for Pytorch and TensorFlow.\n","\n","To make use of the pre-trained model with the hugging face `transformers` library, we need the model's weights to be in a form which pyTorch understands. The original model was trained using tensorflow so we need to convert the weights into pyTorch weights. We can then import and use it."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E-awiIaFW2Nc","executionInfo":{"status":"ok","timestamp":1625761622164,"user_tz":-120,"elapsed":18361,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"18211107-a438-440e-dc28-33b4ca4bd5a5"},"source":["if 'google.colab' in str(get_ipython()):\n","    print('Running on CoLab')\n","    from google.colab import drive\n","    #drive.flush_and_unmount()\n","    drive.mount('/content/drive')\n","    root = '/content/drive/My Drive/Colab Notebooks'\n","else:\n","    print('Not running on CoLab')\n","    root = './'\n","\n","print(\"Current directory: {}\".format(root))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running on CoLab\n","Mounted at /content/drive\n","Current directory: /content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XLKP1xZe17qh"},"source":["## 1. Getting the resources\n","\n","First of all, we will download the model from github repo of [Bio_ClinicalBert](https://github.com/EmilyAlsentzer/clinicalBERT).\n","\n","After that, we will install the needed packages."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eiDJciIUZ1fg","executionInfo":{"status":"ok","timestamp":1625761642301,"user_tz":-120,"elapsed":20141,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"97716f42-32c9-4839-88d3-eb577047fdd5"},"source":["!pip install pytorch_transformers\n","!pip install transformers\n","!pip install seqeval\n","!pip install sklearn-crfsuite"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pytorch_transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n","\u001b[K     |████████████████████████████████| 184kB 7.8MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 31.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.41.1)\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/8a/bfe42e25206da14a311a76798248def9d0f5815bb5651fa4090af7fc4683/boto3-1.17.107-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 51.7MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 49.2MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.9.0+cu102)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n","Collecting botocore<1.21.0,>=1.20.107\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/85/b2e0366a63f4f0aedd4cca8b7bf8b2d6e6adc0f3d72435aa5174d0ec80e2/botocore-1.20.107-py2.py3-none-any.whl (7.7MB)\n","\u001b[K     |████████████████████████████████| 7.7MB 49.1MB/s \n","\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n","\u001b[K     |████████████████████████████████| 81kB 12.7MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.107->boto3->pytorch_transformers) (2.8.1)\n","\u001b[31mERROR: botocore 1.20.107 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: sacremoses, jmespath, botocore, s3transfer, boto3, sentencepiece, pytorch-transformers\n","Successfully installed boto3-1.17.107 botocore-1.20.107 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.4.2 sacremoses-0.0.45 sentencepiece-0.1.96\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 7.2MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 43.4MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting huggingface-hub==0.0.12\n","  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.12 tokenizers-0.10.3 transformers-4.8.2\n","Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 4.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16184 sha256=760903c095388289b9dfe4c6444cb908c6132a6380e28a806dacd46bb164cc19\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Collecting sklearn-crfsuite\n","  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n","Collecting python-crfsuite>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n","\u001b[K     |████████████████████████████████| 747kB 10.2MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (1.15.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.8.9)\n","Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (4.41.1)\n","Installing collected packages: python-crfsuite, sklearn-crfsuite\n","Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ULc2U_O924aK"},"source":["The pretrained `Bio_ClinicalBERT` model can be obtained both from a direct download [here](https://www.dropbox.com/s/8armk04fu16algz/pretrained_bert_tf.tar.gz?dl=0) or loading it directly from the `transformers library`, which is the way used in this notebook."]},{"cell_type":"markdown","metadata":{"id":"3SWmvzdm3D7a"},"source":["## 2. Data loading and first insights\n","\n","In this step we will download the data and define all of the main paths that our model includes.\n","\n","It is also possible to select the desired language (`en` for english and `es` for spanish) and whether to consider all the entities from the model or not (`allTypes` variable)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ytuVTGvFameo","executionInfo":{"status":"ok","timestamp":1625761642302,"user_tz":-120,"elapsed":8,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"c4692c81-02c2-4f73-d722-ff34a468c23d"},"source":["LANG = 'en'  #This system will also process texts written in Spanish, LANG='es'\n","allTypes = True\n","sTypes = ''\n","if allTypes:\n","    sTypes = '_all'\n","\n","#path_data=root+'data/{}/'.format(LANG) #folder where you can find the datasets\n","path_data = root + '/ner/data/gold_nlp4rare_corpus/' #folder where you can find the datasets\n","path_models = root + '/ner/models/{}/'.format(LANG) #folder to save the models\n","checkpoints = root + '/ner/checkpoints/'\n","path_scores = root + '/ner/scores/{}/'.format(LANG) #folder to save the scores\n","path_outputs = root + '/ner/outputs/{}/'.format(LANG) #folder to save the scores\n","\n","print('Datasets:',path_data)\n","print('Path to save this model:',path_models)\n","print('Path for checkpoints:',checkpoints)\n","print('Path to save the scores:',path_scores)\n","print('Path to save the outputs:',path_outputs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Datasets: /content/drive/My Drive/Colab Notebooks/ner/data/gold_nlp4rare_corpus/\n","Path to save this model: /content/drive/My Drive/Colab Notebooks/ner/models/en/\n","Path for checkpoints: /content/drive/My Drive/Colab Notebooks/ner/checkpoints/\n","Path to save the scores: /content/drive/My Drive/Colab Notebooks/ner/scores/en/\n","Path to save the outputs: /content/drive/My Drive/Colab Notebooks/ner/outputs/en/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBUx_tlSbcGu","executionInfo":{"status":"ok","timestamp":1625761645040,"user_tz":-120,"elapsed":2743,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"212772be-522a-442d-c42c-1384e8464bee"},"source":["import pandas as pd\n","\n","df_train = pd.read_csv(path_data+'train{}.csv'.format(sTypes),index_col=0)\n","print('size of the training dataset: {}'.format(len(df_train)))\n","df_dev = pd.read_csv(path_data+'dev{}.csv'.format(sTypes),index_col=0)\n","print('size of the development dataset: {}'.format(len(df_dev)))\n","df_test = pd.read_csv(path_data+'test{}.csv'.format(sTypes),index_col=0)\n","print('size of the test dataset: {}'.format(len(df_test)))\n","print('datasets loaded!\\n')\n","\n","#number of labels (IOB tags)\n","tags = df_train['Tag'].unique()\n","num_tags = df_train['Tag'].nunique()\n","print('Labels: {}'.format(tags))\n","print('Nr of labels: {}'.format(num_tags))\n","\n","# Overall statistics for the number of words in each text\n","count_df_train = df_train.groupby('Sentence #').count()\n","statistics_train = count_df_train['Word'].describe()\n","print('\\nSome statistics of the sentences in the training dataset:')\n","print(statistics_train)\n","\n","count_df_dev = df_dev.groupby('Sentence #').count()\n","statistics_dev = count_df_dev['Word'].describe()\n","print('\\nSome statistics of the sentences in the development dataset:')\n","print(statistics_dev)\n","\n","#The lenth of the longest sentence. Lenght is the number of words.\n","MAX_LEN_TRAIN = int(statistics_train['max'])\n","MAX_LEN_DEV = int(statistics_dev['max'])\n","MAX_LEN = max(MAX_LEN_TRAIN, MAX_LEN_DEV)\n","print('\\n')\n","print('The maximum length of sentences in TRAIN is: ', MAX_LEN_TRAIN)\n","print('The maximum length of sentences in DEV is: ', MAX_LEN_DEV)\n","print('The maximum length of sentences in TOTAL is:', MAX_LEN)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["size of the training dataset: 135656\n","size of the development dataset: 18492\n","size of the test dataset: 37837\n","datasets loaded!\n","\n","Labels: ['O' 'B-RAREDISEASE' 'I-RAREDISEASE' 'B-DISEASE' 'I-DISEASE' 'B-SIGN'\n"," 'I-SIGN' 'B-SYMPTOM' 'I-SYMPTOM']\n","Nr of labels: 9\n","\n","Some statistics of the sentences in the training dataset:\n","count    6451.000000\n","mean       21.028678\n","std        10.653876\n","min         1.000000\n","25%        13.000000\n","50%        19.000000\n","75%        26.000000\n","max        90.000000\n","Name: Word, dtype: float64\n","\n","Some statistics of the sentences in the development dataset:\n","count    903.000000\n","mean      20.478405\n","std       10.105284\n","min        1.000000\n","25%       13.000000\n","50%       18.000000\n","75%       25.000000\n","max       71.000000\n","Name: Word, dtype: float64\n","\n","\n","The maximum length of sentences in TRAIN is:  90\n","The maximum length of sentences in DEV is:  71\n","The maximum length of sentences in TOTAL is: 90\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ltOsBqAv4N_r"},"source":["We visualize next the distribution of each of the datasets according to its entities."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLdpET-UblbE","executionInfo":{"status":"ok","timestamp":1625761645040,"user_tz":-120,"elapsed":5,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"0f28274c-9206-438c-f79f-8d2fe4a0c97f"},"source":["separator = '*'*60\n","# Tag statistics train df\n","print('TRAIN:\\n', df_train['Tag'].value_counts(), sep='\\n', end='\\n')\n","print()\n","print('Percentages:', df_train['Tag'].value_counts(normalize=True)*100, sep='\\n', end='\\n')\n","\n","# Tag statistics dev df\n","print('', separator, '', sep='\\n')\n","print('DEV:\\n', df_dev['Tag'].value_counts(), sep='\\n', end='\\n')\n","print()\n","print('Percentages:', df_dev['Tag'].value_counts(normalize=True)*100, sep='\\n', end='\\n')\n","\n","# Tag statistics test df\n","print('', separator, '', sep='\\n')\n","print('TEST:\\n', df_test['Tag'].value_counts(), sep='\\n', end='\\n')\n","print()\n","print('Percentages:', df_test['Tag'].value_counts(normalize=True)*100, sep='\\n', end='\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TRAIN:\n","\n","O                113555\n","I-SIGN             7584\n","I-RAREDISEASE      4116\n","B-RAREDISEASE      3555\n","B-SIGN             2914\n","I-DISEASE          1735\n","B-DISEASE          1596\n","I-SYMPTOM           304\n","B-SYMPTOM           297\n","Name: Tag, dtype: int64\n","\n","Percentages:\n","O                83.708056\n","I-SIGN            5.590612\n","I-RAREDISEASE     3.034145\n","B-RAREDISEASE     2.620599\n","B-SIGN            2.148080\n","I-DISEASE         1.278970\n","B-DISEASE         1.176505\n","I-SYMPTOM         0.224096\n","B-SYMPTOM         0.218936\n","Name: Tag, dtype: float64\n","\n","************************************************************\n","\n","DEV:\n","\n","O                15131\n","I-SIGN            1337\n","I-RAREDISEASE      626\n","B-RAREDISEASE      513\n","B-SIGN             405\n","I-DISEASE          224\n","B-DISEASE          218\n","I-SYMPTOM           20\n","B-SYMPTOM           18\n","Name: Tag, dtype: int64\n","\n","Percentages:\n","O                81.824573\n","I-SIGN            7.230154\n","I-RAREDISEASE     3.385248\n","B-RAREDISEASE     2.774173\n","B-SIGN            2.190136\n","I-DISEASE         1.211335\n","B-DISEASE         1.178888\n","I-SYMPTOM         0.108155\n","B-SYMPTOM         0.097339\n","Name: Tag, dtype: float64\n","\n","************************************************************\n","\n","TEST:\n","\n","O                31594\n","I-SIGN            2215\n","I-RAREDISEASE     1179\n","B-RAREDISEASE     1073\n","B-SIGN             803\n","B-DISEASE          443\n","I-DISEASE          400\n","I-SYMPTOM           80\n","B-SYMPTOM           50\n","Name: Tag, dtype: int64\n","\n","Percentages:\n","O                83.500278\n","I-SIGN            5.854058\n","I-RAREDISEASE     3.115998\n","B-RAREDISEASE     2.835849\n","B-SIGN            2.122261\n","B-DISEASE         1.170812\n","I-DISEASE         1.057166\n","I-SYMPTOM         0.211433\n","B-SYMPTOM         0.132146\n","Name: Tag, dtype: float64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D30_dqal47wo"},"source":["## 3. Imports and pre-processing of the data\n","\n","First, all the steps to import the necessary packages to use the model are defined. After that, the pre processing of the data is necessary as the `Bert` model need to meet some special requirements."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"id":"wNJcYiT0eXbV","executionInfo":{"status":"ok","timestamp":1625761654392,"user_tz":-120,"elapsed":9355,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"d5e84f50-0e86-4a12-e02a-69b8aa6c18bb"},"source":["#importing a few necessary packages and setting the DATA directory\n","DATA_DIR=\".\"\n","import os\n","import numpy as np\n","import pickle\n","import tensorflow as tf\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","# install BERT\n","!pip install pytorch_pretrained_bert pytorch-nlp\n","\n","# BERT imports\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","# from pytorch_pretrained_bert import BertTokenizer, BertConfig, BertForSequenceClassification\n","from pytorch_pretrained_bert import BertAdam\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","# specify GPU device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pytorch_pretrained_bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 7.7MB/s \n","\u001b[?25hCollecting pytorch-nlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n","\u001b[K     |████████████████████████████████| 92kB 7.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.17.107)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.9.0+cu102)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n","Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.4.2)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n","Requirement already satisfied: botocore<1.21.0,>=1.20.107 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.20.107)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2021.5.30)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.107->boto3->pytorch_pretrained_bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.107->boto3->pytorch_pretrained_bert) (1.15.0)\n","Installing collected packages: pytorch-pretrained-bert, pytorch-nlp\n","Successfully installed pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla T4'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"epO0H4UI5awo"},"source":["The model does not process text, so we need to transform all the pre-defined entities (labels) to a language that can be interpreted by the model, i.e., numbers.\n","\n","To do that, we create a dictionary with the desired labels following the IOB scheme."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AD4URCopex4w","executionInfo":{"status":"ok","timestamp":1625761654393,"user_tz":-120,"elapsed":5,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"4a23dc08-87ee-4b77-d7f6-fcf6ae370971"},"source":["# We have to create a dictionary for the labels (IOB labels):\n","# label is key and value is index.\n","tag_index = {t : i + 1 for i, t in enumerate(tags)}\n","#we have to add a new label for pad tokens\n","tag_index[\"PAD\"] = 0\n","\n","print('Dictionary for labels:', tag_index)\n","print('Number of tags added the tag for pad tokens:', len(tag_index))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dictionary for labels: {'O': 1, 'B-RAREDISEASE': 2, 'I-RAREDISEASE': 3, 'B-DISEASE': 4, 'I-DISEASE': 5, 'B-SIGN': 6, 'I-SIGN': 7, 'B-SYMPTOM': 8, 'I-SYMPTOM': 9, 'PAD': 0}\n","Number of tags added the tag for pad tokens: 10\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DL-1sfr-58qn"},"source":["Next, we perform the first step of preprocessing of the data. Here, a class `SentenceGetter` in combination to a function `vectorization` are defined to extract the desired features from the input data."]},{"cell_type":"code","metadata":{"id":"YIUm7FCEgfFK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625761655368,"user_tz":-120,"elapsed":978,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"9a01148d-412e-484b-ce04-15cb090f8cb0"},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","class SentenceGetter(object):\n","    \"\"\"This is a class to get sentence. Each sentence will be a list of tuples with its words, tag and pos.\"\"\"\n","    def __init__(self, df):\n","        self.n_sent = 1\n","        self.df = df\n","        self.empty = False\n","        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n","                                                       s['POS'].values.tolist(),\n","                                                       s['Tag'].values.tolist())]\n","        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n","        self.sentences = [s for s in self.grouped]\n","        \n","    def get_text(self):\n","        try:\n","            #s = self.grouped['Sentence: {}'.format(self.n_sent)]\n","            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n","            self.n_sent +=1\n","            return s\n","        except:\n","            return None\n","\n","def vectorization(df, tag_index):\n","    \"\"\"This functions gets the dataframe with the dataset and transform it to vectors. \n","    First, its sentences are retrieved. Then, for each sentence, the function creates a list\n","    with its corresponding indexes. In addition to X (which are the sentences transformed to vectors),\n","    the functions also returns the corresponding labels for each token\"\"\"\n","    \n","    df = df[['Sentence #','Word','POS','Tag']]\n","    \n","    # Getting full sentences\n","    getter = SentenceGetter(df)\n","    sentences = getter.sentences\n","\n","    X = [[w[0] for w in s] for s in sentences]\n","\n","    # Convert label to index\n","    y = [[tag_index[w[2]] for w in s] for s in sentences]\n","    \n","    return (X, y)\n","\n","# vectorization of datasets\n","sentences_train, labels_train = vectorization(df_train, tag_index)\n","sentences_dev, labels_dev = vectorization(df_dev, tag_index)\n","sentences_test, labels_test = vectorization(df_test, tag_index)\n","print('Datasets loaded!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Datasets loaded!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NK85yt-p64ft"},"source":["Same as for the labels, all of the retrieved words for each sentence is necessary to be converted to numbers to use them in the model. For that, we use the tokenization of the Bert model.\n","\n","Afterwards, we also load the model to use as the architecture."]},{"cell_type":"code","metadata":{"id":"XVFBcuyehFFD","colab":{"base_uri":"https://localhost:8080/","height":280,"referenced_widgets":["4f2749ac3d4843c581359bbf4ec2b0b5","1fc6efda6448435aab4229c1bd6ccc83","914be3fc6b1744bd80848aa682055d66","89bdd1ccbe92461c86d4298c5c0533e3","33b953fd3f5c4782bc280a96ca0c48ee","8bde44031cfa4dc8a1690dbd02ba1e3c","d6aedeeb3d4946b68c669767e0dd7b1e","0bfaeb922c6b4997a07d1bf54295050a","12d8face70d7488b8d877a112b7d32e0","da4ab5c4bd8d401b81657af9b9b3d4f7","de02fbb4e17c485598f2a5925aa7ad09","9731f40dae134ed1ba85790398b9fc75","25da2b2eb9ac4061a74c689544a13e1f","d3a1e9752689406fa7f2399903b4b9e2","fe28f62025794688aa7a06f3e3c0646b","262b4e19bdbe45fcba9d00e9547791d9","79af1ddccb914b6c9fce79c9ecff43aa","d6dfb7522a394965a209c8e4e97f585e","728a5881ddc249d7a2a8bb304db810ff","15569efb11a04b64acd48a74e546f2f6","fbe9860371c346f8862f652dfbe7e041","ebde14eb068d4ff89ac51bb05806d9b1","b247e87744cc4feda057f39afd29230f","2923bd9e1c6f411bb61c94061b0efba6"]},"executionInfo":{"status":"ok","timestamp":1625761669677,"user_tz":-120,"elapsed":14311,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"3b82038a-d4e3-4891-85c1-99e338c8d7f1"},"source":["from transformers import AutoTokenizer, AutoModelForTokenClassification\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", do_lower_case=True)\n","model = AutoModelForTokenClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", num_labels=num_tags+1)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f2749ac3d4843c581359bbf4ec2b0b5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12d8face70d7488b8d877a112b7d32e0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79af1ddccb914b6c9fce79c9ecff43aa","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435778770.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"-1977pMY7N60"},"source":["Here, an example of tokenization is provided to check how this process works.\n","\n","Through this example, we can see how the original sentence is transformed to new subwords or 'tokens', and after that the tokenizer assign them a number according to its internal vocabulary. \n","\n","As new subwords are created, the original lenght of the sentence is modified. Then, the original labels are no longer valid, and a new processing of the labels is necessary to correct this disalignment between words and labels."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GHEDBh2dvR5u","executionInfo":{"status":"ok","timestamp":1625761669679,"user_tz":-120,"elapsed":9,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"b9cac200-b58e-4684-d5a6-6163da2e6132"},"source":["# Example of BERT tokenization\n","selected_index = np.random.randint(1, 6461)\n","# selected_index = 344\n","# selected_index = 4\n","selected_sentence = sentences_train[selected_index]\n","tokenized_input = tokenizer(selected_sentence, is_split_into_words=True, add_special_tokens=False)\n","tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n","print(\"Sentence used: {}\\nOriginal sentence:\\n\\t{}\".format(selected_index, selected_sentence))\n","print(\"Tokenization of the sentence:\\n\\t{}\".format(tokens))\n","print('Tokenized ids for the sentence:\\n\\t{}'.format(tokenized_input[\"input_ids\"]))\n","print(\"Length:\\n\\tOriginal sentence: {}\\n\\tTokenized sentence: {}\\n\\tTokenized ids: {}\".format(len(selected_sentence), len(tokens), len(tokenized_input[\"input_ids\"])))\n","\n","# Example label alignment after BERT tokenization\n","selected_original_labels = labels_train[selected_index]\n","\n","print('')\n","print('Original labels:\\n\\t{}'.format(selected_original_labels))\n","\n","word_ids = []\n","index = 0\n","current_word = ''\n","for token in tokens:\n","    if token.startswith(\"##\"):\n","        word_ids.append(index-1)\n","    elif token in current_word:\n","        if len(tokenizer.tokenize(current_word)) != 1:\n","            subtokens_qty = len(tokenizer.tokenize(current_word))\n","            for subtoken in tokenizer.tokenize(current_word):\n","                if token == subtoken:\n","                    word_ids.append(index-1)\n","                    break\n","                subtokens_qty -= 1\n","                if subtokens_qty == 0:\n","                    word_ids.append(index)\n","                    current_word = selected_sentence[index].lower()\n","                    index += 1\n","        else:\n","            word_ids.append(index)\n","            current_word = selected_sentence[index].lower()\n","            index += 1\n","    else:\n","        word_ids.append(index)\n","        current_word = selected_sentence[index].lower()\n","        index += 1\n","\n","print('New assigned word_ids:\\n\\t{}'.format(word_ids))\n","\n","aligned_labels = []\n","old_index = -1\n","\n","if allTypes:\n","    for i in word_ids:\n","        if (i == old_index) and ( (selected_original_labels[i] == 2) or (selected_original_labels[i] == 4) or (selected_original_labels[i] == 6) or (selected_original_labels[i] == 8) ):\n","            aligned_labels.append(selected_original_labels[i]+1)\n","        else:\n","            aligned_labels.append(selected_original_labels[i])\n","        old_index = i\n","else:\n","    for i in word_ids:\n","        if (i == old_index) and ( (selected_original_labels[i] == 2) or (selected_original_labels[i] == 4) ):\n","            aligned_labels.append(selected_original_labels[i]+1)\n","        else:\n","            aligned_labels.append(selected_original_labels[i])\n","        old_index = i\n","\n","# print('')\n","# print('Original labels:\\n\\t{}'.format(selected_original_labels))\n","# print('New assigned word_ids:\\n\\t{}'.format(word_ids))\n","print('New label alignment:\\n\\t{}'.format(aligned_labels))\n","print(\"Length:\\n\\tOriginal labels: {}\\n\\tNew assigned word_ids: {}\\n\\tNew label alignment: {}\".format(len(selected_original_labels), len(word_ids), len(aligned_labels)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sentence used: 4689\n","Original sentence:\n","\t['The', 'onset', 'of', 'impaired', 'brain', 'function', 'is', 'rapid', '(', 'acute', ')', ',', 'while', 'other', 'times', 'it', 'can', 'develop', 'slowly', 'over', 'many', 'years', '.']\n","Tokenization of the sentence:\n","\t['the', 'onset', 'of', 'impaired', 'brain', 'function', 'is', 'rapid', '(', 'acute', ')', ',', 'while', 'other', 'times', 'it', 'can', 'develop', 'slowly', 'over', 'many', 'years', '.']\n","Tokenized ids for the sentence:\n","\t[1103, 15415, 1104, 20606, 3575, 3053, 1110, 6099, 113, 12104, 114, 117, 1229, 1168, 1551, 1122, 1169, 3689, 2494, 1166, 1242, 1201, 119]\n","Length:\n","\tOriginal sentence: 23\n","\tTokenized sentence: 23\n","\tTokenized ids: 23\n","\n","Original labels:\n","\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","New assigned word_ids:\n","\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n","New label alignment:\n","\t[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","Length:\n","\tOriginal labels: 23\n","\tNew assigned word_ids: 23\n","\tNew label alignment: 23\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueA3oqQ-VoLL","executionInfo":{"status":"ok","timestamp":1625761669680,"user_tz":-120,"elapsed":8,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"34642afe-d06a-48e7-da69-406ac74f9053"},"source":["# print(tokenizer.tokenize('1%-2'))\n","# print(tokenizer.tokenize('and'))\n","# print(tokenizer.tokenize('NMOSD'))\n","subtoken_to_analyze = '2'\n","strings = ['1%-2', 'and', 'with', 'NMOSD', '2,000', ',', '2-2', '222', '24-hour']\n","\n","for string in strings: \n","    print('[', string, ']')\n","    if len(tokenizer.tokenize(string)) != 1:\n","        print('\\t({})'.format(tokenizer.tokenize(string)))\n","        print('\\tnot unique word')\n","        subtokens_qty = len(tokenizer.tokenize(string))\n","        for subtoken in tokenizer.tokenize(string):\n","            if subtoken_to_analyze.lower() == subtoken:\n","                print('------> <{}> belongs to last word'.format(subtoken_to_analyze))\n","                break\n","            subtokens_qty -= 1\n","            if subtokens_qty == 0:\n","                print('------> <{}> does NOT belong to last word'.format(subtoken_to_analyze))\n","    else:\n","        print('\\tunique word')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ 1%-2 ]\n","\t(['1', '%', '-', '2'])\n","\tnot unique word\n","------> <2> belongs to last word\n","[ and ]\n","\tunique word\n","[ with ]\n","\tunique word\n","[ NMOSD ]\n","\t(['nm', '##os', '##d'])\n","\tnot unique word\n","------> <2> does NOT belong to last word\n","[ 2,000 ]\n","\t(['2', ',', '000'])\n","\tnot unique word\n","------> <2> belongs to last word\n","[ , ]\n","\tunique word\n","[ 2-2 ]\n","\t(['2', '-', '2'])\n","\tnot unique word\n","------> <2> belongs to last word\n","[ 222 ]\n","\tunique word\n","[ 24-hour ]\n","\t(['24', '-', 'hour'])\n","\tnot unique word\n","------> <2> does NOT belong to last word\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y3P5E_Gz8H2o"},"source":["After the example, we proceed with the same operation to the full datasets."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_MoZWkQ1mGmE","executionInfo":{"status":"ok","timestamp":1625761838834,"user_tz":-120,"elapsed":168819,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"ecc16d9b-d8ac-42c7-f33f-d125a22503d5"},"source":["def align_labels(original_sentences, original_labels, MAX_LEN):\n","    \"\"\"\n","    This function assign the new labels following the original input and according to\n","    the results from the Tokenization to create a good alignment between words/subwords\n","    and labels.\n","    Besides this, it provides the new maximum lenght of the sentences after the Tokenization\n","    for future padding purposes.\n","    \"\"\"\n","    tokenized_input = tokenizer(original_sentences, is_split_into_words=True, add_special_tokens=False)\n","    tokens = [tokenizer.convert_ids_to_tokens(t) for t in tokenized_input[\"input_ids\"]]\n","    list_len = [len(i) for i in tokens]\n","    MAX_LEN = max(max(list_len), MAX_LEN) \n","\n","    word_ids_global = []\n","    for nr_sentence, list_tokens in enumerate(tokens):\n","        word_ids = []\n","        index = 0\n","        current_word = ''\n","        for token in list_tokens:\n","            if token.startswith(\"##\"):\n","                word_ids.append(index-1)\n","            elif token in current_word:\n","                if len(tokenizer.tokenize(current_word)) != 1:\n","                    subtokens_qty = len(tokenizer.tokenize(current_word))\n","                    for subtoken in tokenizer.tokenize(current_word):\n","                        if token == subtoken:\n","                            word_ids.append(index-1)\n","                            break\n","                        subtokens_qty -= 1\n","                        if subtokens_qty == 0:\n","                            word_ids.append(index)\n","                            current_word = original_sentences[nr_sentence][index].lower()\n","                            index += 1\n","                else:\n","                    word_ids.append(index)\n","                    current_word = original_sentences[nr_sentence][index].lower()\n","                    index += 1\n","            else:\n","                word_ids.append(index)\n","                current_word = original_sentences[nr_sentence][index].lower()\n","                index += 1\n","        word_ids_global.append(word_ids)\n","\n","    aligned_global = []\n","    for nr_sentence, list_word_ids in enumerate(word_ids_global):\n","        aligned_labels = []\n","        old_index = -1\n","        if allTypes:\n","            for i in list_word_ids:\n","                if (i == old_index) and ( (original_labels[nr_sentence][i] == 2) or (original_labels[nr_sentence][i] == 4) or (original_labels[nr_sentence][i] == 6) or (original_labels[nr_sentence][i] == 8) ):\n","                    aligned_labels.append(original_labels[nr_sentence][i]+1)\n","                else:\n","                    aligned_labels.append(original_labels[nr_sentence][i])\n","                old_index = i\n","        else:\n","            for i in list_word_ids:\n","                if (i == old_index) and ( (original_labels[nr_sentence][i] == 2) or (original_labels[nr_sentence][i] == 4) ):\n","                    aligned_labels.append(original_labels[nr_sentence][i]+1)\n","                else:\n","                    aligned_labels.append(original_labels[nr_sentence][i])\n","                old_index = i\n","        aligned_global.append(aligned_labels)\n","\n","    return MAX_LEN, aligned_global\n","\n","print('Aligning labels...')\n","train_max_len, aligned_labels_train = align_labels(sentences_train, labels_train, MAX_LEN)\n","dev_max_len, aligned_labels_dev = align_labels(sentences_dev, labels_dev, MAX_LEN)\n","test_max_len, aligned_labels_test = align_labels(sentences_test, labels_test, MAX_LEN)\n","print('Labels aligned!')\n","CORRECTED_MAX_LEN = max(train_max_len, dev_max_len)\n","print('New defined MAX_LEN after tokenization is: ', CORRECTED_MAX_LEN)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Aligning labels...\n","Labels aligned!\n","New defined MAX_LEN after tokenization is:  120\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NZrwapYI85Bt"},"source":["The pre-processing of the data is finished with the padding of the new labels to the maximum lenght and the tokenization of the words."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7BvTz40BSMeJ","executionInfo":{"status":"ok","timestamp":1625761840232,"user_tz":-120,"elapsed":1402,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"652eedad-caca-4775-8b8b-8ae293a208c2"},"source":["# Padding labels according to corrected MAX_LEN\n","final_train_labels = pad_sequences(maxlen=CORRECTED_MAX_LEN, sequences=aligned_labels_train, padding=\"post\", value=tag_index[\"PAD\"]).tolist()\n","final_dev_labels = pad_sequences(maxlen=CORRECTED_MAX_LEN, sequences=aligned_labels_dev, padding=\"post\", value=tag_index[\"PAD\"]).tolist()\n","final_test_labels = pad_sequences(maxlen=CORRECTED_MAX_LEN, sequences=aligned_labels_test, padding=\"post\", value=tag_index[\"PAD\"]).tolist()\n","print('Labels padded')\n","\n","# Tokenize inputs according to corrected MAX_LEN\n","# train dataset\n","tokenized_input_train = tokenizer(sentences_train, truncation=True, max_length=CORRECTED_MAX_LEN, padding='max_length', is_split_into_words=True, add_special_tokens=False)\n","print('\\nTrain dataset:\\n\\tsentences lenght: {}.\\n\\tlabels lenght: {}.\\n\\tinput_ids length: {}.'.format(len(sentences_train), len(labels_train), len(tokenized_input_train['input_ids'])))\n","\n","# dev dataset\n","tokenized_input_dev = tokenizer(sentences_dev, truncation=True, max_length=CORRECTED_MAX_LEN, padding='max_length', is_split_into_words=True, add_special_tokens=False)\n","print('\\nDev dataset:\\n\\tsentences lenght: {}.\\n\\tlabels lenght: {}.\\n\\tinput_ids length: {}.'.format(len(sentences_dev), len(labels_dev), len(tokenized_input_dev['input_ids'])))\n","\n","# test dataset\n","tokenized_input_test = tokenizer(sentences_test, truncation=True, max_length=CORRECTED_MAX_LEN, padding='max_length', is_split_into_words=True, add_special_tokens=False)\n","print('\\nTest dataset:\\n\\tsentences lenght: {}.\\n\\tlabels lenght: {}.\\n\\tinput_ids length: {}.'.format(len(sentences_test), len(labels_test), len(tokenized_input_test['input_ids'])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Labels padded\n","\n","Train dataset:\n","\tsentences lenght: 6451.\n","\tlabels lenght: 6451.\n","\tinput_ids length: 6451.\n","\n","Dev dataset:\n","\tsentences lenght: 903.\n","\tlabels lenght: 903.\n","\tinput_ids length: 903.\n","\n","Test dataset:\n","\tsentences lenght: 1772.\n","\tlabels lenght: 1772.\n","\tinput_ids length: 1772.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GWN1XXZa9Fuj"},"source":["We now extract one example from the processed data to check the dimensions and alignment among all of the inputs."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9WxrBL85iDjQ","executionInfo":{"status":"ok","timestamp":1625761840233,"user_tz":-120,"elapsed":4,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"2ca2417f-d743-4844-d2f4-7243e823e7e3"},"source":["# Checking all is right\n","print(tokenized_input_dev.keys())\n","print(tokenized_input_dev['input_ids'][0])\n","print(tokenized_input_dev['attention_mask'][0])\n","print(final_dev_labels[0])\n","print('Length inputs: {}.\\nLength masks: {}.\\nLength labels: {}.'.format(len(tokenized_input_dev['input_ids'][0]), len(tokenized_input_dev['attention_mask'][0]), len(final_dev_labels[0])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n","[5855, 2552, 9318, 113, 172, 1279, 114, 1110, 170, 4054, 22572, 16071, 22354, 7435, 8936, 1115, 1336, 1129, 10238, 1120, 3485, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[2, 3, 3, 1, 2, 3, 1, 1, 1, 1, 4, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Length inputs: 120.\n","Length masks: 120.\n","Length labels: 120.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u2bbyah39e_t"},"source":["## 4. Definition of the model\n","\n","For reproducibility reasons, we fix a seed for PyTorch and convert all the data into tensors as the model requires."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XwA5hL_tj7zj","executionInfo":{"status":"ok","timestamp":1625761840629,"user_tz":-120,"elapsed":398,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"5e397578-87d7-4ff2-81e7-30804d181818"},"source":["import torch\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","np.random.seed(42)\n","torch.backends.cudnn.deterministic=True\n","batch_size = 32 # 64\n","\n","# Convert all of our data into torch tensors, the required datatype for our model\n","train_inputs = torch.tensor(tokenized_input_train[\"input_ids\"])\n","train_masks = torch.tensor(tokenized_input_train[\"attention_mask\"])\n","train_labels = torch.tensor(final_train_labels)\n","\n","validation_inputs = torch.tensor(tokenized_input_dev[\"input_ids\"])\n","validation_masks = torch.tensor(tokenized_input_dev[\"attention_mask\"])\n","validation_labels = torch.tensor(final_dev_labels)\n","\n","test_inputs = torch.tensor(tokenized_input_test[\"input_ids\"])\n","test_masks = torch.tensor(tokenized_input_test[\"attention_mask\"])\n","test_labels = torch.tensor(final_test_labels)\n","\n","# Checking outputs\n","print('Train tensor shapes:')\n","print('Inputs: ', train_inputs.shape)\n","print('Masks: ', train_masks.shape)\n","print('Labels: ', train_labels.shape)\n","print('\\nValidation tensor shapes:')\n","print('Inputs: ', validation_inputs.shape)\n","print('Masks: ', validation_masks.shape)\n","print('Labels: ', validation_labels.shape)\n","print('\\nTest tensor shapes:')\n","print('Inputs: ', test_inputs.shape)\n","print('Masks: ', test_masks.shape)\n","print('Labels: ', test_labels.shape)\n","\n","# Create an iterator of our data with torch DataLoader \n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","shuffled_train_data = torch.utils.data.Subset(train_data, torch.randperm(len(train_data)).tolist())\n","train_dataloader = DataLoader(shuffled_train_data, batch_size=batch_size, shuffle=False)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","shuffled_validation_data = torch.utils.data.Subset(validation_data, torch.randperm(len(validation_data)).tolist())\n","validation_dataloader = DataLoader(shuffled_validation_data, batch_size=len(labels_dev), shuffle=False)\n","\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","shuffled_test_data = torch.utils.data.Subset(test_data, torch.randperm(len(test_data)).tolist())\n","test_dataloader = DataLoader(shuffled_test_data, batch_size=len(labels_test), shuffle=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train tensor shapes:\n","Inputs:  torch.Size([6451, 120])\n","Masks:  torch.Size([6451, 120])\n","Labels:  torch.Size([6451, 120])\n","\n","Validation tensor shapes:\n","Inputs:  torch.Size([903, 120])\n","Masks:  torch.Size([903, 120])\n","Labels:  torch.Size([903, 120])\n","\n","Test tensor shapes:\n","Inputs:  torch.Size([1772, 120])\n","Masks:  torch.Size([1772, 120])\n","Labels:  torch.Size([1772, 120])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AivweFUEgyrk"},"source":["We now charge the model into the cuda core."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0KWfz6HVpsN9","executionInfo":{"status":"ok","timestamp":1625761852525,"user_tz":-120,"elapsed":11898,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"621282e9-a20c-4cf0-fac2-0c2e7a266db8"},"source":["model.cuda()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"Pipz0b42-N_w"},"source":["Here, an example of the evaluation report is provided. For this, we use the `seqeval` library along with the labels or tags we desire to compute."]},{"cell_type":"code","metadata":{"id":"L9sQnkf_7fxU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625761852526,"user_tz":-120,"elapsed":10,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"d3791da2-cecd-47d9-ecc2-5628279c1d11"},"source":["from sklearn_crfsuite.metrics import flat_classification_report\n","from seqeval.metrics.sequence_labeling import get_entities\n","from seqeval.metrics import classification_report, accuracy_score\n","from seqeval.scheme import IOB2\n","\n","\n","if allTypes:\n","    tags_metrics = ['O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'B-DISEASE', 'I-DISEASE', 'B-SIGN', 'I-SIGN', 'B-SYMPTOM', 'I-SYMPTOM']\n","else:\n","    tags_metrics = ['O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'B-SIGN-SYM', 'I-SIGN-SYM']\n","\n","\n","# Example of metrics\n","_labels = final_dev_labels[-10:]\n","_labels_output = [\n","        [l for l in sentence if l != 0]\n","        for sentence in _labels\n","    ]\n","_converted = [\n","        [tags_metrics[l-1] for l in sentence if l != 0]\n","        for sentence in _labels\n","    ]\n","_report = flat_classification_report(y_true=_converted, y_pred=_converted, labels=tags_metrics, digits=4)\n","\n","print('Tags: {}\\nEntities in tag: {}'.format(tags_metrics, get_entities(tags_metrics)))\n","print()\n","print('Nr of sentences with labels: {}\\nExample of labels: {}\\nConverted labels: {}'.format(len(_labels), _labels_output, _converted))\n","print()\n","print(_report)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tags: ['O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'B-DISEASE', 'I-DISEASE', 'B-SIGN', 'I-SIGN', 'B-SYMPTOM', 'I-SYMPTOM']\n","Entities in tag: [('RAREDISEASE', 1, 2), ('DISEASE', 3, 4), ('SIGN', 5, 6), ('SYMPTOM', 7, 8)]\n","\n","Nr of sentences with labels: 10\n","Example of labels: [[2, 3, 3, 3, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1], [1, 1, 1, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1], [2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n","Converted labels: [['B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'O'], ['O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'B-DISEASE', 'I-DISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-RAREDISEASE', 'I-RAREDISEASE', 'I-RAREDISEASE', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n","\n","               precision    recall  f1-score   support\n","\n","            O     1.0000    1.0000    1.0000       168\n","B-RAREDISEASE     1.0000    1.0000    1.0000         8\n","I-RAREDISEASE     1.0000    1.0000    1.0000        29\n","    B-DISEASE     1.0000    1.0000    1.0000         3\n","    I-DISEASE     1.0000    1.0000    1.0000        10\n","       B-SIGN     0.0000    0.0000    0.0000         0\n","       I-SIGN     0.0000    0.0000    0.0000         0\n","    B-SYMPTOM     0.0000    0.0000    0.0000         0\n","    I-SYMPTOM     0.0000    0.0000    0.0000         0\n","\n","    micro avg     1.0000    1.0000    1.0000       218\n","    macro avg     0.5556    0.5556    0.5556       218\n"," weighted avg     1.0000    1.0000    1.0000       218\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"zZ2zHZOn-gRL"},"source":["## 5. Fine tuning the model and training\n","\n","Finally, we define the model parameters and hyper parameters and its training."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jy6n8WG3rAQp","executionInfo":{"status":"ok","timestamp":1625761852526,"user_tz":-120,"elapsed":6,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"c3aaa656-1ae3-47a1-9e98-ea13c0054dfe"},"source":["# BERT fine-tuning parameters\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n","\n","optimizer = BertAdam(optimizer_grouped_parameters,\n","                     lr=2e-5,\n","                     warmup=.1)\n","\n","# Function to compute the metrics of our predictions vs labels\n","def flat_accuracy(predictions, labels):\n","    \"\"\"\n","    This function computes the accuracy of the network as a float number.\n","    \"\"\"\n","    pred_flat = np.argmax(predictions, axis=2).flatten()\n","    labels_flat = labels.flatten()\n","    valid_predictions = [tags_metrics[p-1] for (p, l) in zip(pred_flat, labels_flat) if l != 0]\n","    valid_flags = [tags_metrics[l-1] for (p, l) in zip(pred_flat, labels_flat) if l != 0]\n","    return accuracy_score(y_true=valid_flags, y_pred=valid_predictions)\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def compute_nn_metrics(predictions, labels, tags=tags_metrics, entity_level=False, imbalanced=False):\n","    \"\"\"\n","    This function computes the metrics of the network through the seqeval model.\n","    \"\"\"\n","    pred_flat = np.argmax(predictions, axis=2).flatten()\n","    labels_flat = labels.flatten()\n","    imbalanced_tags = [t for t in tags]\n","    imbalanced_tags.remove('O')\n","    valid_predictions = [[tags_metrics[p-1] for (p, l) in zip(pred_flat, labels_flat) if l != 0]]\n","    valid_flags = [[tags_metrics[l-1] for (p, l) in zip(pred_flat, labels_flat) if l != 0]]\n","    if entity_level:\n","        return classification_report(y_true=valid_flags, y_pred=valid_predictions, scheme=IOB2, zero_division=0, digits=4)\n","    else:\n","        if imbalanced:\n","            return flat_classification_report(y_true=valid_flags, y_pred=valid_predictions, labels=imbalanced_tags, zero_division=0, digits=4)\n","        else:\n","            return flat_classification_report(y_true=valid_flags, y_pred=valid_predictions, labels=tags, zero_division=0, digits=4)\n","        \n","\n","torch.cuda.empty_cache() \n","# Store our loss and accuracy for plotting\n","train_loss_set = []\n","eval_accuracy_set = []\n","# Number of training epochs \n","epochs = 9\n","\n","print('Model finetuned!\\nNr of epochs to use: {}'.format(epochs))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["t_total value of -1 results in schedule not being applied\n"],"name":"stderr"},{"output_type":"stream","text":["Model finetuned!\n","Nr of epochs to use: 9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1HlVLO_rgJP","executionInfo":{"status":"ok","timestamp":1625763224373,"user_tz":-120,"elapsed":1371851,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"2e2af39b-9683-4350-bfc4-57d95cdf7391"},"source":["# BERT training loop\n","for _ in trange(epochs, desc=\"Epoch\"):  \n","  \n","    ## TRAINING\n","\n","    # Set our model to training mode\n","    model.train()  \n","    # Tracking variables\n","    tr_loss, train_accuracy = 0, 0\n","    nb_train_steps = 0\n","    # Train the data for one epoch\n","    for step, batch in enumerate(train_dataloader):\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Clear out the gradients (by default they accumulate)\n","        optimizer.zero_grad()\n","        # Forward pass\n","        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","        train_loss_set.append(loss.item())   \n","        # Backward pass\n","        loss.backward()\n","        # Update parameters and take a step using the computed gradient\n","        optimizer.step()\n","        # Update tracking variables\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        tmp_train_accuracy = flat_accuracy(logits, label_ids)\n","        train_accuracy += tmp_train_accuracy\n","        tr_loss += loss.item()\n","        nb_train_steps += 1\n","    print(\"\\nTrain loss: {}\".format(tr_loss/nb_train_steps))\n","    print(\"Total Train Accuracy: {}\".format(train_accuracy/nb_train_steps))\n","\n","    ## VALIDATION\n","\n","    # Put model in evaluation mode\n","    model.eval()\n","    # Tracking variables \n","    eval_accuracy = 0\n","    nb_eval_steps = 0\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","        with torch.no_grad():\n","            # Forward pass, calculate logit predictions\n","            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","            logits = outputs.logits\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        eval_metrics = compute_nn_metrics(logits, label_ids)\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy   \n","        eval_accuracy_set.append(tmp_eval_accuracy)    \n","        nb_eval_steps += 1\n","    print('\\nMetrics report in Validation:\\n{}'.format(eval_metrics))\n","    print(\"Total Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\rEpoch:   0%|          | 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Train loss: 0.48225549033077636\n","Total Train Accuracy: 0.849661863728547\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  11%|█         | 1/9 [02:29<19:59, 149.97s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9582    0.9490    0.9536     16744\n","B-RAREDISEASE     0.8179    0.8928    0.8537       513\n","I-RAREDISEASE     0.8643    0.9309    0.8964      2156\n","    B-DISEASE     0.6851    0.5688    0.6216       218\n","    I-DISEASE     0.6258    0.6370    0.6313       617\n","       B-SIGN     0.6202    0.7136    0.6636       405\n","       I-SIGN     0.6921    0.6790    0.6855      2165\n","    B-SYMPTOM     0.3333    0.1111    0.1667        18\n","    I-SYMPTOM     0.4000    0.0500    0.0889        40\n","\n","     accuracy                         0.9020     22876\n","    macro avg     0.6663    0.6147    0.6179     22876\n"," weighted avg     0.9020    0.9020    0.9014     22876\n","\n","Total Validation Accuracy: 0.9020370694177303\n","\n","Train loss: 0.19841337012182367\n","Total Train Accuracy: 0.9317131282208388\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  22%|██▏       | 2/9 [05:03<17:36, 150.93s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9626    0.9465    0.9545     16744\n","B-RAREDISEASE     0.8422    0.8947    0.8677       513\n","I-RAREDISEASE     0.8539    0.9569    0.9024      2156\n","    B-DISEASE     0.6940    0.5826    0.6334       218\n","    I-DISEASE     0.6538    0.6029    0.6273       617\n","       B-SIGN     0.6659    0.7086    0.6866       405\n","       I-SIGN     0.6921    0.7122    0.7020      2165\n","    B-SYMPTOM     0.5333    0.4444    0.4848        18\n","    I-SYMPTOM     0.5769    0.3750    0.4545        40\n","\n","     accuracy                         0.9058     22876\n","    macro avg     0.7194    0.6915    0.7015     22876\n"," weighted avg     0.9069    0.9058    0.9059     22876\n","\n","Total Validation Accuracy: 0.905796467913971\n","\n","Train loss: 0.12566399443341364\n","Total Train Accuracy: 0.9580176960206326\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  33%|███▎      | 3/9 [07:35<15:08, 151.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9485    0.9642    0.9563     16744\n","B-RAREDISEASE     0.8315    0.8850    0.8574       513\n","I-RAREDISEASE     0.8716    0.9443    0.9065      2156\n","    B-DISEASE     0.7727    0.5459    0.6398       218\n","    I-DISEASE     0.7685    0.5219    0.6216       617\n","       B-SIGN     0.7172    0.6889    0.7028       405\n","       I-SIGN     0.7336    0.6600    0.6949      2165\n","    B-SYMPTOM     0.4286    0.6667    0.5217        18\n","    I-SYMPTOM     0.4571    0.4000    0.4267        40\n","\n","     accuracy                         0.9098     22876\n","    macro avg     0.7255    0.6974    0.7031     22876\n"," weighted avg     0.9064    0.9098    0.9069     22876\n","\n","Total Validation Accuracy: 0.9097744360902256\n","\n","Train loss: 0.09603618726244953\n","Total Train Accuracy: 0.9688730296397038\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  44%|████▍     | 4/9 [10:08<12:39, 151.81s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9488    0.9656    0.9571     16744\n","B-RAREDISEASE     0.8371    0.8616    0.8492       513\n","I-RAREDISEASE     0.8792    0.9249    0.9014      2156\n","    B-DISEASE     0.6320    0.7248    0.6752       218\n","    I-DISEASE     0.5961    0.6888    0.6391       617\n","       B-SIGN     0.7209    0.6123    0.6622       405\n","       I-SIGN     0.7685    0.5949    0.6707      2165\n","    B-SYMPTOM     0.3846    0.5556    0.4545        18\n","    I-SYMPTOM     0.5000    0.3750    0.4286        40\n","\n","     accuracy                         0.9070     22876\n","    macro avg     0.6964    0.7004    0.6931     22876\n"," weighted avg     0.9049    0.9070    0.9045     22876\n","\n","Total Validation Accuracy: 0.9069767441860465\n","\n","Train loss: 0.0719164134012443\n","Total Train Accuracy: 0.9770630889320866\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  56%|█████▌    | 5/9 [12:40<10:08, 152.01s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9607    0.9544    0.9575     16744\n","B-RAREDISEASE     0.8660    0.8441    0.8549       513\n","I-RAREDISEASE     0.8960    0.8873    0.8916      2156\n","    B-DISEASE     0.6113    0.7431    0.6708       218\n","    I-DISEASE     0.5651    0.7455    0.6429       617\n","       B-SIGN     0.6699    0.6914    0.6804       405\n","       I-SIGN     0.7202    0.6776    0.6982      2165\n","    B-SYMPTOM     0.4333    0.7222    0.5417        18\n","    I-SYMPTOM     0.4186    0.4500    0.4337        40\n","\n","     accuracy                         0.9060     22876\n","    macro avg     0.6823    0.7462    0.7080     22876\n"," weighted avg     0.9092    0.9060    0.9071     22876\n","\n","Total Validation Accuracy: 0.9060150375939849\n","\n","Train loss: 0.05488448727548602\n","Total Train Accuracy: 0.9832241923860782\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  67%|██████▋   | 6/9 [15:13<07:36, 152.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9574    0.9576    0.9575     16744\n","B-RAREDISEASE     0.8447    0.8694    0.8569       513\n","I-RAREDISEASE     0.8913    0.9207    0.9058      2156\n","    B-DISEASE     0.6726    0.6972    0.6847       218\n","    I-DISEASE     0.6369    0.7277    0.6793       617\n","       B-SIGN     0.6958    0.7284    0.7117       405\n","       I-SIGN     0.7354    0.6674    0.6998      2165\n","    B-SYMPTOM     0.5714    0.6667    0.6154        18\n","    I-SYMPTOM     0.5455    0.4500    0.4932        40\n","\n","     accuracy                         0.9108     22876\n","    macro avg     0.7279    0.7428    0.7338     22876\n"," weighted avg     0.9106    0.9108    0.9104     22876\n","\n","Total Validation Accuracy: 0.9108235705542927\n","\n","Train loss: 0.03980383536856769\n","Total Train Accuracy: 0.9880101382845751\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  78%|███████▊  | 7/9 [17:46<05:04, 152.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9571    0.9602    0.9587     16744\n","B-RAREDISEASE     0.8512    0.8811    0.8659       513\n","I-RAREDISEASE     0.8917    0.9239    0.9075      2156\n","    B-DISEASE     0.6824    0.7294    0.7051       218\n","    I-DISEASE     0.6481    0.7164    0.6805       617\n","       B-SIGN     0.7086    0.7086    0.7086       405\n","       I-SIGN     0.7612    0.6771    0.7167      2165\n","    B-SYMPTOM     0.4615    0.6667    0.5455        18\n","    I-SYMPTOM     0.4390    0.4500    0.4444        40\n","\n","     accuracy                         0.9139     22876\n","    macro avg     0.7112    0.7459    0.7259     22876\n"," weighted avg     0.9134    0.9139    0.9133     22876\n","\n","Total Validation Accuracy: 0.9138835460744885\n","\n","Train loss: 0.035036253974551686\n","Total Train Accuracy: 0.9890102884069549\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  89%|████████▉ | 8/9 [20:18<02:32, 152.40s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9534    0.9621    0.9577     16744\n","B-RAREDISEASE     0.8675    0.8421    0.8546       513\n","I-RAREDISEASE     0.9044    0.8998    0.9021      2156\n","    B-DISEASE     0.6639    0.7339    0.6972       218\n","    I-DISEASE     0.6270    0.7164    0.6687       617\n","       B-SIGN     0.6790    0.7259    0.7017       405\n","       I-SIGN     0.7447    0.6550    0.6970      2165\n","    B-SYMPTOM     0.5238    0.6111    0.5641        18\n","    I-SYMPTOM     0.5625    0.4500    0.5000        40\n","\n","     accuracy                         0.9103     22876\n","    macro avg     0.7251    0.7329    0.7270     22876\n"," weighted avg     0.9096    0.9103    0.9096     22876\n","\n","Total Validation Accuracy: 0.9102990033222591\n","\n","Train loss: 0.029837808019071266\n","Total Train Accuracy: 0.9912476429657326\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch: 100%|██████████| 9/9 [22:51<00:00, 152.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Metrics report in Validation:\n","               precision    recall  f1-score   support\n","\n","            O     0.9468    0.9695    0.9580     16744\n","B-RAREDISEASE     0.8569    0.8635    0.8602       513\n","I-RAREDISEASE     0.8930    0.9174    0.9051      2156\n","    B-DISEASE     0.6916    0.7202    0.7056       218\n","    I-DISEASE     0.6677    0.7099    0.6881       617\n","       B-SIGN     0.7363    0.6963    0.7157       405\n","       I-SIGN     0.7915    0.6102    0.6891      2165\n","    B-SYMPTOM     0.4643    0.7222    0.5652        18\n","    I-SYMPTOM     0.5143    0.4500    0.4800        40\n","\n","     accuracy                         0.9129     22876\n","    macro avg     0.7291    0.7399    0.7297     22876\n"," weighted avg     0.9102    0.9129    0.9103     22876\n","\n","Total Validation Accuracy: 0.912921839482427\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"CfY260HEyfWT","colab":{"base_uri":"https://localhost:8080/","height":616},"executionInfo":{"status":"ok","timestamp":1625763224933,"user_tz":-120,"elapsed":571,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"2ffdb341-f5a0-44e6-ac7c-40d0c7948245"},"source":["# plot training performance\n","results_figure = plt.figure(figsize=(18,9))\n","ax_train = results_figure.add_subplot(1, 2, 1)\n","ax_val = results_figure.add_subplot(1, 2, 2)\n","results_figure.suptitle('BioBERT Results')\n","ax_train.set_title(\"Training loss evolution\")\n","ax_train.set_xlabel(\"Batch\")\n","ax_train.set_ylabel(\"Loss\")\n","ax_train.plot(train_loss_set)\n","ax_val.set_title(\"Validation accuracy evolution\")\n","ax_val.set_xlabel(\"Batch\")\n","ax_val.set_ylabel(\"Accuracy\")\n","ax_val.plot(eval_accuracy_set)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1296x648 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"bL8Yp-Kz_N7b"},"source":["## 6. Testing the model\n","\n","The final step is to test the model. This step is similar to the evaluation one with the difference that the input dataset is changed."]},{"cell_type":"code","metadata":{"id":"orWXD7pk0GgF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625763240188,"user_tz":-120,"elapsed":15259,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"89702854-97d0-43ac-e941-58cd7c954d4f"},"source":["## TEST\n","\n","# Put model in evaluation mode\n","model.eval()\n","# Evaluate data for one epoch\n","for batch in test_dataloader:\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","    with torch.no_grad():\n","        # Forward pass, calculate logit predictions\n","        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","        logits = outputs.logits   \n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    test_metrics = compute_nn_metrics(logits, label_ids)\n","    test_metrics_imbalanced = compute_nn_metrics(logits, label_ids, imbalanced=True)\n","    test_metrics_per_entity = compute_nn_metrics(logits, label_ids, entity_level=True)\n","print('Metrics report in Test (with \"O\" class):\\n{}'.format(test_metrics))\n","print('Metrics report in Test (w/o \"O\" class):\\n{}'.format(test_metrics_imbalanced))\n","print('Metrics report in Test per entity:\\n{}'.format(test_metrics_per_entity))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Metrics report in Test (with \"O\" class):\n","               precision    recall  f1-score   support\n","\n","            O     0.9579    0.9691    0.9635     35108\n","B-RAREDISEASE     0.8614    0.8807    0.8710      1073\n","I-RAREDISEASE     0.8829    0.9076    0.8951      4370\n","    B-DISEASE     0.6503    0.6885    0.6689       443\n","    I-DISEASE     0.5969    0.6557    0.6249      1278\n","       B-SIGN     0.6996    0.6961    0.6979       803\n","       I-SIGN     0.7575    0.6220    0.6831      3762\n","    B-SYMPTOM     0.7547    0.8000    0.7767        50\n","    I-SYMPTOM     0.7158    0.5231    0.6044       130\n","\n","     accuracy                         0.9163     47017\n","    macro avg     0.7641    0.7492    0.7539     47017\n"," weighted avg     0.9147    0.9163    0.9149     47017\n","\n","Metrics report in Test (w/o \"O\" class):\n","               precision    recall  f1-score   support\n","\n","B-RAREDISEASE     0.8614    0.8807    0.8710      1073\n","I-RAREDISEASE     0.8829    0.9076    0.8951      4370\n","    B-DISEASE     0.6503    0.6885    0.6689       443\n","    I-DISEASE     0.5969    0.6557    0.6249      1278\n","       B-SIGN     0.6996    0.6961    0.6979       803\n","       I-SIGN     0.7575    0.6220    0.6831      3762\n","    B-SYMPTOM     0.7547    0.8000    0.7767        50\n","    I-SYMPTOM     0.7158    0.5231    0.6044       130\n","\n","    micro avg     0.7881    0.7609    0.7742     11909\n","    macro avg     0.7399    0.7217    0.7277     11909\n"," weighted avg     0.7873    0.7609    0.7716     11909\n","\n","Metrics report in Test per entity:\n","              precision    recall  f1-score   support\n","\n","     DISEASE     0.5788    0.6388    0.6073       454\n"," RAREDISEASE     0.8167    0.8584    0.8370      1095\n","        SIGN     0.5296    0.5501    0.5397       958\n","     SYMPTOM     0.6066    0.6852    0.6435        54\n","\n","   micro avg     0.6625    0.7005    0.6810      2561\n","   macro avg     0.6329    0.6831    0.6569      2561\n","weighted avg     0.6627    0.7005    0.6810      2561\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o2naPUQ2RQeM"},"source":["Scenarios:\n","\n","    - I. Surface string and entity type match\n","    - II. System hypothesized an entity\n","    - III. System misses an entity\n","    - IV. System assigns the wrong entity type\n","    - V. System gets the boundaries of the surface string wrong\n","    - VI. System gets the boundaries and entity type wrong\n","\n","MUC metrics:\n","\n","    - Correct (COR) : both are the same\n","    - Incorrect (INC) : the output of a system and the golden annotation don’t match\n","    - Partial (PAR) : system and the golden annotation are somewhat “similar” but not the same\n","    - Missing (MIS) : a golden annotation is not captured by a system\n","    - Spurius (SPU) : system produces a response which doesn’t exist in the golden annotation\n","\n","Four different ways to measure precision/recall/f1-score:\n","\n","    - Strict: exact boundary surface string match and entity type\n","    - Exact: exact boundary match over the surface string, regardless of the type\n","    - Partial: partial boundary match over the surface string, regardless of the type\n","    - Type: some overlap between the system tagged entity and the gold annotation is required\n"]},{"cell_type":"code","metadata":{"id":"yv6oob40RPgi"},"source":["import logging\n","from collections import namedtuple\n","from copy import deepcopy\n","\n","logging.basicConfig(\n","    format=\"%(asctime)s %(name)s %(levelname)s: %(message)s\",\n","    datefmt=\"%Y-%m-%d %H:%M:%S\",\n","    level=\"DEBUG\",\n",")\n","\n","Entity = namedtuple(\"Entity\", \"e_type start_offset end_offset\")\n","\n","class Evaluator():\n","\n","    def __init__(self, true, pred, tags):\n","        \"\"\"\n","        \"\"\"\n","\n","        if len(true) != len(pred):\n","            raise ValueError(\"Number of predicted documents does not equal true\")\n","\n","        self.true = true\n","        self.pred = pred\n","        self.tags = tags\n","\n","        # Setup dict into which metrics will be stored.\n","\n","        self.metrics_results = {\n","            'correct': 0,\n","            'incorrect': 0,\n","            'partial': 0,\n","            'missed': 0,\n","            'spurious': 0,\n","            'possible': 0,\n","            'actual': 0,\n","            'precision': 0,\n","            'recall': 0,\n","        }\n","\n","        # Copy results dict to cover the four schemes.\n","\n","        self.results = {\n","            'strict': deepcopy(self.metrics_results),\n","            'ent_type': deepcopy(self.metrics_results),\n","            'partial':deepcopy(self.metrics_results),\n","            'exact':deepcopy(self.metrics_results),\n","            }\n","\n","        # Create an accumulator to store results\n","\n","        self.evaluation_agg_entities_type = {e: deepcopy(self.results) for e in tags}\n","\n","\n","    def evaluate(self):\n","\n","        logging.info(\n","            \"Imported %s predictions for %s true examples\",\n","            len(self.pred), len(self.true)\n","        )\n","\n","        for true_ents, pred_ents in zip(self.true, self.pred):\n","\n","            # Check that the length of the true and predicted examples are the\n","            # same. This must be checked here, because another error may not\n","            # be thrown if the lengths do not match.\n","\n","            if len(true_ents) != len(pred_ents):\n","                raise ValueError(\"Prediction length does not match true example length\")\n","\n","            # Compute results for one message\n","\n","            tmp_results, tmp_agg_results = compute_metrics(\n","                collect_named_entities(true_ents),\n","                collect_named_entities(pred_ents),\n","                self.tags\n","            )\n","\n","            # Cycle through each result and accumulate\n","\n","            # TODO: Combine these loops below:\n","\n","            for eval_schema in self.results:\n","\n","                for metric in self.results[eval_schema]:\n","\n","                    self.results[eval_schema][metric] += tmp_results[eval_schema][metric]\n","\n","            # Calculate global precision and recall\n","\n","            self.results = compute_precision_recall_wrapper(self.results)\n","\n","            # Aggregate results by entity type\n","\n","            for e_type in self.tags:\n","\n","                for eval_schema in tmp_agg_results[e_type]:\n","\n","                    for metric in tmp_agg_results[e_type][eval_schema]:\n","\n","                        self.evaluation_agg_entities_type[e_type][eval_schema][metric] += tmp_agg_results[e_type][eval_schema][metric]\n","\n","                # Calculate precision recall at the individual entity level\n","\n","                self.evaluation_agg_entities_type[e_type] = compute_precision_recall_wrapper(self.evaluation_agg_entities_type[e_type])\n","\n","        return self.results, self.evaluation_agg_entities_type\n","\n","\n","def collect_named_entities(tokens):\n","    \"\"\"\n","    Creates a list of Entity named-tuples, storing the entity type and the start and end\n","    offsets of the entity.\n","    :param tokens: a list of tags\n","    :return: a list of Entity named-tuples\n","    \"\"\"\n","\n","    named_entities = []\n","    start_offset = None\n","    end_offset = None\n","    ent_type = None\n","\n","    for offset, token_tag in enumerate(tokens):\n","\n","        if token_tag == 'O':\n","            if ent_type is not None and start_offset is not None:\n","                end_offset = offset - 1\n","                named_entities.append(Entity(ent_type, start_offset, end_offset))\n","                start_offset = None\n","                end_offset = None\n","                ent_type = None\n","\n","        elif ent_type is None:\n","            ent_type = token_tag[2:]\n","            start_offset = offset\n","\n","        elif ent_type != token_tag[2:] or (ent_type == token_tag[2:] and token_tag[:1] == 'B'):\n","\n","            end_offset = offset - 1\n","            named_entities.append(Entity(ent_type, start_offset, end_offset))\n","\n","            # start of a new entity\n","            ent_type = token_tag[2:]\n","            start_offset = offset\n","            end_offset = None\n","\n","    # catches an entity that goes up until the last token\n","\n","    if ent_type is not None and start_offset is not None and end_offset is None:\n","        named_entities.append(Entity(ent_type, start_offset, len(tokens)-1))\n","\n","    return named_entities\n","\n","\n","def compute_metrics(true_named_entities, pred_named_entities, tags):\n","\n","\n","    eval_metrics = {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'precision': 0, 'recall': 0}\n","\n","    # overall results\n","    \n","    evaluation = {\n","        'strict': deepcopy(eval_metrics),\n","        'ent_type': deepcopy(eval_metrics),\n","        'partial': deepcopy(eval_metrics),\n","        'exact': deepcopy(eval_metrics)\n","    }\n","\n","    # results by entity type\n","\n","    evaluation_agg_entities_type = {e: deepcopy(evaluation) for e in tags}\n","\n","    # keep track of entities that overlapped\n","\n","    true_which_overlapped_with_pred = []\n","\n","    # Subset into only the tags that we are interested in.\n","    # NOTE: we remove the tags we don't want from both the predicted and the\n","    # true entities. This covers the two cases where mismatches can occur:\n","    #\n","    # 1) Where the model predicts a tag that is not present in the true data\n","    # 2) Where there is a tag in the true data that the model is not capable of\n","    # predicting.\n","\n","    true_named_entities = [ent for ent in true_named_entities if ent.e_type in tags]\n","    pred_named_entities = [ent for ent in pred_named_entities if ent.e_type in tags]\n","\n","    # go through each predicted named-entity\n","\n","    for pred in pred_named_entities:\n","        found_overlap = False\n","\n","        # Check each of the potential scenarios in turn. See\n","        # http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/\n","        # for scenario explanation.\n","\n","        # Scenario I: Exact match between true and pred\n","\n","        if pred in true_named_entities:\n","            true_which_overlapped_with_pred.append(pred)\n","            evaluation['strict']['correct'] += 1\n","            evaluation['ent_type']['correct'] += 1\n","            evaluation['exact']['correct'] += 1\n","            evaluation['partial']['correct'] += 1\n","\n","            # for the agg. by e_type results\n","            evaluation_agg_entities_type[pred.e_type]['strict']['correct'] += 1\n","            evaluation_agg_entities_type[pred.e_type]['ent_type']['correct'] += 1\n","            evaluation_agg_entities_type[pred.e_type]['exact']['correct'] += 1\n","            evaluation_agg_entities_type[pred.e_type]['partial']['correct'] += 1\n","\n","        else:\n","\n","            # check for overlaps with any of the true entities\n","\n","            for true in true_named_entities:\n","\n","                pred_range = range(pred.start_offset, pred.end_offset)\n","                true_range = range(true.start_offset, true.end_offset)\n","\n","                # Scenario IV: Offsets match, but entity type is wrong\n","\n","                if true.start_offset == pred.start_offset and pred.end_offset == true.end_offset \\\n","                        and true.e_type != pred.e_type:\n","\n","                    # overall results\n","                    evaluation['strict']['incorrect'] += 1\n","                    evaluation['ent_type']['incorrect'] += 1\n","                    evaluation['partial']['correct'] += 1\n","                    evaluation['exact']['correct'] += 1\n","\n","                    # aggregated by entity type results\n","                    evaluation_agg_entities_type[true.e_type]['strict']['incorrect'] += 1\n","                    evaluation_agg_entities_type[true.e_type]['ent_type']['incorrect'] += 1\n","                    evaluation_agg_entities_type[true.e_type]['partial']['correct'] += 1\n","                    evaluation_agg_entities_type[true.e_type]['exact']['correct'] += 1\n","\n","                    true_which_overlapped_with_pred.append(true)\n","                    found_overlap = True\n","\n","                    break\n","\n","                # check for an overlap i.e. not exact boundary match, with true entities\n","\n","                elif find_overlap(true_range, pred_range):\n","\n","                    true_which_overlapped_with_pred.append(true)\n","\n","                    # Scenario V: There is an overlap (but offsets do not match\n","                    # exactly), and the entity type is the same.\n","                    # 2.1 overlaps with the same entity type\n","\n","                    if pred.e_type == true.e_type:\n","\n","                        # overall results\n","                        evaluation['strict']['incorrect'] += 1\n","                        evaluation['ent_type']['correct'] += 1\n","                        evaluation['partial']['partial'] += 1\n","                        evaluation['exact']['incorrect'] += 1\n","\n","                        # aggregated by entity type results\n","                        evaluation_agg_entities_type[true.e_type]['strict']['incorrect'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['ent_type']['correct'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['partial']['partial'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['exact']['incorrect'] += 1\n","\n","                        found_overlap = True\n","\n","                        break\n","\n","                    # Scenario VI: Entities overlap, but the entity type is\n","                    # different.\n","\n","                    else:\n","                        # overall results\n","                        evaluation['strict']['incorrect'] += 1\n","                        evaluation['ent_type']['incorrect'] += 1\n","                        evaluation['partial']['partial'] += 1\n","                        evaluation['exact']['incorrect'] += 1\n","\n","                        # aggregated by entity type results\n","                        # Results against the true entity\n","\n","                        evaluation_agg_entities_type[true.e_type]['strict']['incorrect'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['partial']['partial'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['ent_type']['incorrect'] += 1\n","                        evaluation_agg_entities_type[true.e_type]['exact']['incorrect'] += 1\n","\n","                        # Results against the predicted entity\n","\n","                        # evaluation_agg_entities_type[pred.e_type]['strict']['spurious'] += 1\n","\n","                        found_overlap = True\n","\n","                        break\n","\n","            # Scenario II: Entities are spurious (i.e., over-generated).\n","\n","            if not found_overlap:\n","\n","                # Overall results\n","\n","                evaluation['strict']['spurious'] += 1\n","                evaluation['ent_type']['spurious'] += 1\n","                evaluation['partial']['spurious'] += 1\n","                evaluation['exact']['spurious'] += 1\n","\n","                # Aggregated by entity type results\n","\n","                # NOTE: when pred.e_type is not found in tags\n","                # or when it simply does not appear in the test set, then it is\n","                # spurious, but it is not clear where to assign it at the tag\n","                # level. In this case, it is applied to all target_tags\n","                # found in this example. This will mean that the sum of the\n","                # evaluation_agg_entities will not equal evaluation.\n","\n","                for true in tags:                    \n","\n","                    evaluation_agg_entities_type[true]['strict']['spurious'] += 1\n","                    evaluation_agg_entities_type[true]['ent_type']['spurious'] += 1\n","                    evaluation_agg_entities_type[true]['partial']['spurious'] += 1\n","                    evaluation_agg_entities_type[true]['exact']['spurious'] += 1\n","\n","    # Scenario III: Entity was missed entirely.\n","\n","    for true in true_named_entities:\n","        if true in true_which_overlapped_with_pred:\n","            continue\n","        else:\n","            # overall results\n","            evaluation['strict']['missed'] += 1\n","            evaluation['ent_type']['missed'] += 1\n","            evaluation['partial']['missed'] += 1\n","            evaluation['exact']['missed'] += 1\n","\n","            # for the agg. by e_type\n","            evaluation_agg_entities_type[true.e_type]['strict']['missed'] += 1\n","            evaluation_agg_entities_type[true.e_type]['ent_type']['missed'] += 1\n","            evaluation_agg_entities_type[true.e_type]['partial']['missed'] += 1\n","            evaluation_agg_entities_type[true.e_type]['exact']['missed'] += 1\n","\n","    # Compute 'possible', 'actual' according to SemEval-2013 Task 9.1 on the\n","    # overall results, and use these to calculate precision and recall.\n","\n","    for eval_type in evaluation:\n","        evaluation[eval_type] = compute_actual_possible(evaluation[eval_type])\n","\n","    # Compute 'possible', 'actual', and precision and recall on entity level\n","    # results. Start by cycling through the accumulated results.\n","\n","    for entity_type, entity_level in evaluation_agg_entities_type.items():\n","\n","        # Cycle through the evaluation types for each dict containing entity\n","        # level results.\n","\n","        for eval_type in entity_level:\n","\n","            evaluation_agg_entities_type[entity_type][eval_type] = compute_actual_possible(\n","                entity_level[eval_type]\n","            )\n","\n","    return evaluation, evaluation_agg_entities_type\n","\n","\n","def find_overlap(true_range, pred_range):\n","    \"\"\"Find the overlap between two ranges\n","    Find the overlap between two ranges. Return the overlapping values if\n","    present, else return an empty set().\n","    Examples:\n","    >>> find_overlap((1, 2), (2, 3))\n","    2\n","    >>> find_overlap((1, 2), (3, 4))\n","    set()\n","    \"\"\"\n","\n","    true_set = set(true_range)\n","    pred_set = set(pred_range)\n","\n","    overlaps = true_set.intersection(pred_set)\n","\n","    return overlaps\n","\n","\n","def compute_actual_possible(results):\n","    \"\"\"\n","    Takes a result dict that has been output by compute metrics.\n","    Returns the results dict with actual, possible populated.\n","    When the results dicts is from partial or ent_type metrics, then\n","    partial_or_type=True to ensure the right calculation is used for\n","    calculating precision and recall.\n","    \"\"\"\n","\n","    correct = results['correct']\n","    incorrect = results['incorrect']\n","    partial = results['partial']\n","    missed = results['missed']\n","    spurious = results['spurious']\n","\n","    # Possible: number annotations in the gold-standard which contribute to the\n","    # final score\n","\n","    possible = correct + incorrect + partial + missed\n","\n","    # Actual: number of annotations produced by the NER system\n","\n","    actual = correct + incorrect + partial + spurious\n","\n","    results[\"actual\"] = actual\n","    results[\"possible\"] = possible\n","\n","    return results\n","\n","\n","def compute_precision_recall(results, partial_or_type=False):\n","    \"\"\"\n","    Takes a result dict that has been output by compute metrics.\n","    Returns the results dict with precison and recall populated.\n","    When the results dicts is from partial or ent_type metrics, then\n","    partial_or_type=True to ensure the right calculation is used for\n","    calculating precision and recall.\n","    \"\"\"\n","\n","    actual = results[\"actual\"]\n","    possible = results[\"possible\"]\n","    partial = results['partial']\n","    correct = results['correct']\n","\n","    if partial_or_type:\n","        precision = (correct + 0.5 * partial) / actual if actual > 0 else 0\n","        recall = (correct + 0.5 * partial) / possible if possible > 0 else 0\n","\n","    else:\n","        precision = correct / actual if actual > 0 else 0\n","        recall = correct / possible if possible > 0 else 0\n","\n","    results[\"precision\"] = precision\n","    results[\"recall\"] = recall\n","\n","    return results\n","\n","\n","def compute_precision_recall_wrapper(results):\n","    \"\"\"\n","    Wraps the compute_precision_recall function and runs on a dict of results\n","    \"\"\"\n","\n","    results_a = {key: compute_precision_recall(value, True) for key, value in results.items() if\n","                 key in ['partial', 'ent_type']}\n","    results_b = {key: compute_precision_recall(value) for key, value in results.items() if\n","                 key in ['strict', 'exact']}\n","\n","    results = {**results_a, **results_b}\n","\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z7MzfEKfRpys","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625763242169,"user_tz":-120,"elapsed":1053,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"a447cf42-cfaf-4512-ee73-b5ee3d6ea1e3"},"source":["inputs_idxs = b_input_ids.to('cpu').numpy()\n","inputs_idxs = [[i for i in sentence if i != 0] for sentence in inputs_idxs]\n","inputs_idxs = [tokenizer.convert_ids_to_tokens(sentence) for sentence in inputs_idxs]\n","pred_flat = np.argmax(logits, axis=2)\n","pred_sym = [[tags_metrics[l-1] for l in sentence if l != 0] for sentence in pred_flat]\n","true_flags = [[tags_metrics[l-1] for l in sentence if l != 0] for sentence in label_ids]\n","pred_flags = []\n","\n","for sp, st in zip(pred_sym, true_flags):\n","    limit = len(st)\n","    new = sp[:limit]\n","    pred_flags.append(new)\n","\n","print('Labels and sentences created')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Labels and sentences created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l9qcbi72Ra02","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625763242554,"user_tz":-120,"elapsed":387,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"34b8d43a-5bd7-4fd8-dc2e-28cee6a08bad"},"source":["import random\n","\n","random.seed(3)\n","result_examples_idx = random.sample(range(len(true_flags)), k=30)\n","result_examples_y_gold = list()\n","result_examples_y_pred = list()\n","original_sentences = list()\n","\n","for idx in result_examples_idx:\n","    result_examples_y_gold.append(true_flags[idx])\n","    result_examples_y_pred.append(pred_flags[idx])\n","    original_sentences.append(inputs_idxs[idx])\n","\n","itr = 0\n","for g, p, s in zip(result_examples_y_gold, result_examples_y_pred, original_sentences):\n","    assert len(g) == len(p), 'Results does not seem to be the same'\n","    print('Sentence Nr: ', result_examples_idx[itr])\n","    original_s = pd.Series(s, name='WORD')\n","    df = pd.DataFrame(original_s)\n","    df['GOLD'] = g\n","    df['PRED'] = p\n","    print(df)\n","    itr += 1\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sentence Nr:  487\n","        WORD           GOLD           PRED\n","0        the              O              O\n","1      major              O              O\n","2   physical              O              O\n","3   features              O              O\n","4         of              O              O\n","5         ad  B-RAREDISEASE  B-RAREDISEASE\n","6      ##ams  I-RAREDISEASE  I-RAREDISEASE\n","7          -  I-RAREDISEASE  I-RAREDISEASE\n","8      olive  I-RAREDISEASE  I-RAREDISEASE\n","9        ##r  I-RAREDISEASE  I-RAREDISEASE\n","10  syndrome  I-RAREDISEASE  I-RAREDISEASE\n","11         (              O              O\n","12         i              O              O\n","13         .              O              O\n","14         e              O              O\n","15         .              O              O\n","16         ,              O              O\n","17     scalp         B-SIGN         B-SIGN\n","18   defects         I-SIGN         I-SIGN\n","19       and              O              O\n","20      limb              O         B-SIGN\n","21  abnormal              O         I-SIGN\n","22   ##ities              O         I-SIGN\n","23         )              O              O\n","24       are              O              O\n","25  apparent              O              O\n","26        at              O              O\n","27     birth              O              O\n","28         (              O              O\n","29       con         I-SIGN              O\n","30     ##gen         I-SIGN              O\n","31    ##ital         I-SIGN              O\n","32         )              O              O\n","33         .              O              O\n","\n","Sentence Nr:  1213\n","             WORD           GOLD           PRED\n","0           there              O              O\n","1             are              O              O\n","2        numerous              O              O\n","3      conditions              O              O\n","4   characterized              O              O\n","5              by              O              O\n","6           signs              O              O\n","7             and              O              O\n","8        symptoms              O              O\n","9            that              O              O\n","10            are              O              O\n","11        similar              O              O\n","12             to              O              O\n","13          those              O              O\n","14          found              O              O\n","15             in              O              O\n","16              a  B-RAREDISEASE  B-RAREDISEASE\n","17          ##rac  I-RAREDISEASE  I-RAREDISEASE\n","18           ##hn  I-RAREDISEASE  I-RAREDISEASE\n","19          ##oid  I-RAREDISEASE  I-RAREDISEASE\n","20         ##itis  I-RAREDISEASE  I-RAREDISEASE\n","21              ,              O              O\n","22        however              O              O\n","23              ,              O              O\n","24           only              O              O\n","25              a              O              O\n","26            few              O              O\n","27           will              O              O\n","28             be              O              O\n","29         listed              O              O\n","30              .              O              O\n","\n","Sentence Nr:  1114\n","           WORD           GOLD           PRED\n","0           dry         B-SIGN  B-RAREDISEASE\n","1         cough         I-SIGN  I-RAREDISEASE\n","2            is              O              O\n","3           one              O              O\n","4   distinction              O              O\n","5          from              O              O\n","6       typical              O              O\n","7     pneumonia      B-DISEASE  B-RAREDISEASE\n","8       because              O              O\n","9          spit              O         B-SIGN\n","10            (              O              O\n","11            s         B-SIGN              O\n","12        ##put         I-SIGN              O\n","13         ##um         I-SIGN              O\n","14            )              O              O\n","15           is              O              O\n","16          too              O              O\n","17        thick              O              O\n","18           to         I-SIGN              O\n","19       become         I-SIGN              O\n","20   productive         I-SIGN         I-SIGN\n","21            ,              O              O\n","22    therefore              O              O\n","23   productive              O         B-SIGN\n","24        cough         B-SIGN         I-SIGN\n","25           is              O              O\n","26          not              O              O\n","27           as              O              O\n","28       common              O              O\n","29           in              O              O\n","30            p  B-RAREDISEASE  B-RAREDISEASE\n","31          ##j  I-RAREDISEASE  I-RAREDISEASE\n","32          ##p  I-RAREDISEASE  I-RAREDISEASE\n","33            .              O              O\n","\n","Sentence Nr:  267\n","            WORD GOLD PRED\n","0        however    O    O\n","1              ,    O    O\n","2        despite    O    O\n","3          these    O    O\n","4   similarities    O    O\n","5              ,    O    O\n","6            the    O    O\n","7            two    O    O\n","8      disorders    O    O\n","9            are    O    O\n","10      distinct    O    O\n","11             .    O    O\n","\n","Sentence Nr:  757\n","        WORD GOLD PRED\n","0        the    O    O\n","1      exact    O    O\n","2     number    O    O\n","3         of    O    O\n","4     people    O    O\n","5        who    O    O\n","6       have    O    O\n","7       this    O    O\n","8   disorder    O    O\n","9         is    O    O\n","10   unknown    O    O\n","11         .    O    O\n","\n","Sentence Nr:  1236\n","          WORD GOLD PRED\n","0          the    O    O\n","1     disorder    O    O\n","2          was    O    O\n","3    initially    O    O\n","4    described    O    O\n","5           in    O    O\n","6          the    O    O\n","7      medical    O    O\n","8   literature    O    O\n","9           in    O    O\n","10        1973    O    O\n","11           .    O    O\n","\n","Sentence Nr:  970\n","       WORD           GOLD           PRED\n","0       add  B-RAREDISEASE  B-RAREDISEASE\n","1    ##ison  I-RAREDISEASE  I-RAREDISEASE\n","2         ’  I-RAREDISEASE  I-RAREDISEASE\n","3         s  I-RAREDISEASE  I-RAREDISEASE\n","4   disease  I-RAREDISEASE  I-RAREDISEASE\n","5   affects              O              O\n","6     males              O              O\n","7       and              O              O\n","8   females              O              O\n","9        in              O              O\n","10    equal              O              O\n","11  numbers              O              O\n","12        .              O              O\n","\n","Sentence Nr:  1281\n","          WORD GOLD PRED\n","0        there    O    O\n","1           is    O    O\n","2   tremendous    O    O\n","3    diversity    O    O\n","4           in    O    O\n","5          the    O    O\n","6         type    O    O\n","7          and    O    O\n","8     severity    O    O\n","9           of    O    O\n","10    symptoms    O    O\n","11        from    O    O\n","12     patient    O    O\n","13          to    O    O\n","14     patient    O    O\n","15           .    O    O\n","\n","Sentence Nr:  1189\n","           WORD GOLD PRED\n","0          step    O    O\n","1        ##wise    O    O\n","2       testing    O    O\n","3           for    O    O\n","4             p    O    O\n","5          ##ho    O    O\n","6           ##x    O    O\n","7           ##2    O    O\n","8           ##b    O    O\n","9     mutations    O    O\n","10       should    O    O\n","11           be    O    O\n","12         done    O    O\n","13         with    O    O\n","14        close    O    O\n","15  involvement    O    O\n","16           by    O    O\n","17            a    O    O\n","18    physician    O    O\n","19          and    O    O\n","20      genetic    O    O\n","21    counselor    O    O\n","22            .    O    O\n","\n","Sentence Nr:  134\n","          WORD GOLD PRED\n","0         they    O    O\n","1          may    O    O\n","2           be    O    O\n","3   widespread    O    O\n","4         over    O    O\n","5          the    O    O\n","6        trunk    O    O\n","7            ,    O    O\n","8         back    O    O\n","9            ,    O    O\n","10         and    O    O\n","11           /    O    O\n","12          or    O    O\n","13   shoulders    O    O\n","14           .    O    O\n","\n","Sentence Nr:  1240\n","        WORD GOLD PRED\n","0      early    O    O\n","1  diagnosis    O    O\n","2        and    O    O\n","3        pro    O    O\n","4      ##mpt    O    O\n","5  treatment    O    O\n","6         is    O    O\n","7  essential    O    O\n","8          .    O    O\n","\n","Sentence Nr:  26\n","           WORD       GOLD           PRED\n","0     secondary          O  B-RAREDISEASE\n","1             r  B-DISEASE  I-RAREDISEASE\n","2          ##ls  I-DISEASE  I-RAREDISEASE\n","3           may          O              O\n","4         occur          O              O\n","5            in          O              O\n","6   association          O              O\n","7          with          O              O\n","8       certain          O              O\n","9    conditions          O              O\n","10            ,          O              O\n","11         such          O              O\n","12           as          O              O\n","13         iron  B-DISEASE      B-DISEASE\n","14   deficiency  I-DISEASE      I-DISEASE\n","15            ,          O              O\n","16          low          O              O\n","17       levels          O              O\n","18           of          O              O\n","19          the          O              O\n","20       oxygen          O              O\n","21            -          O              O\n","22     carrying          O              O\n","23    component          O              O\n","24           of          O              O\n","25          red          O              O\n","26        blood          O              O\n","27        cells          O              O\n","28            (          O              O\n","29           an  B-DISEASE      B-DISEASE\n","30       ##emia  I-DISEASE      I-DISEASE\n","31            )          O              O\n","32            ,          O              O\n","33       kidney  B-DISEASE      B-DISEASE\n","34      failure  I-DISEASE      I-DISEASE\n","35            ,          O              O\n","36           or          O              O\n","37    pregnancy          O              O\n","38            .          O              O\n","\n","Sentence Nr:  1715\n","       WORD GOLD PRED\n","0    stress    O    O\n","1       and    O    O\n","2     local    O    O\n","3    injury    O    O\n","4       may    O    O\n","5      also    O    O\n","6        be    O    O\n","7  involved    O    O\n","8         .    O    O\n","\n","Sentence Nr:  960\n","         WORD GOLD PRED\n","0         the    O    O\n","1       range    O    O\n","2         and    O    O\n","3    severity    O    O\n","4          of    O    O\n","5    symptoms    O    O\n","6      varies    O    O\n","7           ,    O    O\n","8     greatly    O    O\n","9   depending    O    O\n","10         on    O    O\n","11        the    O    O\n","12      exact    O    O\n","13   location    O    O\n","14        and    O    O\n","15       size    O    O\n","16         of    O    O\n","17        the    O    O\n","18    missing    O    O\n","19    genetic    O    O\n","20   material    O    O\n","21          .    O    O\n","\n","Sentence Nr:  531\n","       WORD GOLD PRED\n","0      some    O    O\n","1       may    O    O\n","2        be    O    O\n","3     large    O    O\n","4    enough    O    O\n","5        to    O    O\n","6        be    O    O\n","7    called    O    O\n","8         “    O    O\n","9    giants    O    O\n","10        ”    O    O\n","11    while    O    O\n","12   others    O    O\n","13      may    O    O\n","14       be    O    O\n","15  limited    O    O\n","16       to    O    O\n","17    small    O    O\n","18    areas    O    O\n","19       of    O    O\n","20      the    O    O\n","21  temples    O    O\n","22       or    O    O\n","23   cheeks    O    O\n","24        .    O    O\n","\n","Sentence Nr:  1128\n","       WORD           GOLD           PRED\n","0         g  B-RAREDISEASE  B-RAREDISEASE\n","1       ##s  I-RAREDISEASE  I-RAREDISEASE\n","2       ##d  I-RAREDISEASE  I-RAREDISEASE\n","3      type  I-RAREDISEASE  I-RAREDISEASE\n","4         v  I-RAREDISEASE  I-RAREDISEASE\n","5      ##ii  I-RAREDISEASE  I-RAREDISEASE\n","6   affects              O              O\n","7     males              O              O\n","8       and              O              O\n","9   females              O              O\n","10       in              O              O\n","11    equal              O              O\n","12  numbers              O              O\n","13        .              O              O\n","\n","Sentence Nr:  479\n","         WORD GOLD PRED\n","0           a    O    O\n","1      family    O    O\n","2     history    O    O\n","3         and    O    O\n","4    physical    O    O\n","5        exam    O    O\n","6         can    O    O\n","7     confirm    O    O\n","8         the    O    O\n","9   diagnosis    O    O\n","10          .    O    O\n","\n","Sentence Nr:  392\n","         WORD           GOLD           PRED\n","0       hairy  B-RAREDISEASE  B-RAREDISEASE\n","1      tongue  I-RAREDISEASE  I-RAREDISEASE\n","2        most              O              O\n","3    commonly              O              O\n","4     affects              O              O\n","5      adults              O              O\n","6           ;              O              O\n","7     however              O              O\n","8           ,              O              O\n","9          it              O              O\n","10        may              O              O\n","11  sometimes              O              O\n","12      occur              O              O\n","13     during              O              O\n","14  childhood              O              O\n","15         or              O              O\n","16         ad              O              O\n","17      ##ole              O              O\n","18   ##scence              O              O\n","19          .              O              O\n","\n","Sentence Nr:  1468\n","           WORD       GOLD       PRED\n","0            in          O          O\n","1      contrast          O          O\n","2            to          O          O\n","3        purely          O          O\n","4    peripheral  B-DISEASE          O\n","5            ne  I-DISEASE  I-DISEASE\n","6         ##uro  I-DISEASE  I-DISEASE\n","7        ##path  I-DISEASE  I-DISEASE\n","8         ##ies  I-DISEASE  I-DISEASE\n","9             ,          O          O\n","10          the          O          O\n","11       reflex          O     B-SIGN\n","12           of          O          O\n","13          the          O          O\n","14         toes          O          O\n","15        known          O          O\n","16           as          O          O\n","17            b     B-SIGN     B-SIGN\n","18        ##abi     I-SIGN     I-SIGN\n","19         ##ns     I-SIGN     I-SIGN\n","20         ##ki     I-SIGN     I-SIGN\n","21            ’     I-SIGN     I-SIGN\n","22            s     I-SIGN     I-SIGN\n","23         sign     I-SIGN     I-SIGN\n","24           is     I-SIGN          O\n","25        often     I-SIGN          O\n","26     positive     I-SIGN          O\n","27            ,          O          O\n","28   indicating          O          O\n","29  involvement          O          O\n","30           of          O          O\n","31      central          O          O\n","32        motor          O          O\n","33     pathways          O          O\n","34            .          O          O\n","\n","Sentence Nr:  963\n","          WORD GOLD    PRED\n","0        these    O       O\n","1       tumors    O  B-SIGN\n","2          are    O       O\n","3   frequently    O       O\n","4        micro    O       O\n","5     ##scopic    O       O\n","6          and    O       O\n","7    extremely    O       O\n","8    difficult    O       O\n","9           to    O       O\n","10      detect    O       O\n","11           .    O       O\n","\n","Sentence Nr:  1107\n","       WORD           GOLD           PRED\n","0        am  B-RAREDISEASE  B-RAREDISEASE\n","1     ##elo  I-RAREDISEASE  I-RAREDISEASE\n","2   ##blast  I-RAREDISEASE  I-RAREDISEASE\n","3     ##oma  I-RAREDISEASE  I-RAREDISEASE\n","4       can              O              O\n","5      show              O              O\n","6        up              O              O\n","7    either              O              O\n","8        in              O              O\n","9         a              O              O\n","10  regular              O              O\n","11        x              O              O\n","12        -              O              O\n","13      ray              O              O\n","14       or              O              O\n","15       in              O              O\n","16       an              O              O\n","17        m              O              O\n","18     ##ri              O              O\n","19  imaging              O              O\n","20    study              O              O\n","21        .              O              O\n","\n","Sentence Nr:  1713\n","         WORD       GOLD       PRED\n","0          in          O          O\n","1    patients          O          O\n","2        with          O          O\n","3   pulmonary  B-DISEASE  B-DISEASE\n","4          fi  I-DISEASE  I-DISEASE\n","5       ##bro  I-DISEASE  I-DISEASE\n","6       ##sis  I-DISEASE  I-DISEASE\n","7   similarly          O          O\n","8           2          O          O\n","9           -          O          O\n","10          5          O          O\n","11          %          O          O\n","12        are          O          O\n","13    thought          O          O\n","14         to          O          O\n","15         be          O          O\n","16        due          O          O\n","17         to          O          O\n","18  mutations          O          O\n","19         in          O          O\n","20         te          O          O\n","21       ##rc          O          O\n","22         or          O          O\n","23         te          O          O\n","24       ##rt          O          O\n","25          .          O          O\n","\n","Sentence Nr:  1125\n","           WORD           GOLD           PRED\n","0           the              O              O\n","1      severity              O              O\n","2           and              O              O\n","3   progression              O              O\n","4            of              O              O\n","5             s  B-RAREDISEASE  B-RAREDISEASE\n","6          ##ps  I-RAREDISEASE  I-RAREDISEASE\n","7        varies              O              O\n","8          from              O              O\n","9           one              O              O\n","10       person              O              O\n","11           to              O              O\n","12      another              O              O\n","13            .              O              O\n","\n","Sentence Nr:  975\n","       WORD    GOLD    PRED\n","0    people       O       O\n","1      with       O       O\n","2      this       O       O\n","3   disease       O       O\n","4      also       O       O\n","5        br  B-SIGN  B-SIGN\n","6    ##uise  I-SIGN  I-SIGN\n","7    easily       O  I-SIGN\n","8       and       O       O\n","9       the       O       O\n","10  bruises  B-SIGN  B-SIGN\n","11     tend       O       O\n","12       to       O       O\n","13        l       O       O\n","14  ##inger       O       O\n","15        .       O       O\n","\n","Sentence Nr:  813\n","          WORD           GOLD           PRED\n","0            i  I-RAREDISEASE  B-RAREDISEASE\n","1   associated  I-RAREDISEASE  I-RAREDISEASE\n","2           my  I-RAREDISEASE  I-RAREDISEASE\n","3        ##elo  I-RAREDISEASE  I-RAREDISEASE\n","4      ##pathy  I-RAREDISEASE  I-RAREDISEASE\n","5            /  I-RAREDISEASE  I-RAREDISEASE\n","6     tropical  I-RAREDISEASE  I-RAREDISEASE\n","7          spa  I-RAREDISEASE  I-RAREDISEASE\n","8       ##stic  I-RAREDISEASE  I-RAREDISEASE\n","9         para  I-RAREDISEASE  I-RAREDISEASE\n","10       ##par  I-RAREDISEASE  I-RAREDISEASE\n","11      ##esis  I-RAREDISEASE  I-RAREDISEASE\n","12           (              O              O\n","13          ha  B-RAREDISEASE  B-RAREDISEASE\n","14         ##m  I-RAREDISEASE  I-RAREDISEASE\n","15           /  I-RAREDISEASE  I-RAREDISEASE\n","16           t  I-RAREDISEASE  I-RAREDISEASE\n","17        ##sp  I-RAREDISEASE  I-RAREDISEASE\n","18           )              O              O\n","19           .              O              O\n","\n","Sentence Nr:  1308\n","          WORD           GOLD           PRED\n","0    treatment              O              O\n","1           of              O              O\n","2            k  B-RAREDISEASE  B-RAREDISEASE\n","3         ##lu  I-RAREDISEASE  I-RAREDISEASE\n","4        ##ver  I-RAREDISEASE  I-RAREDISEASE\n","5            -  I-RAREDISEASE  I-RAREDISEASE\n","6            b  I-RAREDISEASE  I-RAREDISEASE\n","7         ##uc  I-RAREDISEASE  I-RAREDISEASE\n","8          ##y  I-RAREDISEASE  I-RAREDISEASE\n","9     syndrome  I-RAREDISEASE  I-RAREDISEASE\n","10          is              O              O\n","11  supportive              O              O\n","12         and              O              O\n","13          ps              O              O\n","14       ##ych              O              O\n","15        ##ot              O              O\n","16     ##ropic              O              O\n","17         ##s              O              O\n","18        that              O              O\n","19         may              O              O\n","20          be              O              O\n","21   effective              O              O\n","22         for              O              O\n","23        some              O              O\n","24          of              O              O\n","25         the              O              O\n","26  associated              O              O\n","27    symptoms              O              O\n","28           .              O              O\n","\n","Sentence Nr:  1763\n","        WORD           GOLD           PRED\n","0         in              O              O\n","1   addition              O              O\n","2          ,              O              O\n","3          o  B-RAREDISEASE  B-RAREDISEASE\n","4       ##cc  I-RAREDISEASE  I-RAREDISEASE\n","..       ...            ...            ...\n","70        or              O              O\n","71      near              O              O\n","72       the              O              O\n","73      ears              O              O\n","74         .              O              O\n","\n","[75 rows x 3 columns]\n","\n","Sentence Nr:  308\n","         WORD           GOLD           PRED\n","0          le  B-RAREDISEASE  B-RAREDISEASE\n","1        ##nn  I-RAREDISEASE  I-RAREDISEASE\n","2        ##ox  I-RAREDISEASE  I-RAREDISEASE\n","3           -  I-RAREDISEASE  I-RAREDISEASE\n","4         gas  I-RAREDISEASE  I-RAREDISEASE\n","5        ##ta  I-RAREDISEASE  I-RAREDISEASE\n","6        ##ut  I-RAREDISEASE  I-RAREDISEASE\n","7    syndrome  I-RAREDISEASE  I-RAREDISEASE\n","8           (              O              O\n","9           l  B-RAREDISEASE  B-RAREDISEASE\n","10       ##gs  I-RAREDISEASE  I-RAREDISEASE\n","11          )              O              O\n","12         is              O              O\n","13          a              O              O\n","14     severe              O              O\n","15       form              O              O\n","16         of              O              O\n","17          e      B-DISEASE      B-DISEASE\n","18     ##pile      I-DISEASE      I-DISEASE\n","19      ##psy      I-DISEASE      I-DISEASE\n","20       that              O              O\n","21  typically              O              O\n","22    becomes              O              O\n","23   apparent              O              O\n","24     during         I-SIGN              O\n","25    infancy         I-SIGN              O\n","26         or         I-SIGN              O\n","27      early         I-SIGN              O\n","28  childhood         I-SIGN              O\n","29          .              O              O\n","\n","Sentence Nr:  474\n","         WORD           GOLD           PRED\n","0         the              O              O\n","1       exact              O              O\n","2       cause              O              O\n","3          of              O              O\n","4          me  B-RAREDISEASE  B-RAREDISEASE\n","5        ##du  I-RAREDISEASE  I-RAREDISEASE\n","6      ##llar  I-RAREDISEASE  I-RAREDISEASE\n","7         ##y  I-RAREDISEASE  I-RAREDISEASE\n","8           s  I-RAREDISEASE  I-RAREDISEASE\n","9        ##po  I-RAREDISEASE  I-RAREDISEASE\n","10      ##nge  I-RAREDISEASE  I-RAREDISEASE\n","11     kidney  I-RAREDISEASE  I-RAREDISEASE\n","12         is              O              O\n","13        not              O              O\n","14      known              O              O\n","15        and              O              O\n","16       most              O              O\n","17      cases              O              O\n","18      occur              O              O\n","19          s              O              O\n","20  ##poradic              O              O\n","21     ##ally              O              O\n","22        for              O              O\n","23         no              O              O\n","24   apparent              O              O\n","25     reason              O              O\n","26          .              O              O\n","\n","Sentence Nr:  1300\n","        WORD GOLD PRED\n","0     during    O    O\n","1          a    O    O\n","2          s    O    O\n","3      ##chi    O    O\n","4    ##lling    O    O\n","5       test    O    O\n","6          ,    O    O\n","7        the    O    O\n","8         in    O    O\n","9     ##test    O    O\n","10    ##ines    O    O\n","11         '    O    O\n","12   ability    O    O\n","13        to    O    O\n","14    absorb    O    O\n","15   vitamin    O    O\n","16         b    O    O\n","17      ##12    O    O\n","18        is    O    O\n","19  measured    O    O\n","20         .    O    O\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lV_GbDavXyRC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625763242554,"user_tz":-120,"elapsed":11,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"eb7225f0-9dfb-4a99-888e-dd7ae8a8738b"},"source":["if allTypes:\n","    test_labels = ['DISEASE', 'RAREDISEASE', 'SYMPTOM', 'SIGN']\n","else:\n","    test_labels = ['RAREDISEASE', 'SIGN-SYM']\n","\n","test_to_use_gold = result_examples_y_gold\n","test_to_use_pred = result_examples_y_pred\n","\n","evaluator_examples = Evaluator(test_to_use_gold, test_to_use_pred, test_labels)\n","results_examples, results_agg_examples = evaluator_examples.evaluate()\n","\n","print('## OVERALL RESULTS')\n","for item in results_examples.keys():\n","    print('\\tEvaluation Metric: ', item)\n","    print('\\t', results_examples[item])\n","print('## RESULTS AT ENTITY LEVEL')\n","for entity in results_agg_examples.keys():\n","    print('Entity: ', entity)\n","    for item in results_agg_examples[entity].keys():\n","        print('\\tEvaluation Metric: ', item)\n","        print('\\t', results_agg_examples[entity][item])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-07-08 16:54:03 root INFO: Imported 30 predictions for 30 true examples\n"],"name":"stderr"},{"output_type":"stream","text":["## OVERALL RESULTS\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 28, 'incorrect': 3, 'partial': 0, 'missed': 6, 'spurious': 6, 'possible': 37, 'actual': 37, 'precision': 0.7567567567567568, 'recall': 0.7567567567567568}\n","\tEvaluation Metric:  partial\n","\t {'correct': 26, 'incorrect': 0, 'partial': 5, 'missed': 6, 'spurious': 6, 'possible': 37, 'actual': 37, 'precision': 0.7702702702702703, 'recall': 0.7702702702702703}\n","\tEvaluation Metric:  strict\n","\t {'correct': 24, 'incorrect': 7, 'partial': 0, 'missed': 6, 'spurious': 6, 'possible': 37, 'actual': 37, 'precision': 0.6486486486486487, 'recall': 0.6486486486486487}\n","\tEvaluation Metric:  exact\n","\t {'correct': 26, 'incorrect': 5, 'partial': 0, 'missed': 6, 'spurious': 6, 'possible': 37, 'actual': 37, 'precision': 0.7027027027027027, 'recall': 0.7027027027027027}\n","## RESULTS AT ENTITY LEVEL\n","Entity:  DISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 6, 'incorrect': 2, 'partial': 0, 'missed': 0, 'spurious': 6, 'possible': 8, 'actual': 14, 'precision': 0.42857142857142855, 'recall': 0.75}\n","\tEvaluation Metric:  partial\n","\t {'correct': 6, 'incorrect': 0, 'partial': 2, 'missed': 0, 'spurious': 6, 'possible': 8, 'actual': 14, 'precision': 0.5, 'recall': 0.875}\n","\tEvaluation Metric:  strict\n","\t {'correct': 5, 'incorrect': 3, 'partial': 0, 'missed': 0, 'spurious': 6, 'possible': 8, 'actual': 14, 'precision': 0.35714285714285715, 'recall': 0.625}\n","\tEvaluation Metric:  exact\n","\t {'correct': 6, 'incorrect': 2, 'partial': 0, 'missed': 0, 'spurious': 6, 'possible': 8, 'actual': 14, 'precision': 0.42857142857142855, 'recall': 0.75}\n","Entity:  RAREDISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 15, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 6, 'possible': 15, 'actual': 21, 'precision': 0.7142857142857143, 'recall': 1.0}\n","\tEvaluation Metric:  partial\n","\t {'correct': 15, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 6, 'possible': 15, 'actual': 21, 'precision': 0.7142857142857143, 'recall': 1.0}\n","\tEvaluation Metric:  strict\n","\t {'correct': 15, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 6, 'possible': 15, 'actual': 21, 'precision': 0.7142857142857143, 'recall': 1.0}\n","\tEvaluation Metric:  exact\n","\t {'correct': 15, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 6, 'possible': 15, 'actual': 21, 'precision': 0.7142857142857143, 'recall': 1.0}\n","Entity:  SYMPTOM\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 6, 'possible': 0, 'actual': 6, 'precision': 0.0, 'recall': 0}\n","\tEvaluation Metric:  partial\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 6, 'possible': 0, 'actual': 6, 'precision': 0.0, 'recall': 0}\n","\tEvaluation Metric:  strict\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 6, 'possible': 0, 'actual': 6, 'precision': 0.0, 'recall': 0}\n","\tEvaluation Metric:  exact\n","\t {'correct': 0, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 6, 'possible': 0, 'actual': 6, 'precision': 0.0, 'recall': 0}\n","Entity:  SIGN\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 7, 'incorrect': 1, 'partial': 0, 'missed': 6, 'spurious': 6, 'possible': 14, 'actual': 14, 'precision': 0.5, 'recall': 0.5}\n","\tEvaluation Metric:  partial\n","\t {'correct': 5, 'incorrect': 0, 'partial': 3, 'missed': 6, 'spurious': 6, 'possible': 14, 'actual': 14, 'precision': 0.4642857142857143, 'recall': 0.4642857142857143}\n","\tEvaluation Metric:  strict\n","\t {'correct': 4, 'incorrect': 4, 'partial': 0, 'missed': 6, 'spurious': 6, 'possible': 14, 'actual': 14, 'precision': 0.2857142857142857, 'recall': 0.2857142857142857}\n","\tEvaluation Metric:  exact\n","\t {'correct': 5, 'incorrect': 3, 'partial': 0, 'missed': 6, 'spurious': 6, 'possible': 14, 'actual': 14, 'precision': 0.35714285714285715, 'recall': 0.35714285714285715}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"39ZEiDXiX2xl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625763243128,"user_tz":-120,"elapsed":577,"user":{"displayName":"DAVID CAMINO PERDONES","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiLCCgS4w-fVRYMDlXvvqiLIeFpwQ42CszSb_Oy=s64","userId":"09595192169897091711"}},"outputId":"2fdfbaf4-c40d-44c5-a3d2-e96454f4335d"},"source":["evaluator_all = Evaluator(true_flags, pred_flags, test_labels)\n","results_all, results_agg_all = evaluator_all.evaluate()\n","\n","print('## OVERALL RESULTS')\n","for item in results_all.keys():\n","    print('\\tEvaluation Metric: ', item)\n","    print('\\t', results_all[item])\n","print('## RESULTS AT ENTITY LEVEL')\n","for entity in results_agg_all.keys():\n","    print('Entity: ', entity)\n","    for item in results_agg_all[entity].keys():\n","        print('\\tEvaluation Metric: ', item)\n","        print('\\t', results_agg_all[entity][item])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-07-08 16:54:03 root INFO: Imported 1772 predictions for 1772 true examples\n"],"name":"stderr"},{"output_type":"stream","text":["## OVERALL RESULTS\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 2026, 'incorrect': 276, 'partial': 0, 'missed': 306, 'spurious': 406, 'possible': 2608, 'actual': 2708, 'precision': 0.7481536189069424, 'recall': 0.776840490797546}\n","\tEvaluation Metric:  partial\n","\t {'correct': 2018, 'incorrect': 0, 'partial': 284, 'missed': 306, 'spurious': 406, 'possible': 2608, 'actual': 2708, 'precision': 0.7976366322008862, 'recall': 0.8282208588957055}\n","\tEvaluation Metric:  strict\n","\t {'correct': 1794, 'incorrect': 508, 'partial': 0, 'missed': 306, 'spurious': 406, 'possible': 2608, 'actual': 2708, 'precision': 0.6624815361890695, 'recall': 0.6878834355828221}\n","\tEvaluation Metric:  exact\n","\t {'correct': 2018, 'incorrect': 284, 'partial': 0, 'missed': 306, 'spurious': 406, 'possible': 2608, 'actual': 2708, 'precision': 0.7451994091580503, 'recall': 0.7737730061349694}\n","## RESULTS AT ENTITY LEVEL\n","Entity:  DISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 308, 'incorrect': 109, 'partial': 0, 'missed': 39, 'spurious': 406, 'possible': 456, 'actual': 823, 'precision': 0.37424058323207776, 'recall': 0.6754385964912281}\n","\tEvaluation Metric:  partial\n","\t {'correct': 383, 'incorrect': 0, 'partial': 34, 'missed': 39, 'spurious': 406, 'possible': 456, 'actual': 823, 'precision': 0.48602673147023084, 'recall': 0.8771929824561403}\n","\tEvaluation Metric:  strict\n","\t {'correct': 290, 'incorrect': 127, 'partial': 0, 'missed': 39, 'spurious': 406, 'possible': 456, 'actual': 823, 'precision': 0.35236938031591736, 'recall': 0.6359649122807017}\n","\tEvaluation Metric:  exact\n","\t {'correct': 383, 'incorrect': 34, 'partial': 0, 'missed': 39, 'spurious': 406, 'possible': 456, 'actual': 823, 'precision': 0.46537059538274606, 'recall': 0.8399122807017544}\n","Entity:  RAREDISEASE\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 995, 'incorrect': 79, 'partial': 0, 'missed': 33, 'spurious': 406, 'possible': 1107, 'actual': 1480, 'precision': 0.6722972972972973, 'recall': 0.8988256549232159}\n","\tEvaluation Metric:  partial\n","\t {'correct': 1000, 'incorrect': 0, 'partial': 74, 'missed': 33, 'spurious': 406, 'possible': 1107, 'actual': 1480, 'precision': 0.7006756756756757, 'recall': 0.9367660343270099}\n","\tEvaluation Metric:  strict\n","\t {'correct': 940, 'incorrect': 134, 'partial': 0, 'missed': 33, 'spurious': 406, 'possible': 1107, 'actual': 1480, 'precision': 0.6351351351351351, 'recall': 0.8491418247515808}\n","\tEvaluation Metric:  exact\n","\t {'correct': 1000, 'incorrect': 74, 'partial': 0, 'missed': 33, 'spurious': 406, 'possible': 1107, 'actual': 1480, 'precision': 0.6756756756756757, 'recall': 0.9033423667570009}\n","Entity:  SYMPTOM\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 42, 'incorrect': 4, 'partial': 0, 'missed': 9, 'spurious': 406, 'possible': 55, 'actual': 452, 'precision': 0.09292035398230089, 'recall': 0.7636363636363637}\n","\tEvaluation Metric:  partial\n","\t {'correct': 41, 'incorrect': 0, 'partial': 5, 'missed': 9, 'spurious': 406, 'possible': 55, 'actual': 452, 'precision': 0.09623893805309734, 'recall': 0.7909090909090909}\n","\tEvaluation Metric:  strict\n","\t {'correct': 37, 'incorrect': 9, 'partial': 0, 'missed': 9, 'spurious': 406, 'possible': 55, 'actual': 452, 'precision': 0.08185840707964602, 'recall': 0.6727272727272727}\n","\tEvaluation Metric:  exact\n","\t {'correct': 41, 'incorrect': 5, 'partial': 0, 'missed': 9, 'spurious': 406, 'possible': 55, 'actual': 452, 'precision': 0.09070796460176991, 'recall': 0.7454545454545455}\n","Entity:  SIGN\n","\tEvaluation Metric:  ent_type\n","\t {'correct': 681, 'incorrect': 84, 'partial': 0, 'missed': 225, 'spurious': 406, 'possible': 990, 'actual': 1171, 'precision': 0.5815542271562767, 'recall': 0.6878787878787879}\n","\tEvaluation Metric:  partial\n","\t {'correct': 594, 'incorrect': 0, 'partial': 171, 'missed': 225, 'spurious': 406, 'possible': 990, 'actual': 1171, 'precision': 0.5802732707087959, 'recall': 0.6863636363636364}\n","\tEvaluation Metric:  strict\n","\t {'correct': 527, 'incorrect': 238, 'partial': 0, 'missed': 225, 'spurious': 406, 'possible': 990, 'actual': 1171, 'precision': 0.45004269854824935, 'recall': 0.5323232323232323}\n","\tEvaluation Metric:  exact\n","\t {'correct': 594, 'incorrect': 171, 'partial': 0, 'missed': 225, 'spurious': 406, 'possible': 990, 'actual': 1171, 'precision': 0.5072587532023911, 'recall': 0.6}\n"],"name":"stdout"}]}]}